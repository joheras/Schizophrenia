{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "    models[ ' knn ' ] = KNeighborsClassifier(n_neighbors=7,n_jobs=-1)\n",
    "    models[ ' cart ' ] = DecisionTreeClassifier()\n",
    "    models[ ' svm ' ] = SVC()\n",
    "    models[ ' bayes ' ] = GaussianNB()\n",
    "    # ensemble models\n",
    "    models[ ' bag ' ] = BaggingClassifier(n_estimators=100,n_jobs=-1)\n",
    "    models[ ' rf ' ] = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "    models[ ' et ' ] = ExtraTreesClassifier(n_estimators=100,n_jobs=-1)\n",
    "    print( ' Defined %d models ' % len(models))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(testy, yhat)* 100.0\n",
    "    precision = precision_score(testy, yhat)* 100.0\n",
    "    recall = recall_score(testy, yhat)* 100.0\n",
    "    f1score = f1_score(testy, yhat)* 100.0\n",
    "    auc = roc_auc_score(testy, yhat)* 100.0\n",
    "    return [accuracy ,precision,recall,f1score, auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X,y, models):\n",
    "    \n",
    "    results = dict()\n",
    "    for i in range(0,5):\n",
    "        print('Iteration ' + str(i+1))\n",
    "        trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.20)\n",
    "        trainX = trainX.reshape((trainX.shape[0], trainX.shape[1] * trainX.shape[2]))\n",
    "        testX = testX.reshape((testX.shape[0], testX.shape[1] * testX.shape[2]))\n",
    "        mean = trainX.mean(axis=0)\n",
    "        trainX -= mean\n",
    "        std = trainX.std(axis=0)\n",
    "        trainX /= std\n",
    "        testX -= mean\n",
    "        testX /= std\n",
    "        for name, model in models.items():\n",
    "            print(name)\n",
    "            # evaluate the model\n",
    "            try:\n",
    "                results[name].append(evaluate_model(trainX, trainy, testX, testy, model))\n",
    "            except:\n",
    "                results[name] = [evaluate_model(trainX, trainy, testX, testy, model)]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(results):\n",
    "    for key in results.keys():\n",
    "        values = results[key]\n",
    "        print(key+ ', mean: '+ str(np.mean(values,axis=0))+ ', std: ' + str(np.std(values,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Defined 7 models \n",
      "Iteration 1\n",
      " knn \n",
      " cart \n",
      " svm \n",
      " bayes \n",
      " bag \n",
      " rf \n",
      " et \n",
      "Iteration 2\n",
      " knn \n",
      " cart \n",
      " svm \n",
      " bayes \n",
      " bag \n",
      " rf \n",
      " et \n",
      "Iteration 3\n",
      " knn \n",
      " cart \n",
      " svm \n",
      " bayes \n",
      " bag \n",
      " rf \n",
      " et \n",
      "Iteration 4\n",
      " knn \n",
      " cart \n",
      " svm \n",
      " bayes \n",
      " bag \n",
      " rf \n",
      " et \n",
      "Iteration 5\n",
      " knn \n",
      " cart \n",
      " svm \n",
      " bayes \n",
      " bag \n",
      " rf \n",
      " et \n"
     ]
    }
   ],
   "source": [
    "# get model list\n",
    "models = define_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " knn , mean: [55.10917031 49.32373226 99.8019802  66.0054683  60.13674392], std: [1.77702969 1.42394347 0.3960396  1.23135545 1.28008998]\n",
      " cart , mean: [64.71615721 59.28253705 61.16902326 60.18968009 64.31405401], std: [4.12796587 5.00244201 5.14853369 4.94117849 4.21991179]\n",
      " svm , mean: [62.09606987 54.72421838 77.81514344 64.21130078 63.89279666], std: [2.75351664 2.92281875 2.01654308 2.22122014 2.42687571]\n",
      " bayes , mean: [59.12663755 51.78915699 94.81510727 66.96435673 63.15593419], std: [3.26315139 2.38269103 2.6102573  2.38724692 2.97599342]\n",
      " bag , mean: [81.22270742 82.90160327 72.02580537 77.02021208 80.2131945 ], std: [1.74672489 3.76677893 1.95330522 1.89626619 1.65413011]\n",
      " rf , mean: [78.77729258 81.23752766 66.80662911 73.29107317 77.44317334], std: [1.55252304 2.31886364 2.94424125 2.35983986 1.74959249]\n",
      " et , mean: [76.94323144 76.29886127 68.35931324 72.06907867 75.96685737], std: [1.81944687 2.27703377 3.90499261 2.85067227 2.0562665 ]\n"
     ]
    }
   ],
   "source": [
    "show_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
