{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.metrics import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 6250, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(accuracies,precisions,recalls,aucs):\n",
    "    m, s = mean(accuracies), std(accuracies)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(precisions), std(precisions)\n",
    "    print( ' Precision: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(recalls), std(recalls)\n",
    "    print( ' Recall: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(aucs), std(aucs)\n",
    "    print( ' AUC: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7471 - accuracy: 0.5170 - precision: 0.4828 - recall: 0.4252 - auc: 0.5038\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.7112 - accuracy: 0.5203 - precision: 0.4893 - recall: 0.5327 - auc: 0.5209\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.7201 - accuracy: 0.4863 - precision: 0.4491 - recall: 0.4229 - auc: 0.4907\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7202 - accuracy: 0.4863 - precision: 0.4494 - recall: 0.4252 - auc: 0.4799\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.7098 - accuracy: 0.5049 - precision: 0.4701 - recall: 0.4416 - auc: 0.5019\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7098 - accuracy: 0.5016 - precision: 0.4554 - recall: 0.3224 - auc: 0.4892\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7100 - accuracy: 0.5027 - precision: 0.4615 - recall: 0.3645 - auc: 0.4839\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7119 - accuracy: 0.4863 - precision: 0.4476 - recall: 0.4089 - auc: 0.4686\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7124 - accuracy: 0.5038 - precision: 0.4535 - recall: 0.2850 - auc: 0.4706\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.7021 - accuracy: 0.5082 - precision: 0.4553 - recall: 0.2500 - auc: 0.5025\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.7016 - accuracy: 0.5170 - precision: 0.4652 - recall: 0.2033 - auc: 0.5178\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6979 - accuracy: 0.5126 - precision: 0.4635 - recall: 0.2523 - auc: 0.5111\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6971 - accuracy: 0.5235 - precision: 0.4901 - recall: 0.4042 - auc: 0.5138\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.7025 - accuracy: 0.5104 - precision: 0.4768 - recall: 0.4556 - auc: 0.5017\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6971 - accuracy: 0.5137 - precision: 0.4793 - recall: 0.4322 - auc: 0.5151\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6943 - accuracy: 0.5192 - precision: 0.4816 - recall: 0.3364 - auc: 0.5185\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6940 - accuracy: 0.5378 - precision: 0.5116 - recall: 0.3084 - auc: 0.5273\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6997 - accuracy: 0.5257 - precision: 0.4884 - recall: 0.2453 - auc: 0.5042\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6936 - accuracy: 0.5235 - precision: 0.4876 - recall: 0.3224 - auc: 0.5293\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7004 - accuracy: 0.4808 - precision: 0.4331 - recall: 0.3481 - auc: 0.4911\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6911 - accuracy: 0.5334 - precision: 0.5025 - recall: 0.4696 - auc: 0.5397\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7024 - accuracy: 0.4995 - precision: 0.4594 - recall: 0.3832 - auc: 0.4816\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.7010 - accuracy: 0.4874 - precision: 0.4180 - recall: 0.2383 - auc: 0.4787\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6849 - accuracy: 0.5378 - precision: 0.5136 - recall: 0.2640 - auc: 0.5661\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6974 - accuracy: 0.5257 - precision: 0.4872 - recall: 0.2220 - auc: 0.5189\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.6984 - accuracy: 0.5027 - precision: 0.4545 - recall: 0.3037 - auc: 0.4998\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.7036 - accuracy: 0.5093 - precision: 0.4693 - recall: 0.3575 - auc: 0.4854\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7017 - accuracy: 0.5005 - precision: 0.4591 - recall: 0.3668 - auc: 0.4907\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6969 - accuracy: 0.5170 - precision: 0.4830 - recall: 0.4322 - auc: 0.5119\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6942 - accuracy: 0.5235 - precision: 0.4892 - recall: 0.3715 - auc: 0.5184\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6975 - accuracy: 0.5071 - precision: 0.4631 - recall: 0.3224 - auc: 0.5004\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6896 - accuracy: 0.5345 - precision: 0.5050 - recall: 0.3575 - auc: 0.5333\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6985 - accuracy: 0.5137 - precision: 0.4733 - recall: 0.3318 - auc: 0.4943\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6915 - accuracy: 0.5444 - precision: 0.5221 - recall: 0.3318 - auc: 0.5344\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6938 - accuracy: 0.5214 - precision: 0.4841 - recall: 0.3201 - auc: 0.5055\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7029 - accuracy: 0.4841 - precision: 0.4343 - recall: 0.3318 - auc: 0.4678\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6896 - accuracy: 0.5203 - precision: 0.4877 - recall: 0.4626 - auc: 0.5405\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6948 - accuracy: 0.5104 - precision: 0.4740 - recall: 0.4042 - auc: 0.5107\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.6989 - accuracy: 0.5137 - precision: 0.4608 - recall: 0.2196 - auc: 0.4876\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6999 - accuracy: 0.5060 - precision: 0.4475 - recall: 0.2290 - auc: 0.4896\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6973 - accuracy: 0.5104 - precision: 0.4508 - recall: 0.2033 - auc: 0.5023\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6956 - accuracy: 0.5356 - precision: 0.5096 - recall: 0.2477 - auc: 0.5040\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6950 - accuracy: 0.5323 - precision: 0.5020 - recall: 0.2874 - auc: 0.5073\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6868 - accuracy: 0.5422 - precision: 0.5181 - recall: 0.3341 - auc: 0.5528\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.6997 - accuracy: 0.4907 - precision: 0.4448 - recall: 0.3481 - auc: 0.4847\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.6986 - accuracy: 0.5115 - precision: 0.4706 - recall: 0.3364 - auc: 0.4911\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6959 - accuracy: 0.5170 - precision: 0.4815 - recall: 0.3949 - auc: 0.5115\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6955 - accuracy: 0.5192 - precision: 0.4830 - recall: 0.3645 - auc: 0.5003\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6962 - accuracy: 0.5137 - precision: 0.4740 - recall: 0.3411 - auc: 0.4962\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6913 - accuracy: 0.5170 - precision: 0.4809 - recall: 0.3832 - auc: 0.5220\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.7460 - accuracy: 0.5093 - precision_1: 0.4771 - recall_1: 0.4860 - auc_1: 0.5094\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7291 - accuracy: 0.5115 - precision_1: 0.4651 - recall_1: 0.2804 - auc_1: 0.4894\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7056 - accuracy: 0.5378 - precision_1: 0.5078 - recall_1: 0.4579 - auc_1: 0.5363\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7239 - accuracy: 0.4929 - precision_1: 0.4644 - recall_1: 0.5327 - auc_1: 0.4834\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 75ms/step - loss: 0.7306 - accuracy: 0.4765 - precision_1: 0.4399 - recall_1: 0.4276 - auc_1: 0.4658\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7177 - accuracy: 0.4951 - precision_1: 0.4433 - recall_1: 0.3014 - auc_1: 0.4796\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.7089 - accuracy: 0.5301 - precision_1: 0.4977 - recall_1: 0.2547 - auc_1: 0.5132\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7156 - accuracy: 0.5137 - precision_1: 0.4570 - recall_1: 0.1986 - auc_1: 0.4791\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7132 - accuracy: 0.4754 - precision_1: 0.4380 - recall_1: 0.4206 - auc_1: 0.4723\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7050 - accuracy: 0.5060 - precision_1: 0.4779 - recall_1: 0.5818 - auc_1: 0.5199\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7078 - accuracy: 0.4995 - precision_1: 0.4635 - recall_1: 0.4299 - auc_1: 0.4910\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7151 - accuracy: 0.4765 - precision_1: 0.4053 - recall_1: 0.2500 - auc_1: 0.4672\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7102 - accuracy: 0.4995 - precision_1: 0.4199 - recall_1: 0.1776 - auc_1: 0.4863\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7072 - accuracy: 0.4852 - precision_1: 0.4192 - recall_1: 0.2547 - auc_1: 0.4814\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7098 - accuracy: 0.4841 - precision_1: 0.4447 - recall_1: 0.4042 - auc_1: 0.4721\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7023 - accuracy: 0.5126 - precision_1: 0.4761 - recall_1: 0.3949 - auc_1: 0.4968\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.7069 - accuracy: 0.5005 - precision_1: 0.4545 - recall_1: 0.3271 - auc_1: 0.4740\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6930 - accuracy: 0.5411 - precision_1: 0.5222 - recall_1: 0.2477 - auc_1: 0.5229\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.7027 - accuracy: 0.5115 - precision_1: 0.4664 - recall_1: 0.2921 - auc_1: 0.4924\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7032 - accuracy: 0.4929 - precision_1: 0.4448 - recall_1: 0.3294 - auc_1: 0.4916\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.6990 - accuracy: 0.5159 - precision_1: 0.4801 - recall_1: 0.3949 - auc_1: 0.5031\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.7002 - accuracy: 0.5027 - precision_1: 0.4635 - recall_1: 0.3855 - auc_1: 0.4931\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7000 - accuracy: 0.5060 - precision_1: 0.4563 - recall_1: 0.2804 - auc_1: 0.4947\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6957 - accuracy: 0.5257 - precision_1: 0.4884 - recall_1: 0.2453 - auc_1: 0.5199\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.6972 - accuracy: 0.5181 - precision_1: 0.4827 - recall_1: 0.3902 - auc_1: 0.5072\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.6895 - accuracy: 0.5389 - precision_1: 0.5111 - recall_1: 0.3762 - auc_1: 0.5420\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.7005 - accuracy: 0.5279 - precision_1: 0.4926 - recall_1: 0.2336 - auc_1: 0.5081\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7067 - accuracy: 0.5038 - precision_1: 0.4464 - recall_1: 0.2430 - auc_1: 0.4702\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6923 - accuracy: 0.5225 - precision_1: 0.4889 - recall_1: 0.4112 - auc_1: 0.5260\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6937 - accuracy: 0.5192 - precision_1: 0.4854 - recall_1: 0.4276 - auc_1: 0.5258\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6937 - accuracy: 0.5027 - precision_1: 0.4645 - recall_1: 0.3972 - auc_1: 0.5116\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.6938 - accuracy: 0.5345 - precision_1: 0.5062 - recall_1: 0.2874 - auc_1: 0.5215\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6936 - accuracy: 0.5378 - precision_1: 0.5119 - recall_1: 0.3014 - auc_1: 0.5182\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.6956 - accuracy: 0.5082 - precision_1: 0.4662 - recall_1: 0.3388 - auc_1: 0.5098\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7004 - accuracy: 0.5126 - precision_1: 0.4719 - recall_1: 0.3341 - auc_1: 0.4974\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.6960 - accuracy: 0.5181 - precision_1: 0.4801 - recall_1: 0.3388 - auc_1: 0.5070\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7007 - accuracy: 0.5016 - precision_1: 0.4523 - recall_1: 0.2991 - auc_1: 0.4830\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6928 - accuracy: 0.5323 - precision_1: 0.5016 - recall_1: 0.3598 - auc_1: 0.5240\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6971 - accuracy: 0.5214 - precision_1: 0.4842 - recall_1: 0.3224 - auc_1: 0.5031\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.6952 - accuracy: 0.5060 - precision_1: 0.4613 - recall_1: 0.3201 - auc_1: 0.4998\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6971 - accuracy: 0.5159 - precision_1: 0.4752 - recall_1: 0.3131 - auc_1: 0.4954\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6921 - accuracy: 0.5104 - precision_1: 0.4592 - recall_1: 0.2500 - auc_1: 0.5205\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6924 - accuracy: 0.5400 - precision_1: 0.5247 - recall_1: 0.1986 - auc_1: 0.5260\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6920 - accuracy: 0.5356 - precision_1: 0.5111 - recall_1: 0.2150 - auc_1: 0.5313\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6930 - accuracy: 0.5093 - precision_1: 0.4576 - recall_1: 0.2523 - auc_1: 0.5084\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6908 - accuracy: 0.5235 - precision_1: 0.4873 - recall_1: 0.3131 - auc_1: 0.5340\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6983 - accuracy: 0.4995 - precision_1: 0.4652 - recall_1: 0.4533 - auc_1: 0.4919\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.6919 - accuracy: 0.5203 - precision_1: 0.4887 - recall_1: 0.5070 - auc_1: 0.5357\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.6937 - accuracy: 0.5257 - precision_1: 0.4925 - recall_1: 0.3832 - auc_1: 0.5169\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6977 - accuracy: 0.5049 - precision_1: 0.4362 - recall_1: 0.1916 - auc_1: 0.4902\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7216 - accuracy: 0.5126 - precision_2: 0.4832 - recall_2: 0.5701 - auc_2: 0.5130\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7260 - accuracy: 0.5027 - precision_2: 0.4198 - recall_2: 0.1589 - auc_2: 0.4873\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7151 - accuracy: 0.5268 - precision_2: 0.4916 - recall_2: 0.2734 - auc_2: 0.5050\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7097 - accuracy: 0.5060 - precision_2: 0.4724 - recall_2: 0.4603 - auc_2: 0.4990\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7079 - accuracy: 0.4962 - precision_2: 0.4596 - recall_2: 0.4252 - auc_2: 0.4985\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7061 - accuracy: 0.5071 - precision_2: 0.4688 - recall_2: 0.3855 - auc_2: 0.4981\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7042 - accuracy: 0.5115 - precision_2: 0.4720 - recall_2: 0.3551 - auc_2: 0.5065\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6981 - accuracy: 0.5323 - precision_2: 0.5015 - recall_2: 0.3832 - auc_2: 0.5173\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7021 - accuracy: 0.5093 - precision_2: 0.4718 - recall_2: 0.3902 - auc_2: 0.5045\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7007 - accuracy: 0.5060 - precision_2: 0.4585 - recall_2: 0.2967 - auc_2: 0.5045\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7033 - accuracy: 0.5203 - precision_2: 0.4819 - recall_2: 0.3107 - auc_2: 0.5079\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6957 - accuracy: 0.5301 - precision_2: 0.4983 - recall_2: 0.3388 - auc_2: 0.5157\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6996 - accuracy: 0.5005 - precision_2: 0.4514 - recall_2: 0.3037 - auc_2: 0.4997\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6935 - accuracy: 0.5225 - precision_2: 0.4863 - recall_2: 0.3318 - auc_2: 0.5337\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6975 - accuracy: 0.4940 - precision_2: 0.4375 - recall_2: 0.2780 - auc_2: 0.5114\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.7041 - accuracy: 0.4973 - precision_2: 0.4517 - recall_2: 0.3388 - auc_2: 0.4873\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6939 - accuracy: 0.5268 - precision_2: 0.4943 - recall_2: 0.4065 - auc_2: 0.5230\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6970 - accuracy: 0.5214 - precision_2: 0.4846 - recall_2: 0.3318 - auc_2: 0.5126\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6875 - accuracy: 0.5345 - precision_2: 0.5060 - recall_2: 0.2944 - auc_2: 0.5540\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6957 - accuracy: 0.5181 - precision_2: 0.4720 - recall_2: 0.2360 - auc_2: 0.5221\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7030 - accuracy: 0.5049 - precision_2: 0.4388 - recall_2: 0.2009 - auc_2: 0.5013\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.7091 - accuracy: 0.4841 - precision_2: 0.4163 - recall_2: 0.2500 - auc_2: 0.4684\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6933 - accuracy: 0.5181 - precision_2: 0.4839 - recall_2: 0.4206 - auc_2: 0.5288\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.6989 - accuracy: 0.4973 - precision_2: 0.4517 - recall_2: 0.3388 - auc_2: 0.5043\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6959 - accuracy: 0.5301 - precision_2: 0.4981 - recall_2: 0.3107 - auc_2: 0.5231\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6944 - accuracy: 0.5246 - precision_2: 0.4867 - recall_2: 0.2570 - auc_2: 0.5234\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6956 - accuracy: 0.5159 - precision_2: 0.4743 - recall_2: 0.3014 - auc_2: 0.5131\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6884 - accuracy: 0.5170 - precision_2: 0.4781 - recall_2: 0.3318 - auc_2: 0.5455\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6732 - accuracy: 0.5663 - precision_2: 0.5567 - recall_2: 0.3668 - auc_2: 0.5967\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.6665 - accuracy: 0.5411 - precision_2: 0.5155 - recall_2: 0.3505 - auc_2: 0.5986\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.5996 - accuracy: 0.6123 - precision_2: 0.6267 - recall_2: 0.4276 - auc_2: 0.7138\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5630 - accuracy: 0.6561 - precision_2: 0.5931 - recall_2: 0.8481 - auc_2: 0.7251\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.5332 - accuracy: 0.6769 - precision_2: 0.6291 - recall_2: 0.7570 - auc_2: 0.7623\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4521 - accuracy: 0.8094 - precision_2: 0.7761 - recall_2: 0.8341 - auc_2: 0.8667\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5547 - accuracy: 0.6824 - precision_2: 0.6142 - recall_2: 0.8668 - auc_2: 0.7505\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.5266 - accuracy: 0.6791 - precision_2: 0.6849 - recall_2: 0.5841 - auc_2: 0.7907\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3966 - accuracy: 0.8127 - precision_2: 0.7954 - recall_2: 0.8084 - auc_2: 0.8936\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2949 - accuracy: 0.8850 - precision_2: 0.8400 - recall_2: 0.9322 - auc_2: 0.9420\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2454 - accuracy: 0.9036 - precision_2: 0.8728 - recall_2: 0.9299 - auc_2: 0.9598\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2210 - accuracy: 0.9222 - precision_2: 0.8923 - recall_2: 0.9486 - auc_2: 0.9631\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1975 - accuracy: 0.9277 - precision_2: 0.9022 - recall_2: 0.9486 - auc_2: 0.9684\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1785 - accuracy: 0.9409 - precision_2: 0.9156 - recall_2: 0.9626 - auc_2: 0.9739: 0s - loss: 0.1934 - accuracy: 0.9349 - precision_2: 0.8964 - recall_2: 0.9719 - auc_2: 0\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.1697 - accuracy: 0.9452 - precision_2: 0.9219 - recall_2: 0.9650 - auc_2: 0.9753\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.1723 - accuracy: 0.9430 - precision_2: 0.9273 - recall_2: 0.9533 - auc_2: 0.9752\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2249 - accuracy: 0.9211 - precision_2: 0.8870 - recall_2: 0.9533 - auc_2: 0.9670\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1403 - accuracy: 0.9617 - precision_2: 0.9376 - recall_2: 0.9836 - auc_2: 0.9867\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1631 - accuracy: 0.9474 - precision_2: 0.9185 - recall_2: 0.9743 - auc_2: 0.9778\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1210 - accuracy: 0.9639 - precision_2: 0.9519 - recall_2: 0.9720 - auc_2: 0.9882\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1161 - accuracy: 0.9606 - precision_2: 0.9475 - recall_2: 0.9696 - auc_2: 0.9876\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1140 - accuracy: 0.9628 - precision_2: 0.9437 - recall_2: 0.9790 - auc_2: 0.9888\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.7151 - accuracy: 0.5126 - precision_3: 0.4812 - recall_3: 0.5070 - auc_3: 0.5210\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7138 - accuracy: 0.5027 - precision_3: 0.4539 - recall_3: 0.2991 - auc_3: 0.4821\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.7053 - accuracy: 0.5137 - precision_3: 0.4706 - recall_3: 0.2991 - auc_3: 0.5079\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7001 - accuracy: 0.5323 - precision_3: 0.5019 - recall_3: 0.3014 - auc_3: 0.5233\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6986 - accuracy: 0.5312 - precision_3: 0.5000 - recall_3: 0.3832 - auc_3: 0.5293\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6903 - accuracy: 0.5356 - precision_3: 0.5067 - recall_3: 0.3551 - auc_3: 0.5545\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.6748 - accuracy: 0.5487 - precision_3: 0.5216 - recall_3: 0.4509 - auc_3: 0.6010\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6928 - accuracy: 0.5652 - precision_3: 0.5683 - recall_3: 0.3014 - auc_3: 0.5686\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.6789 - accuracy: 0.5641 - precision_3: 0.5322 - recall_3: 0.5794 - auc_3: 0.6018\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6915 - accuracy: 0.5531 - precision_3: 0.5294 - recall_3: 0.4206 - auc_3: 0.5566\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6819 - accuracy: 0.5750 - precision_3: 0.5498 - recall_3: 0.5164 - auc_3: 0.5869\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6944 - accuracy: 0.5356 - precision_3: 0.5061 - recall_3: 0.3855 - auc_3: 0.5538\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6724 - accuracy: 0.5849 - precision_3: 0.5773 - recall_3: 0.4276 - auc_3: 0.6137\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6508 - accuracy: 0.6166 - precision_3: 0.6175 - recall_3: 0.4790 - auc_3: 0.6588\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6271 - accuracy: 0.6670 - precision_3: 0.6520 - recall_3: 0.6215 - auc_3: 0.7207\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.5920 - accuracy: 0.7218 - precision_3: 0.7143 - recall_3: 0.6776 - auc_3: 0.7845\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5510 - accuracy: 0.7678 - precision_3: 0.7903 - recall_3: 0.6869 - auc_3: 0.8198\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6424 - accuracy: 0.6495 - precision_3: 0.7812 - recall_3: 0.3505 - auc_3: 0.7080\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5833 - accuracy: 0.6911 - precision_3: 0.6807 - recall_3: 0.6425 - auc_3: 0.7555\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.5308 - accuracy: 0.7579 - precision_3: 0.6892 - recall_3: 0.8808 - auc_3: 0.8437\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.4700 - accuracy: 0.7996 - precision_3: 0.8055 - recall_3: 0.7547 - auc_3: 0.8829\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.4504 - accuracy: 0.8039 - precision_3: 0.8411 - recall_3: 0.7173 - auc_3: 0.8855\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4157 - accuracy: 0.8291 - precision_3: 0.8301 - recall_3: 0.7991 - auc_3: 0.8996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.3718 - accuracy: 0.8609 - precision_3: 0.8525 - recall_3: 0.8505 - auc_3: 0.9201\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3517 - accuracy: 0.8806 - precision_3: 0.8771 - recall_3: 0.8668 - auc_3: 0.9313\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3675 - accuracy: 0.8423 - precision_3: 0.8757 - recall_3: 0.7734 - auc_3: 0.9215\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3458 - accuracy: 0.8762 - precision_3: 0.8344 - recall_3: 0.9182 - auc_3: 0.9329\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.3316 - accuracy: 0.8795 - precision_3: 0.8841 - recall_3: 0.8551 - auc_3: 0.9314\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2629 - accuracy: 0.9168 - precision_3: 0.9190 - recall_3: 0.9019 - auc_3: 0.9596\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2602 - accuracy: 0.9091 - precision_3: 0.8966 - recall_3: 0.9112 - auc_3: 0.9598\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2274 - accuracy: 0.9266 - precision_3: 0.9287 - recall_3: 0.9136 - auc_3: 0.9678\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2322 - accuracy: 0.9157 - precision_3: 0.9312 - recall_3: 0.8855 - auc_3: 0.9663\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2137 - accuracy: 0.9332 - precision_3: 0.9465 - recall_3: 0.9089 - auc_3: 0.9694\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2102 - accuracy: 0.9266 - precision_3: 0.9308 - recall_3: 0.9112 - auc_3: 0.9733\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.3163 - accuracy: 0.8697 - precision_3: 0.9142 - recall_3: 0.7967 - auc_3: 0.9399\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2717 - accuracy: 0.9036 - precision_3: 0.8586 - recall_3: 0.9509 - auc_3: 0.9600\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2210 - accuracy: 0.9233 - precision_3: 0.9431 - recall_3: 0.8902 - auc_3: 0.9685\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2190 - accuracy: 0.9124 - precision_3: 0.9028 - recall_3: 0.9112 - auc_3: 0.9708\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1991 - accuracy: 0.9310 - precision_3: 0.9506 - recall_3: 0.8995 - auc_3: 0.9738\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1684 - accuracy: 0.9365 - precision_3: 0.9282 - recall_3: 0.9369 - auc_3: 0.9820\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1631 - accuracy: 0.9354 - precision_3: 0.9511 - recall_3: 0.9089 - auc_3: 0.9834\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1735 - accuracy: 0.9365 - precision_3: 0.9205 - recall_3: 0.9463 - auc_3: 0.9823\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.1565 - accuracy: 0.9430 - precision_3: 0.9519 - recall_3: 0.9252 - auc_3: 0.9842\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1449 - accuracy: 0.9540 - precision_3: 0.9488 - recall_3: 0.9533 - auc_3: 0.9848\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1295 - accuracy: 0.9573 - precision_3: 0.9642 - recall_3: 0.9439 - auc_3: 0.9887\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1345 - accuracy: 0.9573 - precision_3: 0.9451 - recall_3: 0.9650 - auc_3: 0.9879\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1056 - accuracy: 0.9617 - precision_3: 0.9667 - recall_3: 0.9509 - auc_3: 0.9922\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0976 - accuracy: 0.9726 - precision_3: 0.9632 - recall_3: 0.9790 - auc_3: 0.9926\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0850 - accuracy: 0.9704 - precision_3: 0.9785 - recall_3: 0.9579 - auc_3: 0.9944\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0840 - accuracy: 0.9781 - precision_3: 0.9679 - recall_3: 0.9860 - auc_3: 0.9952\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.7136 - accuracy: 0.5323 - precision_4: 0.5014 - recall_4: 0.4042 - auc_4: 0.5195\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.7036 - accuracy: 0.4918 - precision_4: 0.4500 - recall_4: 0.3785 - auc_4: 0.5070\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.7111 - accuracy: 0.5049 - precision_4: 0.4721 - recall_4: 0.4743 - auc_4: 0.4925\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7051 - accuracy: 0.5159 - precision_4: 0.4802 - recall_4: 0.3972 - auc_4: 0.5024\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.7021 - accuracy: 0.5126 - precision_4: 0.4714 - recall_4: 0.3271 - auc_4: 0.5161\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7091 - accuracy: 0.5082 - precision_4: 0.4598 - recall_4: 0.2804 - auc_4: 0.4838\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7009 - accuracy: 0.5049 - precision_4: 0.4592 - recall_4: 0.3154 - auc_4: 0.5007\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.6981 - accuracy: 0.5170 - precision_4: 0.4850 - recall_4: 0.4907 - auc_4: 0.5205\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7013 - accuracy: 0.5027 - precision_4: 0.4714 - recall_4: 0.5000 - auc_4: 0.5061\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7067 - accuracy: 0.5159 - precision_4: 0.4788 - recall_4: 0.3692 - auc_4: 0.4950\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7028 - accuracy: 0.5192 - precision_4: 0.4768 - recall_4: 0.2640 - auc_4: 0.4982\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.7009 - accuracy: 0.5093 - precision_4: 0.4615 - recall_4: 0.2804 - auc_4: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7016 - accuracy: 0.5170 - precision_4: 0.4733 - recall_4: 0.2687 - auc_4: 0.4900\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7029 - accuracy: 0.5027 - precision_4: 0.4519 - recall_4: 0.2850 - auc_4: 0.4939\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7004 - accuracy: 0.5137 - precision_4: 0.4652 - recall_4: 0.2500 - auc_4: 0.5048\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6993 - accuracy: 0.5203 - precision_4: 0.4826 - recall_4: 0.3248 - auc_4: 0.5046\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6999 - accuracy: 0.5181 - precision_4: 0.4771 - recall_4: 0.2921 - auc_4: 0.4984\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.6916 - accuracy: 0.5334 - precision_4: 0.5045 - recall_4: 0.2617 - auc_4: 0.5328\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.7028 - accuracy: 0.5093 - precision_4: 0.4635 - recall_4: 0.2967 - auc_4: 0.4838\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6958 - accuracy: 0.5290 - precision_4: 0.4964 - recall_4: 0.3248 - auc_4: 0.5251\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.6960 - accuracy: 0.5137 - precision_4: 0.4685 - recall_4: 0.2780 - auc_4: 0.5137\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6949 - accuracy: 0.5279 - precision_4: 0.4940 - recall_4: 0.2874 - auc_4: 0.5160\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.6944 - accuracy: 0.5126 - precision_4: 0.4629 - recall_4: 0.2477 - auc_4: 0.5118\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6902 - accuracy: 0.5301 - precision_4: 0.4980 - recall_4: 0.2967 - auc_4: 0.5306\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7069 - accuracy: 0.4622 - precision_4: 0.4127 - recall_4: 0.3481 - auc_4: 0.4522\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.6950 - accuracy: 0.5301 - precision_4: 0.4987 - recall_4: 0.4416 - auc_4: 0.5176\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7022 - accuracy: 0.4885 - precision_4: 0.4334 - recall_4: 0.2967 - auc_4: 0.4702\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6970 - accuracy: 0.5159 - precision_4: 0.4690 - recall_4: 0.2477 - auc_4: 0.5077\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6935 - accuracy: 0.5192 - precision_4: 0.4766 - recall_4: 0.2617 - auc_4: 0.5146\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6965 - accuracy: 0.5301 - precision_4: 0.4981 - recall_4: 0.3107 - auc_4: 0.5088\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6969 - accuracy: 0.5115 - precision_4: 0.4727 - recall_4: 0.3645 - auc_4: 0.5056\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6942 - accuracy: 0.5104 - precision_4: 0.4558 - recall_4: 0.2290 - auc_4: 0.5135: 0s - loss: 0.6955 - accuracy: 0.5078 - precision_4: 0.4778 - recall_4: 0.2324 - auc_4: 0.51\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6933 - accuracy: 0.5367 - precision_4: 0.5229 - recall_4: 0.1332 - auc_4: 0.5264\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.7036 - accuracy: 0.5049 - precision_4: 0.4032 - recall_4: 0.1168 - auc_4: 0.4804\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.6966 - accuracy: 0.5115 - precision_4: 0.4500 - recall_4: 0.1893 - auc_4: 0.5030\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6969 - accuracy: 0.4995 - precision_4: 0.4449 - recall_4: 0.2734 - auc_4: 0.4952\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6973 - accuracy: 0.4929 - precision_4: 0.4377 - recall_4: 0.2874 - auc_4: 0.4951\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.6967 - accuracy: 0.5093 - precision_4: 0.4554 - recall_4: 0.2383 - auc_4: 0.4969\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.6993 - accuracy: 0.4951 - precision_4: 0.4292 - recall_4: 0.2336 - auc_4: 0.4761\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6933 - accuracy: 0.5301 - precision_4: 0.4973 - recall_4: 0.2173 - auc_4: 0.5131\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.6937 - accuracy: 0.5367 - precision_4: 0.5140 - recall_4: 0.2150 - auc_4: 0.5117\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.6921 - accuracy: 0.4984 - precision_4: 0.4419 - recall_4: 0.2664 - auc_4: 0.5119\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6935 - accuracy: 0.5203 - precision_4: 0.4855 - recall_4: 0.3902 - auc_4: 0.5164\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.6946 - accuracy: 0.5181 - precision_4: 0.4840 - recall_4: 0.4252 - auc_4: 0.5184\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6934 - accuracy: 0.5148 - precision_4: 0.4749 - recall_4: 0.3318 - auc_4: 0.5135\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.6912 - accuracy: 0.5257 - precision_4: 0.4894 - recall_4: 0.2687 - auc_4: 0.5331\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7001 - accuracy: 0.5159 - precision_4: 0.4635 - recall_4: 0.2079 - auc_4: 0.4785\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.6958 - accuracy: 0.5159 - precision_4: 0.4663 - recall_4: 0.2266 - auc_4: 0.4941\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.6930 - accuracy: 0.5323 - precision_4: 0.5018 - recall_4: 0.3224 - auc_4: 0.5127\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6933 - accuracy: 0.5203 - precision_4: 0.4784 - recall_4: 0.2593 - auc_4: 0.5142\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7efcf0171a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " Accuracy: 74.061% (+/-16.037) \n",
      " Precision: 46.003% (+/-40.543) \n",
      " Recall: 56.136% (+/-45.860) \n",
      " AUC: 72.365% (+/-22.090) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.7456 - accuracy: 0.5115 - precision_5: 0.4763 - recall_5: 0.4229 - auc_5: 0.5121\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.7217 - accuracy: 0.5422 - precision_5: 0.5130 - recall_5: 0.4626 - auc_5: 0.5436\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.7283 - accuracy: 0.5005 - precision_5: 0.4659 - recall_5: 0.4463 - auc_5: 0.4953\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.7369 - accuracy: 0.4589 - precision_5: 0.4149 - recall_5: 0.3762 - auc_5: 0.4570\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7193 - accuracy: 0.5071 - precision_5: 0.4707 - recall_5: 0.4136 - auc_5: 0.5001\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6921 - accuracy: 0.5761 - precision_5: 0.5627 - recall_5: 0.4299 - auc_5: 0.5753\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.6899 - accuracy: 0.5619 - precision_5: 0.5363 - recall_5: 0.4836 - auc_5: 0.5765\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6541 - accuracy: 0.6210 - precision_5: 0.5981 - recall_5: 0.5841 - auc_5: 0.6584\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6474 - accuracy: 0.6243 - precision_5: 0.5977 - recall_5: 0.6075 - auc_5: 0.6652\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.6090 - accuracy: 0.6605 - precision_5: 0.6705 - recall_5: 0.5421 - auc_5: 0.7319\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.5736 - accuracy: 0.6999 - precision_5: 0.6782 - recall_5: 0.6846 - auc_5: 0.7739\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.5018 - accuracy: 0.7700 - precision_5: 0.7583 - recall_5: 0.7477 - auc_5: 0.8485\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.4672 - accuracy: 0.7985 - precision_5: 0.7711 - recall_5: 0.8107 - auc_5: 0.8758\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.4914 - accuracy: 0.7579 - precision_5: 0.7379 - recall_5: 0.7500 - auc_5: 0.8448\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.4483 - accuracy: 0.7875 - precision_5: 0.7378 - recall_5: 0.8481 - auc_5: 0.8778\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.3713 - accuracy: 0.8576 - precision_5: 0.8091 - recall_5: 0.9112 - auc_5: 0.9162\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3512 - accuracy: 0.8478 - precision_5: 0.8247 - recall_5: 0.8575 - auc_5: 0.9243\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.2922 - accuracy: 0.8916 - precision_5: 0.9042 - recall_5: 0.8598 - auc_5: 0.9534\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.2785 - accuracy: 0.8992 - precision_5: 0.8717 - recall_5: 0.9206 - auc_5: 0.9525\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.2342 - accuracy: 0.9135 - precision_5: 0.8975 - recall_5: 0.9206 - auc_5: 0.9663\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2001 - accuracy: 0.9266 - precision_5: 0.9308 - recall_5: 0.9112 - auc_5: 0.9758\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1551 - accuracy: 0.9496 - precision_5: 0.9381 - recall_5: 0.9556 - auc_5: 0.9859\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.1559 - accuracy: 0.9518 - precision_5: 0.9486 - recall_5: 0.9486 - auc_5: 0.9836\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1625 - accuracy: 0.9365 - precision_5: 0.9167 - recall_5: 0.9509 - auc_5: 0.9834\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1398 - accuracy: 0.9441 - precision_5: 0.9314 - recall_5: 0.9509 - auc_5: 0.9886\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1167 - accuracy: 0.9606 - precision_5: 0.9579 - recall_5: 0.9579 - auc_5: 0.9919\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1111 - accuracy: 0.9617 - precision_5: 0.9319 - recall_5: 0.9907 - auc_5: 0.9929\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0978 - accuracy: 0.9660 - precision_5: 0.9606 - recall_5: 0.9673 - auc_5: 0.9931\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0789 - accuracy: 0.9715 - precision_5: 0.9696 - recall_5: 0.9696 - auc_5: 0.9964\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0736 - accuracy: 0.9803 - precision_5: 0.9767 - recall_5: 0.9813 - auc_5: 0.9956\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0764 - accuracy: 0.9770 - precision_5: 0.9678 - recall_5: 0.9836 - auc_5: 0.9955\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0734 - accuracy: 0.9759 - precision_5: 0.9635 - recall_5: 0.9860 - auc_5: 0.9948\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0554 - accuracy: 0.9781 - precision_5: 0.9744 - recall_5: 0.9790 - auc_5: 0.9981\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0766 - accuracy: 0.9803 - precision_5: 0.9881 - recall_5: 0.9696 - auc_5: 0.9951\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0818 - accuracy: 0.9748 - precision_5: 0.9810 - recall_5: 0.9650 - auc_5: 0.9947\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0658 - accuracy: 0.9836 - precision_5: 0.9725 - recall_5: 0.9930 - auc_5: 0.9962\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0554 - accuracy: 0.9803 - precision_5: 0.9812 - recall_5: 0.9766 - auc_5: 0.9982\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0520 - accuracy: 0.9836 - precision_5: 0.9791 - recall_5: 0.9860 - auc_5: 0.9973\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0556 - accuracy: 0.9836 - precision_5: 0.9836 - recall_5: 0.9813 - auc_5: 0.9958\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0576 - accuracy: 0.9770 - precision_5: 0.9636 - recall_5: 0.9883 - auc_5: 0.9976\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0457 - accuracy: 0.9847 - precision_5: 0.9770 - recall_5: 0.9907 - auc_5: 0.9987\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0522 - accuracy: 0.9869 - precision_5: 0.9815 - recall_5: 0.9907 - auc_5: 0.9963\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0448 - accuracy: 0.9836 - precision_5: 0.9814 - recall_5: 0.9836 - auc_5: 0.9986\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0359 - accuracy: 0.9869 - precision_5: 0.9749 - recall_5: 0.9977 - auc_5: 0.9992\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0448 - accuracy: 0.9847 - precision_5: 0.9859 - recall_5: 0.9813 - auc_5: 0.9990\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0550 - accuracy: 0.9825 - precision_5: 0.9858 - recall_5: 0.9766 - auc_5: 0.9972\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0474 - accuracy: 0.9814 - precision_5: 0.9703 - recall_5: 0.9907 - auc_5: 0.9988\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0349 - accuracy: 0.9912 - precision_5: 0.9884 - recall_5: 0.9930 - auc_5: 0.9993\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0344 - accuracy: 0.9901 - precision_5: 0.9883 - recall_5: 0.9907 - auc_5: 0.9990\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0304 - accuracy: 0.9890 - precision_5: 0.9794 - recall_5: 0.9977 - auc_5: 0.9996\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd9c653510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.7340 - accuracy: 0.5060 - precision_6: 0.4637 - recall_6: 0.3435 - auc_6: 0.4951\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.7187 - accuracy: 0.4962 - precision_6: 0.4524 - recall_6: 0.3551 - auc_6: 0.4929\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7270 - accuracy: 0.5060 - precision_6: 0.4743 - recall_6: 0.4953 - auc_6: 0.4798\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7116 - accuracy: 0.5126 - precision_6: 0.4845 - recall_6: 0.6215 - auc_6: 0.5233\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.6857 - accuracy: 0.5411 - precision_6: 0.5122 - recall_6: 0.4416 - auc_6: 0.5737\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.6840 - accuracy: 0.5531 - precision_6: 0.5296 - recall_6: 0.4182 - auc_6: 0.5769\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.6772 - accuracy: 0.5455 - precision_6: 0.5180 - recall_6: 0.4369 - auc_6: 0.5898\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.6499 - accuracy: 0.6068 - precision_6: 0.5869 - recall_6: 0.5444 - auc_6: 0.6538\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6271 - accuracy: 0.6484 - precision_6: 0.6230 - recall_6: 0.6332 - auc_6: 0.7052\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6038 - accuracy: 0.6802 - precision_6: 0.6323 - recall_6: 0.7593 - auc_6: 0.7402\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.5681 - accuracy: 0.7054 - precision_6: 0.7751 - recall_6: 0.5234 - auc_6: 0.7926\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.4845 - accuracy: 0.7853 - precision_6: 0.7636 - recall_6: 0.7850 - auc_6: 0.8567\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4292 - accuracy: 0.8116 - precision_6: 0.7870 - recall_6: 0.8201 - auc_6: 0.8943\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3759 - accuracy: 0.8587 - precision_6: 0.8551 - recall_6: 0.8411 - auc_6: 0.9213\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.3873 - accuracy: 0.8467 - precision_6: 0.8412 - recall_6: 0.8294 - auc_6: 0.9067\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2986 - accuracy: 0.8850 - precision_6: 0.8836 - recall_6: 0.8692 - auc_6: 0.9484\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2519 - accuracy: 0.9080 - precision_6: 0.8822 - recall_6: 0.9276 - auc_6: 0.9618\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2565 - accuracy: 0.9058 - precision_6: 0.8834 - recall_6: 0.9206 - auc_6: 0.9579\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2549 - accuracy: 0.8981 - precision_6: 0.9156 - recall_6: 0.8621 - auc_6: 0.9637\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2280 - accuracy: 0.9200 - precision_6: 0.8834 - recall_6: 0.9556 - auc_6: 0.9698\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2374 - accuracy: 0.9189 - precision_6: 0.9470 - recall_6: 0.8762 - auc_6: 0.9691\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2132 - accuracy: 0.9179 - precision_6: 0.8716 - recall_6: 0.9673 - auc_6: 0.9748\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1652 - accuracy: 0.9419 - precision_6: 0.9213 - recall_6: 0.9579 - auc_6: 0.9820\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1520 - accuracy: 0.9518 - precision_6: 0.9528 - recall_6: 0.9439 - auc_6: 0.9849\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1473 - accuracy: 0.9562 - precision_6: 0.9470 - recall_6: 0.9603 - auc_6: 0.9855\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1682 - accuracy: 0.9376 - precision_6: 0.9150 - recall_6: 0.9556 - auc_6: 0.9828\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1192 - accuracy: 0.9595 - precision_6: 0.9536 - recall_6: 0.9603 - auc_6: 0.9910\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1284 - accuracy: 0.9595 - precision_6: 0.9474 - recall_6: 0.9673 - auc_6: 0.9875\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1183 - accuracy: 0.9529 - precision_6: 0.9212 - recall_6: 0.9836 - auc_6: 0.9928\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1231 - accuracy: 0.9518 - precision_6: 0.9571 - recall_6: 0.9393 - auc_6: 0.9903\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1171 - accuracy: 0.9628 - precision_6: 0.9690 - recall_6: 0.9509 - auc_6: 0.9916\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1054 - accuracy: 0.9660 - precision_6: 0.9584 - recall_6: 0.9696 - auc_6: 0.9933\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0963 - accuracy: 0.9650 - precision_6: 0.9562 - recall_6: 0.9696 - auc_6: 0.9933\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0976 - accuracy: 0.9693 - precision_6: 0.9545 - recall_6: 0.9813 - auc_6: 0.9926\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1069 - accuracy: 0.9660 - precision_6: 0.9606 - recall_6: 0.9673 - auc_6: 0.9905\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0855 - accuracy: 0.9715 - precision_6: 0.9855 - recall_6: 0.9533 - auc_6: 0.9957\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0771 - accuracy: 0.9748 - precision_6: 0.9634 - recall_6: 0.9836 - auc_6: 0.9959\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0735 - accuracy: 0.9803 - precision_6: 0.9904 - recall_6: 0.9673 - auc_6: 0.9959\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0729 - accuracy: 0.9803 - precision_6: 0.9835 - recall_6: 0.9743 - auc_6: 0.9949\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0741 - accuracy: 0.9704 - precision_6: 0.9609 - recall_6: 0.9766 - auc_6: 0.9972\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0720 - accuracy: 0.9737 - precision_6: 0.9856 - recall_6: 0.9579 - auc_6: 0.9976\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0484 - accuracy: 0.9792 - precision_6: 0.9723 - recall_6: 0.9836 - auc_6: 0.9989\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0516 - accuracy: 0.9836 - precision_6: 0.9928 - recall_6: 0.9720 - auc_6: 0.9987\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0423 - accuracy: 0.9880 - precision_6: 0.9838 - recall_6: 0.9907 - auc_6: 0.9990\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0458 - accuracy: 0.9825 - precision_6: 0.9747 - recall_6: 0.9883 - auc_6: 0.9988\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0394 - accuracy: 0.9901 - precision_6: 0.9861 - recall_6: 0.9930 - auc_6: 0.9988\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0433 - accuracy: 0.9869 - precision_6: 0.9837 - recall_6: 0.9883 - auc_6: 0.9979\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0384 - accuracy: 0.9847 - precision_6: 0.9814 - recall_6: 0.9860 - auc_6: 0.9990\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0357 - accuracy: 0.9912 - precision_6: 0.9907 - recall_6: 0.9907 - auc_6: 0.9992\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1129 - accuracy: 0.9606 - precision_6: 0.9279 - recall_6: 0.9930 - auc_6: 0.9943\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd9c86fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7132 - accuracy: 0.5334 - precision_7: 0.5021 - recall_7: 0.5537 - auc_7: 0.5411\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7065 - accuracy: 0.5235 - precision_7: 0.4894 - recall_7: 0.3762 - auc_7: 0.5353\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7025 - accuracy: 0.5192 - precision_7: 0.4860 - recall_7: 0.4463 - auc_7: 0.5430\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6937 - accuracy: 0.5553 - precision_7: 0.5327 - recall_7: 0.4182 - auc_7: 0.5633\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.6762 - accuracy: 0.5739 - precision_7: 0.5484 - recall_7: 0.5164 - auc_7: 0.6051\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6657 - accuracy: 0.5641 - precision_7: 0.5517 - recall_7: 0.3738 - auc_7: 0.6233\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6518 - accuracy: 0.5958 - precision_7: 0.5778 - recall_7: 0.5117 - auc_7: 0.6464\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6248 - accuracy: 0.6254 - precision_7: 0.6049 - recall_7: 0.5794 - auc_7: 0.6969\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.5809 - accuracy: 0.6824 - precision_7: 0.6825 - recall_7: 0.6028 - auc_7: 0.7719\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5410 - accuracy: 0.7568 - precision_7: 0.7352 - recall_7: 0.7523 - auc_7: 0.8266\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4527 - accuracy: 0.8248 - precision_7: 0.8018 - recall_7: 0.8318 - auc_7: 0.8822\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.3826 - accuracy: 0.8598 - precision_7: 0.8205 - recall_7: 0.8972 - auc_7: 0.9268\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3231 - accuracy: 0.8905 - precision_7: 0.8581 - recall_7: 0.9182 - auc_7: 0.9407\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2943 - accuracy: 0.8894 - precision_7: 0.8547 - recall_7: 0.9206 - auc_7: 0.9471\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2751 - accuracy: 0.9168 - precision_7: 0.9093 - recall_7: 0.9136 - auc_7: 0.9545\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2217 - accuracy: 0.9189 - precision_7: 0.8734 - recall_7: 0.9673 - auc_7: 0.9697\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2221 - accuracy: 0.9189 - precision_7: 0.8969 - recall_7: 0.9346 - auc_7: 0.9676\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1662 - accuracy: 0.9463 - precision_7: 0.9202 - recall_7: 0.9696 - auc_7: 0.9819\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1689 - accuracy: 0.9409 - precision_7: 0.9174 - recall_7: 0.9603 - auc_7: 0.9814\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1391 - accuracy: 0.9551 - precision_7: 0.9408 - recall_7: 0.9650 - auc_7: 0.9865\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1122 - accuracy: 0.9693 - precision_7: 0.9587 - recall_7: 0.9766 - auc_7: 0.9901\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1137 - accuracy: 0.9606 - precision_7: 0.9395 - recall_7: 0.9790 - auc_7: 0.9912\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1114 - accuracy: 0.9650 - precision_7: 0.9500 - recall_7: 0.9766 - auc_7: 0.9903\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1009 - accuracy: 0.9693 - precision_7: 0.9545 - recall_7: 0.9813 - auc_7: 0.9909\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0973 - accuracy: 0.9704 - precision_7: 0.9630 - recall_7: 0.9743 - auc_7: 0.9926\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0763 - accuracy: 0.9748 - precision_7: 0.9698 - recall_7: 0.9766 - auc_7: 0.9956\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0822 - accuracy: 0.9704 - precision_7: 0.9588 - recall_7: 0.9790 - auc_7: 0.9950\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1008 - accuracy: 0.9650 - precision_7: 0.9583 - recall_7: 0.9673 - auc_7: 0.9913\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0996 - accuracy: 0.9639 - precision_7: 0.9341 - recall_7: 0.9930 - auc_7: 0.9938\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1136 - accuracy: 0.9595 - precision_7: 0.9536 - recall_7: 0.9603 - auc_7: 0.9909\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0969 - accuracy: 0.9639 - precision_7: 0.9805 - recall_7: 0.9416 - auc_7: 0.9948\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0640 - accuracy: 0.9770 - precision_7: 0.9636 - recall_7: 0.9883 - auc_7: 0.9967\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0630 - accuracy: 0.9792 - precision_7: 0.9767 - recall_7: 0.9790 - auc_7: 0.9962\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0660 - accuracy: 0.9781 - precision_7: 0.9722 - recall_7: 0.9813 - auc_7: 0.9964\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0605 - accuracy: 0.9792 - precision_7: 0.9637 - recall_7: 0.9930 - auc_7: 0.9983\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0631 - accuracy: 0.9759 - precision_7: 0.9833 - recall_7: 0.9650 - auc_7: 0.9978\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0650 - accuracy: 0.9715 - precision_7: 0.9589 - recall_7: 0.9813 - auc_7: 0.9974\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0537 - accuracy: 0.9814 - precision_7: 0.9703 - recall_7: 0.9907 - auc_7: 0.9986\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0497 - accuracy: 0.9858 - precision_7: 0.9882 - recall_7: 0.9813 - auc_7: 0.9978\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0393 - accuracy: 0.9858 - precision_7: 0.9792 - recall_7: 0.9907 - auc_7: 0.9991\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0379 - accuracy: 0.9847 - precision_7: 0.9905 - recall_7: 0.9766 - auc_7: 0.9994\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0375 - accuracy: 0.9880 - precision_7: 0.9771 - recall_7: 0.9977 - auc_7: 0.9990\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0273 - accuracy: 0.9934 - precision_7: 0.9884 - recall_7: 0.9977 - auc_7: 0.9995\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0382 - accuracy: 0.9880 - precision_7: 0.9838 - recall_7: 0.9907 - auc_7: 0.9980\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0329 - accuracy: 0.9869 - precision_7: 0.9771 - recall_7: 0.9953 - auc_7: 0.9997\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0428 - accuracy: 0.9869 - precision_7: 0.9906 - recall_7: 0.9813 - auc_7: 0.9976\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0299 - accuracy: 0.9912 - precision_7: 0.9861 - recall_7: 0.9953 - auc_7: 0.9981\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0257 - accuracy: 0.9934 - precision_7: 0.9884 - recall_7: 0.9977 - auc_7: 0.9984\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0203 - accuracy: 0.9934 - precision_7: 0.9907 - recall_7: 0.9953 - auc_7: 0.9998\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0234 - accuracy: 0.9945 - precision_7: 0.9976 - recall_7: 0.9907 - auc_7: 0.9986\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efcf8080268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7340 - accuracy: 0.5192 - precision_8: 0.4858 - recall_8: 0.4393 - auc_8: 0.5105\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7119 - accuracy: 0.5301 - precision_8: 0.4983 - recall_8: 0.3458 - auc_8: 0.5101\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7095 - accuracy: 0.4940 - precision_8: 0.4562 - recall_8: 0.4136 - auc_8: 0.5012\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7027 - accuracy: 0.5345 - precision_8: 0.5059 - recall_8: 0.3014 - auc_8: 0.5351\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6876 - accuracy: 0.5586 - precision_8: 0.5371 - recall_8: 0.4229 - auc_8: 0.5652\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6893 - accuracy: 0.5312 - precision_8: 0.5000 - recall_8: 0.4720 - auc_8: 0.5606\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6838 - accuracy: 0.5608 - precision_8: 0.5405 - recall_8: 0.4206 - auc_8: 0.5770\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6816 - accuracy: 0.5389 - precision_8: 0.5084 - recall_8: 0.4953 - auc_8: 0.5695\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6766 - accuracy: 0.5947 - precision_8: 0.5597 - recall_8: 0.6355 - auc_8: 0.6136\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6891 - accuracy: 0.5498 - precision_8: 0.5586 - recall_8: 0.1893 - auc_8: 0.5706\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6835 - accuracy: 0.5630 - precision_8: 0.5420 - recall_8: 0.4369 - auc_8: 0.5663\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.6820 - accuracy: 0.5411 - precision_8: 0.5090 - recall_8: 0.5935 - auc_8: 0.5660\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6672 - accuracy: 0.5619 - precision_8: 0.5355 - recall_8: 0.4930 - auc_8: 0.6020\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.6361 - accuracy: 0.6331 - precision_8: 0.6281 - recall_8: 0.5327 - auc_8: 0.6784\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6359 - accuracy: 0.6375 - precision_8: 0.6667 - recall_8: 0.4533 - auc_8: 0.6916\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6231 - accuracy: 0.6407 - precision_8: 0.6506 - recall_8: 0.5047 - auc_8: 0.7029\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5802 - accuracy: 0.7032 - precision_8: 0.6938 - recall_8: 0.6565 - auc_8: 0.7643\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.5581 - accuracy: 0.7229 - precision_8: 0.7238 - recall_8: 0.6612 - auc_8: 0.7933\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.5381 - accuracy: 0.7382 - precision_8: 0.7507 - recall_8: 0.6612 - auc_8: 0.8065\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.5075 - accuracy: 0.7426 - precision_8: 0.7560 - recall_8: 0.6659 - auc_8: 0.8347\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4126 - accuracy: 0.8018 - precision_8: 0.8175 - recall_8: 0.7430 - auc_8: 0.9038\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.3771 - accuracy: 0.8434 - precision_8: 0.8740 - recall_8: 0.7780 - auc_8: 0.9203\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.3868 - accuracy: 0.8445 - precision_8: 0.7979 - recall_8: 0.8949 - auc_8: 0.9082\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.3877 - accuracy: 0.8324 - precision_8: 0.8590 - recall_8: 0.7687 - auc_8: 0.9141\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2892 - accuracy: 0.8970 - precision_8: 0.9175 - recall_8: 0.8575 - auc_8: 0.9509\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.2714 - accuracy: 0.8883 - precision_8: 0.8705 - recall_8: 0.8949 - auc_8: 0.9551\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1930 - accuracy: 0.9365 - precision_8: 0.9224 - recall_8: 0.9439 - auc_8: 0.9786\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2086 - accuracy: 0.9244 - precision_8: 0.9305 - recall_8: 0.9065 - auc_8: 0.9738\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1811 - accuracy: 0.9354 - precision_8: 0.9222 - recall_8: 0.9416 - auc_8: 0.9804\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1640 - accuracy: 0.9441 - precision_8: 0.9499 - recall_8: 0.9299 - auc_8: 0.9829\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1567 - accuracy: 0.9409 - precision_8: 0.9329 - recall_8: 0.9416 - auc_8: 0.9841\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1366 - accuracy: 0.9540 - precision_8: 0.9347 - recall_8: 0.9696 - auc_8: 0.9872\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1178 - accuracy: 0.9584 - precision_8: 0.9710 - recall_8: 0.9393 - auc_8: 0.9913\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1205 - accuracy: 0.9529 - precision_8: 0.9287 - recall_8: 0.9743 - auc_8: 0.9913\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1128 - accuracy: 0.9628 - precision_8: 0.9581 - recall_8: 0.9626 - auc_8: 0.9912\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0940 - accuracy: 0.9693 - precision_8: 0.9608 - recall_8: 0.9743 - auc_8: 0.9936\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0700 - accuracy: 0.9737 - precision_8: 0.9633 - recall_8: 0.9813 - auc_8: 0.9970\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0941 - accuracy: 0.9671 - precision_8: 0.9784 - recall_8: 0.9509 - auc_8: 0.9948\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0827 - accuracy: 0.9737 - precision_8: 0.9676 - recall_8: 0.9766 - auc_8: 0.9950\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0725 - accuracy: 0.9847 - precision_8: 0.9748 - recall_8: 0.9930 - auc_8: 0.9929\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0687 - accuracy: 0.9803 - precision_8: 0.9745 - recall_8: 0.9836 - auc_8: 0.9947\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9877 - precision_8: 0.9789 - recall_8: 0.9952 - auc_8: 0.996 - 0s 50ms/step - loss: 0.0556 - accuracy: 0.9880 - precision_8: 0.9793 - recall_8: 0.9953 - auc_8: 0.9965\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0473 - accuracy: 0.9880 - precision_8: 0.9815 - recall_8: 0.9930 - auc_8: 0.9969\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0416 - accuracy: 0.9923 - precision_8: 0.9907 - recall_8: 0.9930 - auc_8: 0.9983\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0432 - accuracy: 0.9836 - precision_8: 0.9747 - recall_8: 0.9907 - auc_8: 0.9991\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0399 - accuracy: 0.9923 - precision_8: 0.9884 - recall_8: 0.9953 - auc_8: 0.9976\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0500 - accuracy: 0.9880 - precision_8: 0.9906 - recall_8: 0.9836 - auc_8: 0.9962\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0528 - accuracy: 0.9836 - precision_8: 0.9725 - recall_8: 0.9930 - auc_8: 0.9969\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0327 - accuracy: 0.9880 - precision_8: 0.9860 - recall_8: 0.9883 - auc_8: 0.9993\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0273 - accuracy: 0.9912 - precision_8: 0.9953 - recall_8: 0.9860 - auc_8: 0.9997\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd7bf2fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7466 - accuracy: 0.5060 - precision_9: 0.4738 - recall_9: 0.4860 - auc_9: 0.4974\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7341 - accuracy: 0.5246 - precision_9: 0.4894 - recall_9: 0.3248 - auc_9: 0.5006\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7193 - accuracy: 0.5192 - precision_9: 0.4804 - recall_9: 0.3154 - auc_9: 0.5171\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7037 - accuracy: 0.5356 - precision_9: 0.5040 - recall_9: 0.5818 - auc_9: 0.5467\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7073 - accuracy: 0.5159 - precision_9: 0.4839 - recall_9: 0.4907 - auc_9: 0.5203: 0s - loss: 0.7078 - accuracy: 0.5130 - precision_9: 0.4717 - recall_9: 0.4958 - auc_9: 0.52\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6976 - accuracy: 0.5235 - precision_9: 0.4912 - recall_9: 0.4579 - auc_9: 0.5464\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6804 - accuracy: 0.5378 - precision_9: 0.5071 - recall_9: 0.5023 - auc_9: 0.5858\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6722 - accuracy: 0.5849 - precision_9: 0.5599 - recall_9: 0.5350 - auc_9: 0.6091\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6524 - accuracy: 0.5783 - precision_9: 0.5558 - recall_9: 0.5000 - auc_9: 0.6371\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6056 - accuracy: 0.6528 - precision_9: 0.6657 - recall_9: 0.5210 - auc_9: 0.7404\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5690 - accuracy: 0.6988 - precision_9: 0.6759 - recall_9: 0.6869 - auc_9: 0.7745\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.4962 - accuracy: 0.7733 - precision_9: 0.7472 - recall_9: 0.7804 - auc_9: 0.8560\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4187 - accuracy: 0.8269 - precision_9: 0.8184 - recall_9: 0.8107 - auc_9: 0.9096\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.3400 - accuracy: 0.8850 - precision_9: 0.8696 - recall_9: 0.8879 - auc_9: 0.9368\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2908 - accuracy: 0.8927 - precision_9: 0.8802 - recall_9: 0.8925 - auc_9: 0.9531\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2727 - accuracy: 0.9047 - precision_9: 0.8559 - recall_9: 0.9579 - auc_9: 0.9558\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2141 - accuracy: 0.9266 - precision_9: 0.9056 - recall_9: 0.9416 - auc_9: 0.9702\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2140 - accuracy: 0.9179 - precision_9: 0.9057 - recall_9: 0.9206 - auc_9: 0.9715\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2122 - accuracy: 0.9200 - precision_9: 0.9025 - recall_9: 0.9299 - auc_9: 0.9698\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1660 - accuracy: 0.9398 - precision_9: 0.9287 - recall_9: 0.9439 - auc_9: 0.9812\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1702 - accuracy: 0.9387 - precision_9: 0.9247 - recall_9: 0.9463 - auc_9: 0.9795\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1283 - accuracy: 0.9529 - precision_9: 0.9326 - recall_9: 0.9696 - auc_9: 0.9898\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1291 - accuracy: 0.9562 - precision_9: 0.9554 - recall_9: 0.9509 - auc_9: 0.9876\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1264 - accuracy: 0.9507 - precision_9: 0.9485 - recall_9: 0.9463 - auc_9: 0.9901\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0876 - accuracy: 0.9726 - precision_9: 0.9569 - recall_9: 0.9860 - auc_9: 0.9961\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0712 - accuracy: 0.9759 - precision_9: 0.9743 - recall_9: 0.9743 - auc_9: 0.9974\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0589 - accuracy: 0.9814 - precision_9: 0.9724 - recall_9: 0.9883 - auc_9: 0.9979\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0815 - accuracy: 0.9715 - precision_9: 0.9674 - recall_9: 0.9720 - auc_9: 0.9952\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1138 - accuracy: 0.9518 - precision_9: 0.9174 - recall_9: 0.9860 - auc_9: 0.9947\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1467 - accuracy: 0.9441 - precision_9: 0.8985 - recall_9: 0.9930 - auc_9: 0.9900\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1372 - accuracy: 0.9452 - precision_9: 0.9655 - recall_9: 0.9159 - auc_9: 0.9920\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.1204 - accuracy: 0.9496 - precision_9: 0.9484 - recall_9: 0.9439 - auc_9: 0.9922\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1285 - accuracy: 0.9496 - precision_9: 0.9321 - recall_9: 0.9626 - auc_9: 0.9888\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.1178 - accuracy: 0.9573 - precision_9: 0.9534 - recall_9: 0.9556 - auc_9: 0.9908\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0893 - accuracy: 0.9682 - precision_9: 0.9607 - recall_9: 0.9720 - auc_9: 0.9961\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0704 - accuracy: 0.9869 - precision_9: 0.9837 - recall_9: 0.9883 - auc_9: 0.9964\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0721 - accuracy: 0.9726 - precision_9: 0.9590 - recall_9: 0.9836 - auc_9: 0.9967\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0704 - accuracy: 0.9770 - precision_9: 0.9811 - recall_9: 0.9696 - auc_9: 0.9967\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0598 - accuracy: 0.9825 - precision_9: 0.9769 - recall_9: 0.9860 - auc_9: 0.9977\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0589 - accuracy: 0.9792 - precision_9: 0.9789 - recall_9: 0.9766 - auc_9: 0.9973\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0506 - accuracy: 0.9781 - precision_9: 0.9658 - recall_9: 0.9883 - auc_9: 0.9985\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0416 - accuracy: 0.9901 - precision_9: 0.9929 - recall_9: 0.9860 - auc_9: 0.9985\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0652 - accuracy: 0.9792 - precision_9: 0.9596 - recall_9: 0.9977 - auc_9: 0.9986\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0459 - accuracy: 0.9825 - precision_9: 0.9882 - recall_9: 0.9743 - auc_9: 0.9991\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0458 - accuracy: 0.9858 - precision_9: 0.9770 - recall_9: 0.9930 - auc_9: 0.9972\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0406 - accuracy: 0.9890 - precision_9: 0.9860 - recall_9: 0.9907 - auc_9: 0.9988\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0595 - accuracy: 0.9814 - precision_9: 0.9813 - recall_9: 0.9790 - auc_9: 0.9971\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0405 - accuracy: 0.9858 - precision_9: 0.9748 - recall_9: 0.9953 - auc_9: 0.9992: 0s - loss: 0.0353 - accuracy: 0.9896 - precision_9: 0.9794 - recall_9: 1.0000 - auc_9: 0\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0471 - accuracy: 0.9792 - precision_9: 0.9881 - recall_9: 0.9673 - auc_9: 0.9991\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0386 - accuracy: 0.9847 - precision_9: 0.9770 - recall_9: 0.9907 - auc_9: 0.9989\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd9ca09a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 68.734% (+/-7.039) \n",
      " Precision: 61.607% (+/-11.186) \n",
      " Recall: 52.273% (+/-25.430) \n",
      " AUC: 78.134% (+/-7.424) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3),input_shape=(None,n_length,n_features)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7762 - accuracy: 0.5279 - precision_10: 0.4963 - recall_10: 0.4696 - auc_10: 0.5148\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7192 - accuracy: 0.5498 - precision_10: 0.5191 - recall_10: 0.5397 - auc_10: 0.5525\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6814 - accuracy: 0.5871 - precision_10: 0.5726 - recall_10: 0.4696 - auc_10: 0.6133\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6611 - accuracy: 0.5849 - precision_10: 0.5525 - recall_10: 0.6028 - auc_10: 0.6278\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6618 - accuracy: 0.5772 - precision_10: 0.5449 - recall_10: 0.5958 - auc_10: 0.6239\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6223 - accuracy: 0.6342 - precision_10: 0.6211 - recall_10: 0.5631 - auc_10: 0.6995\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6107 - accuracy: 0.6320 - precision_10: 0.6150 - recall_10: 0.5748 - auc_10: 0.7099\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.5453 - accuracy: 0.6988 - precision_10: 0.6800 - recall_10: 0.6752 - auc_10: 0.7896\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.5451 - accuracy: 0.7119 - precision_10: 0.6492 - recall_10: 0.8388 - auc_10: 0.8038\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5160 - accuracy: 0.7503 - precision_10: 0.7008 - recall_10: 0.8154 - auc_10: 0.8265\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5160 - accuracy: 0.7295 - precision_10: 0.7718 - recall_10: 0.6005 - auc_10: 0.8358\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.5009 - accuracy: 0.7558 - precision_10: 0.6967 - recall_10: 0.8481 - auc_10: 0.8362\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.4467 - accuracy: 0.7952 - precision_10: 0.7434 - recall_10: 0.8598 - auc_10: 0.8723\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.4481 - accuracy: 0.7853 - precision_10: 0.8169 - recall_10: 0.6986 - auc_10: 0.8813\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.4006 - accuracy: 0.8280 - precision_10: 0.8059 - recall_10: 0.8341 - auc_10: 0.9003\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3641 - accuracy: 0.8478 - precision_10: 0.8055 - recall_10: 0.8902 - auc_10: 0.9214\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3317 - accuracy: 0.8740 - precision_10: 0.8789 - recall_10: 0.8481 - auc_10: 0.9351\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3428 - accuracy: 0.8456 - precision_10: 0.7652 - recall_10: 0.9673 - auc_10: 0.9375\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2844 - accuracy: 0.9014 - precision_10: 0.9183 - recall_10: 0.8668 - auc_10: 0.9553\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2336 - accuracy: 0.9124 - precision_10: 0.8783 - recall_10: 0.9439 - auc_10: 0.9667\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.2259 - accuracy: 0.9200 - precision_10: 0.9025 - recall_10: 0.9299 - auc_10: 0.9675\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1999 - accuracy: 0.9332 - precision_10: 0.9069 - recall_10: 0.9556 - auc_10: 0.9736\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1778 - accuracy: 0.9409 - precision_10: 0.9137 - recall_10: 0.9650 - auc_10: 0.9797\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1929 - accuracy: 0.9321 - precision_10: 0.9316 - recall_10: 0.9229 - auc_10: 0.9752\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1936 - accuracy: 0.9354 - precision_10: 0.9556 - recall_10: 0.9042 - auc_10: 0.9788\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2159 - accuracy: 0.9157 - precision_10: 0.8726 - recall_10: 0.9603 - auc_10: 0.9741\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1870 - accuracy: 0.9310 - precision_10: 0.9314 - recall_10: 0.9206 - auc_10: 0.9785\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1615 - accuracy: 0.9441 - precision_10: 0.9456 - recall_10: 0.9346 - auc_10: 0.9841\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1914 - accuracy: 0.9277 - precision_10: 0.8901 - recall_10: 0.9650 - auc_10: 0.9784\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1443 - accuracy: 0.9463 - precision_10: 0.9523 - recall_10: 0.9322 - auc_10: 0.9865\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1245 - accuracy: 0.9606 - precision_10: 0.9558 - recall_10: 0.9603 - auc_10: 0.9889\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1319 - accuracy: 0.9441 - precision_10: 0.9054 - recall_10: 0.9836 - auc_10: 0.9896\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.1297 - accuracy: 0.9606 - precision_10: 0.9558 - recall_10: 0.9603 - auc_10: 0.9875\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1177 - accuracy: 0.9628 - precision_10: 0.9498 - recall_10: 0.9720 - auc_10: 0.9907\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.1035 - accuracy: 0.9748 - precision_10: 0.9698 - recall_10: 0.9766 - auc_10: 0.9887\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0714 - accuracy: 0.9792 - precision_10: 0.9680 - recall_10: 0.9883 - auc_10: 0.9949\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0767 - accuracy: 0.9759 - precision_10: 0.9765 - recall_10: 0.9720 - auc_10: 0.9940\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.1076 - accuracy: 0.9682 - precision_10: 0.9404 - recall_10: 0.9953 - auc_10: 0.9919\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.1143 - accuracy: 0.9628 - precision_10: 0.9782 - recall_10: 0.9416 - auc_10: 0.9925\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1032 - accuracy: 0.9650 - precision_10: 0.9400 - recall_10: 0.9883 - auc_10: 0.9931\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0792 - accuracy: 0.9759 - precision_10: 0.9810 - recall_10: 0.9673 - auc_10: 0.9936\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0674 - accuracy: 0.9759 - precision_10: 0.9635 - recall_10: 0.9860 - auc_10: 0.9961\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0641 - accuracy: 0.9803 - precision_10: 0.9638 - recall_10: 0.9953 - auc_10: 0.9962\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0734 - accuracy: 0.9836 - precision_10: 0.9905 - recall_10: 0.9743 - auc_10: 0.9948\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0610 - accuracy: 0.9858 - precision_10: 0.9792 - recall_10: 0.9907 - auc_10: 0.9965\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0554 - accuracy: 0.9814 - precision_10: 0.9835 - recall_10: 0.9766 - auc_10: 0.9971\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0419 - accuracy: 0.9880 - precision_10: 0.9771 - recall_10: 0.9977 - auc_10: 0.9989\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0394 - accuracy: 0.9901 - precision_10: 0.9883 - recall_10: 0.9907 - auc_10: 0.9978\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0475 - accuracy: 0.9836 - precision_10: 0.9769 - recall_10: 0.9883 - auc_10: 0.9978\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0415 - accuracy: 0.9880 - precision_10: 0.9793 - recall_10: 0.9953 - auc_10: 0.9988\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd9ca09950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/8 [======>.......................] - ETA: 0s - loss: 0.8390 - accuracy: 0.4570 - precision_11: 0.4483 - recall_11: 0.5242 - auc_11: 0.4582WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0513s vs `on_train_batch_end` time: 0.0972s). Check your callbacks.\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.8029 - accuracy: 0.4995 - precision_11: 0.4645 - recall_11: 0.4439 - auc_11: 0.4949\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.7193 - accuracy: 0.5455 - precision_11: 0.5164 - recall_11: 0.4790 - auc_11: 0.5608\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.7321 - accuracy: 0.5214 - precision_11: 0.4889 - recall_11: 0.4650 - auc_11: 0.5371\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.7005 - accuracy: 0.5630 - precision_11: 0.5420 - recall_11: 0.4369 - auc_11: 0.5894\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.6805 - accuracy: 0.5827 - precision_11: 0.5491 - recall_11: 0.6145 - auc_11: 0.6193\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.6564 - accuracy: 0.5969 - precision_11: 0.5888 - recall_11: 0.4650 - auc_11: 0.6526\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.5867 - accuracy: 0.6802 - precision_11: 0.6868 - recall_11: 0.5841 - auc_11: 0.7579\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.5162 - accuracy: 0.7590 - precision_11: 0.7385 - recall_11: 0.7523 - auc_11: 0.8284\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.4839 - accuracy: 0.7809 - precision_11: 0.7478 - recall_11: 0.8037 - auc_11: 0.8534\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 134ms/step - loss: 0.3897 - accuracy: 0.8204 - precision_11: 0.7845 - recall_11: 0.8505 - auc_11: 0.9141\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.3086 - accuracy: 0.8697 - precision_11: 0.8853 - recall_11: 0.8294 - auc_11: 0.9477\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.2824 - accuracy: 0.8916 - precision_11: 0.9042 - recall_11: 0.8598 - auc_11: 0.9530\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.2524 - accuracy: 0.9080 - precision_11: 0.8822 - recall_11: 0.9276 - auc_11: 0.9621\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.1744 - accuracy: 0.9354 - precision_11: 0.9403 - recall_11: 0.9206 - auc_11: 0.9831\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.1908 - accuracy: 0.9310 - precision_11: 0.9506 - recall_11: 0.8995 - auc_11: 0.9801\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.1638 - accuracy: 0.9529 - precision_11: 0.9487 - recall_11: 0.9509 - auc_11: 0.9820\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.1578 - accuracy: 0.9441 - precision_11: 0.9477 - recall_11: 0.9322 - auc_11: 0.9850\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.1307 - accuracy: 0.9518 - precision_11: 0.9384 - recall_11: 0.9603 - auc_11: 0.9895\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.1463 - accuracy: 0.9507 - precision_11: 0.9485 - recall_11: 0.9463 - auc_11: 0.9855\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.1272 - accuracy: 0.9562 - precision_11: 0.9512 - recall_11: 0.9556 - auc_11: 0.9887\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.1168 - accuracy: 0.9639 - precision_11: 0.9478 - recall_11: 0.9766 - auc_11: 0.9909\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1261 - accuracy: 0.9540 - precision_11: 0.9639 - recall_11: 0.9369 - auc_11: 0.9891\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.1555 - accuracy: 0.9507 - precision_11: 0.9637 - recall_11: 0.9299 - auc_11: 0.9842\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.1058 - accuracy: 0.9660 - precision_11: 0.9563 - recall_11: 0.9720 - auc_11: 0.9933\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0976 - accuracy: 0.9671 - precision_11: 0.9693 - recall_11: 0.9603 - auc_11: 0.9937\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0779 - accuracy: 0.9748 - precision_11: 0.9833 - recall_11: 0.9626 - auc_11: 0.9969\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0729 - accuracy: 0.9781 - precision_11: 0.9766 - recall_11: 0.9766 - auc_11: 0.9960\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0605 - accuracy: 0.9803 - precision_11: 0.9835 - recall_11: 0.9743 - auc_11: 0.9966\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0574 - accuracy: 0.9836 - precision_11: 0.9747 - recall_11: 0.9907 - auc_11: 0.9971\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.0837 - accuracy: 0.9726 - precision_11: 0.9764 - recall_11: 0.9650 - auc_11: 0.9950\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.0726 - accuracy: 0.9737 - precision_11: 0.9698 - recall_11: 0.9743 - auc_11: 0.9969\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0779 - accuracy: 0.9715 - precision_11: 0.9653 - recall_11: 0.9743 - auc_11: 0.9963\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0662 - accuracy: 0.9737 - precision_11: 0.9833 - recall_11: 0.9603 - auc_11: 0.9978\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0622 - accuracy: 0.9792 - precision_11: 0.9881 - recall_11: 0.9673 - auc_11: 0.9980\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0688 - accuracy: 0.9726 - precision_11: 0.9590 - recall_11: 0.9836 - auc_11: 0.9981\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0744 - accuracy: 0.9726 - precision_11: 0.9809 - recall_11: 0.9603 - auc_11: 0.9966\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0807 - accuracy: 0.9682 - precision_11: 0.9483 - recall_11: 0.9860 - auc_11: 0.9961\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0878 - accuracy: 0.9704 - precision_11: 0.9878 - recall_11: 0.9486 - auc_11: 0.9961\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0692 - accuracy: 0.9748 - precision_11: 0.9613 - recall_11: 0.9860 - auc_11: 0.9975\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0611 - accuracy: 0.9803 - precision_11: 0.9724 - recall_11: 0.9860 - auc_11: 0.9968\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0628 - accuracy: 0.9803 - precision_11: 0.9904 - recall_11: 0.9673 - auc_11: 0.9978\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0441 - accuracy: 0.9858 - precision_11: 0.9792 - recall_11: 0.9907 - auc_11: 0.9991\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0388 - accuracy: 0.9890 - precision_11: 0.9906 - recall_11: 0.9860 - auc_11: 0.9982\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0326 - accuracy: 0.9880 - precision_11: 0.9883 - recall_11: 0.9860 - auc_11: 0.9995\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0374 - accuracy: 0.9880 - precision_11: 0.9906 - recall_11: 0.9836 - auc_11: 0.9993\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0239 - accuracy: 0.9934 - precision_11: 0.9930 - recall_11: 0.9930 - auc_11: 0.9998\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0277 - accuracy: 0.9934 - precision_11: 0.9907 - recall_11: 0.9953 - auc_11: 0.9994\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0252 - accuracy: 0.9912 - precision_11: 0.9953 - recall_11: 0.9860 - auc_11: 0.9997\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0268 - accuracy: 0.9912 - precision_11: 0.9930 - recall_11: 0.9883 - auc_11: 0.9996\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0181 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 0.9998\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd7c7738c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.8414 - accuracy: 0.4885 - precision_12: 0.4651 - recall_12: 0.6075 - auc_12: 0.5001\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.7449 - accuracy: 0.5411 - precision_12: 0.5213 - recall_12: 0.2570 - auc_12: 0.5393\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.7342 - accuracy: 0.5301 - precision_12: 0.4990 - recall_12: 0.5607 - auc_12: 0.5354\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.7203 - accuracy: 0.5531 - precision_12: 0.5214 - recall_12: 0.5701 - auc_12: 0.5473\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.7183 - accuracy: 0.5301 - precision_12: 0.4981 - recall_12: 0.3061 - auc_12: 0.5502\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.6957 - accuracy: 0.5630 - precision_12: 0.5326 - recall_12: 0.5537 - auc_12: 0.5834\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.7076 - accuracy: 0.5564 - precision_12: 0.5317 - recall_12: 0.4509 - auc_12: 0.5683\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.6856 - accuracy: 0.5706 - precision_12: 0.5508 - recall_12: 0.4556 - auc_12: 0.5986\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.6827 - accuracy: 0.5882 - precision_12: 0.5778 - recall_12: 0.4509 - auc_12: 0.6125\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.6963 - accuracy: 0.5706 - precision_12: 0.5738 - recall_12: 0.3271 - auc_12: 0.6074\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6979 - accuracy: 0.5608 - precision_12: 0.5313 - recall_12: 0.5350 - auc_12: 0.5892\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6621 - accuracy: 0.6046 - precision_12: 0.5633 - recall_12: 0.6963 - auc_12: 0.6492\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.5997 - accuracy: 0.6966 - precision_12: 0.6931 - recall_12: 0.6332 - auc_12: 0.7532\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.5669 - accuracy: 0.7306 - precision_12: 0.7209 - recall_12: 0.6939 - auc_12: 0.7808\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6105 - accuracy: 0.6769 - precision_12: 0.6852 - recall_12: 0.5748 - auc_12: 0.7340\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.6257 - accuracy: 0.6451 - precision_12: 0.6215 - recall_12: 0.6215 - auc_12: 0.7046\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6153 - accuracy: 0.6605 - precision_12: 0.6513 - recall_12: 0.5935 - auc_12: 0.7288\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.5173 - accuracy: 0.7711 - precision_12: 0.7267 - recall_12: 0.8201 - auc_12: 0.8260\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.4587 - accuracy: 0.7952 - precision_12: 0.8066 - recall_12: 0.7407 - auc_12: 0.8757\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.4009 - accuracy: 0.8532 - precision_12: 0.8419 - recall_12: 0.8458 - auc_12: 0.9067\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3868 - accuracy: 0.8412 - precision_12: 0.8209 - recall_12: 0.8458 - auc_12: 0.9094\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.3390 - accuracy: 0.8719 - precision_12: 0.8783 - recall_12: 0.8435 - auc_12: 0.9330\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3475 - accuracy: 0.8598 - precision_12: 0.7799 - recall_12: 0.9766 - auc_12: 0.9327\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2980 - accuracy: 0.8949 - precision_12: 0.9010 - recall_12: 0.8715 - auc_12: 0.9517\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2466 - accuracy: 0.9157 - precision_12: 0.8710 - recall_12: 0.9626 - auc_12: 0.9625\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2749 - accuracy: 0.9102 - precision_12: 0.9199 - recall_12: 0.8855 - auc_12: 0.9543\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.1947 - accuracy: 0.9376 - precision_12: 0.9150 - recall_12: 0.9556 - auc_12: 0.9745\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2081 - accuracy: 0.9255 - precision_12: 0.9412 - recall_12: 0.8972 - auc_12: 0.9732\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2219 - accuracy: 0.9179 - precision_12: 0.8896 - recall_12: 0.9416 - auc_12: 0.9698\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1955 - accuracy: 0.9387 - precision_12: 0.9604 - recall_12: 0.9065 - auc_12: 0.9780\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1668 - accuracy: 0.9419 - precision_12: 0.9067 - recall_12: 0.9766 - auc_12: 0.9833\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1365 - accuracy: 0.9606 - precision_12: 0.9645 - recall_12: 0.9509 - auc_12: 0.9872\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1228 - accuracy: 0.9540 - precision_12: 0.9327 - recall_12: 0.9720 - auc_12: 0.9907 0s - loss: 0.1241 - accuracy: 0.9547 - precision_12: 0.9344 - recall_12: 0.9739 - auc_12: \n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1299 - accuracy: 0.9518 - precision_12: 0.9384 - recall_12: 0.9603 - auc_12: 0.9884\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1081 - accuracy: 0.9639 - precision_12: 0.9418 - recall_12: 0.9836 - auc_12: 0.9937\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1239 - accuracy: 0.9540 - precision_12: 0.9707 - recall_12: 0.9299 - auc_12: 0.9903\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1224 - accuracy: 0.9540 - precision_12: 0.9251 - recall_12: 0.9813 - auc_12: 0.9919\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0952 - accuracy: 0.9737 - precision_12: 0.9833 - recall_12: 0.9603 - auc_12: 0.9936\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0844 - accuracy: 0.9781 - precision_12: 0.9766 - recall_12: 0.9766 - auc_12: 0.9958\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0995 - accuracy: 0.9639 - precision_12: 0.9582 - recall_12: 0.9650 - auc_12: 0.9943\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0972 - accuracy: 0.9660 - precision_12: 0.9715 - recall_12: 0.9556 - auc_12: 0.9929\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0811 - accuracy: 0.9748 - precision_12: 0.9698 - recall_12: 0.9766 - auc_12: 0.9949\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0965 - accuracy: 0.9693 - precision_12: 0.9566 - recall_12: 0.9790 - auc_12: 0.9930\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0998 - accuracy: 0.9617 - precision_12: 0.9396 - recall_12: 0.9813 - auc_12: 0.9936\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0868 - accuracy: 0.9726 - precision_12: 0.9675 - recall_12: 0.9743 - auc_12: 0.9944\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0810 - accuracy: 0.9704 - precision_12: 0.9652 - recall_12: 0.9720 - auc_12: 0.9958\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0787 - accuracy: 0.9726 - precision_12: 0.9741 - recall_12: 0.9673 - auc_12: 0.9958\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0986 - accuracy: 0.9715 - precision_12: 0.9548 - recall_12: 0.9860 - auc_12: 0.9940\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1241 - accuracy: 0.9606 - precision_12: 0.9876 - recall_12: 0.9276 - auc_12: 0.9907\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1213 - accuracy: 0.9485 - precision_12: 0.9062 - recall_12: 0.9930 - auc_12: 0.9937\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd7b7209d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.7760 - accuracy: 0.5356 - precision_13: 0.5051 - recall_13: 0.4673 - auc_13: 0.5368\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.7350 - accuracy: 0.5268 - precision_13: 0.4954 - recall_13: 0.5070 - auc_13: 0.5468\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.7069 - accuracy: 0.5444 - precision_13: 0.5159 - recall_13: 0.4556 - auc_13: 0.5783\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6759 - accuracy: 0.5827 - precision_13: 0.5580 - recall_13: 0.5280 - auc_13: 0.6317\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6518 - accuracy: 0.6112 - precision_13: 0.5863 - recall_13: 0.5794 - auc_13: 0.6673\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.6220 - accuracy: 0.6484 - precision_13: 0.6321 - recall_13: 0.5981 - auc_13: 0.7100\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.5692 - accuracy: 0.7054 - precision_13: 0.7023 - recall_13: 0.6449 - auc_13: 0.7692\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.5029 - accuracy: 0.7579 - precision_13: 0.8439 - recall_13: 0.5935 - auc_13: 0.8540\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.4377 - accuracy: 0.7974 - precision_13: 0.7341 - recall_13: 0.8902 - auc_13: 0.8990\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.3647 - accuracy: 0.8532 - precision_13: 0.8639 - recall_13: 0.8154 - auc_13: 0.9218\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.3344 - accuracy: 0.8587 - precision_13: 0.8518 - recall_13: 0.8458 - auc_13: 0.9331\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.3287 - accuracy: 0.8565 - precision_13: 0.8367 - recall_13: 0.8621 - auc_13: 0.9354\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.3170 - accuracy: 0.8697 - precision_13: 0.8892 - recall_13: 0.8248 - auc_13: 0.9392\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2541 - accuracy: 0.9168 - precision_13: 0.9074 - recall_13: 0.9159 - auc_13: 0.9595\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2196 - accuracy: 0.9244 - precision_13: 0.9567 - recall_13: 0.8785 - auc_13: 0.9728\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2535 - accuracy: 0.9113 - precision_13: 0.8899 - recall_13: 0.9252 - auc_13: 0.9591\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2210 - accuracy: 0.9146 - precision_13: 0.8855 - recall_13: 0.9393 - auc_13: 0.9716\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2540 - accuracy: 0.8981 - precision_13: 0.9017 - recall_13: 0.8785 - auc_13: 0.9610\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2212 - accuracy: 0.9157 - precision_13: 0.9270 - recall_13: 0.8902 - auc_13: 0.9705\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.1864 - accuracy: 0.9343 - precision_13: 0.9279 - recall_13: 0.9322 - auc_13: 0.9785\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.2062 - accuracy: 0.9124 - precision_13: 0.9328 - recall_13: 0.8762 - auc_13: 0.9762\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1685 - accuracy: 0.9441 - precision_13: 0.9415 - recall_13: 0.9393 - auc_13: 0.9821\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1833 - accuracy: 0.9441 - precision_13: 0.9654 - recall_13: 0.9136 - auc_13: 0.9771\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2446 - accuracy: 0.9047 - precision_13: 0.8545 - recall_13: 0.9603 - auc_13: 0.9742\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1681 - accuracy: 0.9419 - precision_13: 0.9607 - recall_13: 0.9136 - auc_13: 0.9821\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1428 - accuracy: 0.9507 - precision_13: 0.9464 - recall_13: 0.9486 - auc_13: 0.9870\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1446 - accuracy: 0.9474 - precision_13: 0.9774 - recall_13: 0.9089 - auc_13: 0.9864\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1518 - accuracy: 0.9452 - precision_13: 0.9219 - recall_13: 0.9650 - auc_13: 0.9872\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.1278 - accuracy: 0.9595 - precision_13: 0.9780 - recall_13: 0.9346 - auc_13: 0.9903\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1547 - accuracy: 0.9496 - precision_13: 0.9134 - recall_13: 0.9860 - auc_13: 0.9856\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1447 - accuracy: 0.9518 - precision_13: 0.9824 - recall_13: 0.9136 - auc_13: 0.9908\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0970 - accuracy: 0.9704 - precision_13: 0.9526 - recall_13: 0.9860 - auc_13: 0.9962\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1000 - accuracy: 0.9606 - precision_13: 0.9623 - recall_13: 0.9533 - auc_13: 0.9945\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0859 - accuracy: 0.9781 - precision_13: 0.9766 - recall_13: 0.9766 - auc_13: 0.9937\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0785 - accuracy: 0.9770 - precision_13: 0.9700 - recall_13: 0.9813 - auc_13: 0.9953\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0829 - accuracy: 0.9715 - precision_13: 0.9763 - recall_13: 0.9626 - auc_13: 0.9961\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0856 - accuracy: 0.9693 - precision_13: 0.9785 - recall_13: 0.9556 - auc_13: 0.9961\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0951 - accuracy: 0.9693 - precision_13: 0.9739 - recall_13: 0.9603 - auc_13: 0.9945\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0892 - accuracy: 0.9693 - precision_13: 0.9695 - recall_13: 0.9650 - auc_13: 0.9947\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1148 - accuracy: 0.9573 - precision_13: 0.9779 - recall_13: 0.9299 - auc_13: 0.9929\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0886 - accuracy: 0.9693 - precision_13: 0.9444 - recall_13: 0.9930 - auc_13: 0.9950\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0636 - accuracy: 0.9792 - precision_13: 0.9857 - recall_13: 0.9696 - auc_13: 0.9969\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0618 - accuracy: 0.9770 - precision_13: 0.9722 - recall_13: 0.9790 - auc_13: 0.9968\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0527 - accuracy: 0.9847 - precision_13: 0.9792 - recall_13: 0.9883 - auc_13: 0.9974\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0589 - accuracy: 0.9825 - precision_13: 0.9928 - recall_13: 0.9696 - auc_13: 0.9970\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0538 - accuracy: 0.9847 - precision_13: 0.9836 - recall_13: 0.9836 - auc_13: 0.9972\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0560 - accuracy: 0.9814 - precision_13: 0.9790 - recall_13: 0.9813 - auc_13: 0.9972\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0357 - accuracy: 0.9912 - precision_13: 0.9976 - recall_13: 0.9836 - auc_13: 0.9992\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0355 - accuracy: 0.9890 - precision_13: 0.9929 - recall_13: 0.9836 - auc_13: 0.9990\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0297 - accuracy: 0.9890 - precision_13: 0.9860 - recall_13: 0.9907 - auc_13: 0.9994\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd9ca4a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.8034 - accuracy: 0.5181 - precision_14: 0.4867 - recall_14: 0.5117 - auc_14: 0.5078\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.7391 - accuracy: 0.5049 - precision_14: 0.4608 - recall_14: 0.3294 - auc_14: 0.5357\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.7514 - accuracy: 0.4929 - precision_14: 0.4655 - recall_14: 0.5514 - auc_14: 0.5094\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.7374 - accuracy: 0.5268 - precision_14: 0.4938 - recall_14: 0.3692 - auc_14: 0.5091\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.7390 - accuracy: 0.5170 - precision_14: 0.4757 - recall_14: 0.2967 - auc_14: 0.4891\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.7320 - accuracy: 0.4885 - precision_14: 0.4499 - recall_14: 0.4089 - auc_14: 0.4882\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.6914 - accuracy: 0.5619 - precision_14: 0.5363 - recall_14: 0.4836 - auc_14: 0.5680\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.6875 - accuracy: 0.5586 - precision_14: 0.5455 - recall_14: 0.3505 - auc_14: 0.5820\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.6744 - accuracy: 0.5717 - precision_14: 0.5481 - recall_14: 0.4930 - auc_14: 0.6118\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6547 - accuracy: 0.6035 - precision_14: 0.5965 - recall_14: 0.4766 - auc_14: 0.6529\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.6297 - accuracy: 0.6364 - precision_14: 0.6188 - recall_14: 0.5841 - auc_14: 0.6904\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.6072 - accuracy: 0.6605 - precision_14: 0.6185 - recall_14: 0.7196 - auc_14: 0.7244\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.5936 - accuracy: 0.6605 - precision_14: 0.6446 - recall_14: 0.6145 - auc_14: 0.7336\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.5724 - accuracy: 0.6451 - precision_14: 0.6711 - recall_14: 0.4766 - auc_14: 0.7717\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.5500 - accuracy: 0.7295 - precision_14: 0.6946 - recall_14: 0.7547 - auc_14: 0.7913\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.5030 - accuracy: 0.7788 - precision_14: 0.7316 - recall_14: 0.8341 - auc_14: 0.8336\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.4661 - accuracy: 0.8007 - precision_14: 0.7365 - recall_14: 0.8949 - auc_14: 0.8555\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3979 - accuracy: 0.8412 - precision_14: 0.8443 - recall_14: 0.8107 - auc_14: 0.9099\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.4877 - accuracy: 0.7798 - precision_14: 0.6852 - recall_14: 0.9813 - auc_14: 0.8706\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.4229 - accuracy: 0.8061 - precision_14: 0.8724 - recall_14: 0.6869 - auc_14: 0.9078\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.4202 - accuracy: 0.8313 - precision_14: 0.7566 - recall_14: 0.9439 - auc_14: 0.8839\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.3530 - accuracy: 0.8719 - precision_14: 0.8463 - recall_14: 0.8879 - auc_14: 0.9190\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3038 - accuracy: 0.8719 - precision_14: 0.8840 - recall_14: 0.8364 - auc_14: 0.9515\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2698 - accuracy: 0.8992 - precision_14: 0.8443 - recall_14: 0.9626 - auc_14: 0.9588\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2289 - accuracy: 0.9168 - precision_14: 0.9093 - recall_14: 0.9136 - auc_14: 0.9683\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2551 - accuracy: 0.9080 - precision_14: 0.8510 - recall_14: 0.9743 - auc_14: 0.9579\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2149 - accuracy: 0.9310 - precision_14: 0.9462 - recall_14: 0.9042 - auc_14: 0.9728\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.1791 - accuracy: 0.9332 - precision_14: 0.9051 - recall_14: 0.9579 - auc_14: 0.9791\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1939 - accuracy: 0.9365 - precision_14: 0.9075 - recall_14: 0.9626 - auc_14: 0.9752\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2267 - accuracy: 0.9146 - precision_14: 0.9510 - recall_14: 0.8621 - auc_14: 0.9757\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2253 - accuracy: 0.9058 - precision_14: 0.8379 - recall_14: 0.9907 - auc_14: 0.9791\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.1522 - accuracy: 0.9463 - precision_14: 0.9611 - recall_14: 0.9229 - auc_14: 0.9876\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1814 - accuracy: 0.9354 - precision_14: 0.8985 - recall_14: 0.9720 - auc_14: 0.9789\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.1282 - accuracy: 0.9540 - precision_14: 0.9386 - recall_14: 0.9650 - auc_14: 0.9898\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.1367 - accuracy: 0.9540 - precision_14: 0.9406 - recall_14: 0.9626 - auc_14: 0.9875\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1261 - accuracy: 0.9518 - precision_14: 0.9550 - recall_14: 0.9416 - auc_14: 0.9905\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1128 - accuracy: 0.9595 - precision_14: 0.9354 - recall_14: 0.9813 - auc_14: 0.9927\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.1187 - accuracy: 0.9584 - precision_14: 0.9665 - recall_14: 0.9439 - auc_14: 0.9904\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1777 - accuracy: 0.9387 - precision_14: 0.9170 - recall_14: 0.9556 - auc_14: 0.9794\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0988 - accuracy: 0.9660 - precision_14: 0.9760 - recall_14: 0.9509 - auc_14: 0.9935\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0890 - accuracy: 0.9693 - precision_14: 0.9651 - recall_14: 0.9696 - auc_14: 0.9951\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0671 - accuracy: 0.9770 - precision_14: 0.9700 - recall_14: 0.9813 - auc_14: 0.9971\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0624 - accuracy: 0.9814 - precision_14: 0.9813 - recall_14: 0.9790 - auc_14: 0.9968\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0737 - accuracy: 0.9770 - precision_14: 0.9615 - recall_14: 0.9907 - auc_14: 0.9961\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.0704 - accuracy: 0.9759 - precision_14: 0.9677 - recall_14: 0.9813 - auc_14: 0.9955\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0513 - accuracy: 0.9880 - precision_14: 0.9906 - recall_14: 0.9836 - auc_14: 0.9973\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0518 - accuracy: 0.9803 - precision_14: 0.9790 - recall_14: 0.9790 - auc_14: 0.9986\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0600 - accuracy: 0.9825 - precision_14: 0.9836 - recall_14: 0.9790 - auc_14: 0.9970\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0854 - accuracy: 0.9781 - precision_14: 0.9766 - recall_14: 0.9766 - auc_14: 0.9927\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0662 - accuracy: 0.9803 - precision_14: 0.9702 - recall_14: 0.9883 - auc_14: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7efd7c3b3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " Accuracy: 72.052% (+/-9.394) \n",
      " Precision: 64.407% (+/-13.100) \n",
      " Recall: 60.682% (+/-12.889) \n",
      " AUC: 81.735% (+/-7.914) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_3(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu'),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='selu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_3(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_3(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_3(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
