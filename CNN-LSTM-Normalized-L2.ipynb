{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 6250, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(accuracies,precisions,recalls,aucs):\n",
    "    m, s = mean(accuracies), std(accuracies)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(precisions), std(precisions)\n",
    "    print( ' Precision: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(recalls), std(recalls)\n",
    "    print( ' Recall: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(aucs), std(aucs)\n",
    "    print( ' AUC: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 10.3305 - accuracy: 0.5082 - precision: 0.4697 - recall: 0.3808 - auc: 0.5082\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 6.0461 - accuracy: 0.5235 - precision: 0.4928 - recall: 0.5631 - auc: 0.5487\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 4.4186 - accuracy: 0.6145 - precision: 0.5760 - recall: 0.6729 - auc: 0.6644\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 3.7836 - accuracy: 0.6725 - precision: 0.6210 - recall: 0.7734 - auc: 0.7352\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.2635 - accuracy: 0.7809 - precision: 0.7579 - recall: 0.7827 - auc: 0.8637\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.8560 - accuracy: 0.8521 - precision: 0.8399 - recall: 0.8458 - auc: 0.9155\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.5407 - accuracy: 0.9189 - precision: 0.9296 - recall: 0.8949 - auc: 0.9650\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.3396 - accuracy: 0.9299 - precision: 0.9233 - recall: 0.9276 - auc: 0.9718\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 2.2389 - accuracy: 0.9069 - precision: 0.9054 - recall: 0.8949 - auc: 0.9619\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.1809 - accuracy: 0.8883 - precision: 0.8559 - recall: 0.9159 - auc: 0.9522\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.0257 - accuracy: 0.9387 - precision: 0.9306 - recall: 0.9393 - auc: 0.9776\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.8886 - accuracy: 0.9507 - precision: 0.9637 - recall: 0.9299 - auc: 0.9836\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.8479 - accuracy: 0.9255 - precision: 0.9128 - recall: 0.9299 - auc: 0.9738\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.7001 - accuracy: 0.9639 - precision: 0.9736 - recall: 0.9486 - auc: 0.9899\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.6253 - accuracy: 0.9595 - precision: 0.9600 - recall: 0.9533 - auc: 0.9881\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.5605 - accuracy: 0.9595 - precision: 0.9688 - recall: 0.9439 - auc: 0.9915\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.5743 - accuracy: 0.9430 - precision: 0.9434 - recall: 0.9346 - auc: 0.9791\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.5177 - accuracy: 0.9584 - precision: 0.9493 - recall: 0.9626 - auc: 0.9856\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.4495 - accuracy: 0.9693 - precision: 0.9717 - recall: 0.9626 - auc: 0.9884\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.3689 - accuracy: 0.9693 - precision: 0.9762 - recall: 0.9579 - auc: 0.9928\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.3211 - accuracy: 0.9726 - precision: 0.9809 - recall: 0.9603 - auc: 0.9915\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.2600 - accuracy: 0.9803 - precision: 0.9835 - recall: 0.9743 - auc: 0.9953\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.2181 - accuracy: 0.9825 - precision: 0.9836 - recall: 0.9790 - auc: 0.9968\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1654 - accuracy: 0.9890 - precision: 0.9929 - recall: 0.9836 - auc: 0.9978\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.1279 - accuracy: 0.9890 - precision: 0.9906 - recall: 0.9860 - auc: 0.9976\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.1559 - accuracy: 0.9781 - precision: 0.9811 - recall: 0.9720 - auc: 0.9952\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.1428 - accuracy: 0.9792 - precision: 0.9789 - recall: 0.9766 - auc: 0.9944\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0928 - accuracy: 0.9858 - precision: 0.9882 - recall: 0.9813 - auc: 0.9970\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.0508 - accuracy: 0.9880 - precision: 0.9906 - recall: 0.9836 - auc: 0.9977\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.9959 - accuracy: 0.9934 - precision: 0.9953 - recall: 0.9907 - auc: 0.9992\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9988 - accuracy: 0.9825 - precision: 0.9791 - recall: 0.9836 - auc: 0.9964\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.1084 - accuracy: 0.9376 - precision: 0.9406 - recall: 0.9252 - auc: 0.9809\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.9968 - accuracy: 0.9890 - precision: 0.9906 - recall: 0.9860 - auc: 0.9973\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9454 - accuracy: 0.9934 - precision: 0.9976 - recall: 0.9883 - auc: 0.9981\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9127 - accuracy: 0.9912 - precision: 0.9930 - recall: 0.9883 - auc: 0.9979\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.8794 - accuracy: 0.9912 - precision: 0.9907 - recall: 0.9907 - auc: 0.9998\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8669 - accuracy: 0.9934 - precision: 0.9953 - recall: 0.9907 - auc: 0.9974\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.8519 - accuracy: 0.9880 - precision: 0.9860 - recall: 0.9883 - auc: 0.9982\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.8311 - accuracy: 0.9945 - precision: 0.9953 - recall: 0.9930 - auc: 0.9990\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.8026 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7877 - accuracy: 0.9956 - precision: 0.9977 - recall: 0.9930 - auc: 0.9995\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.8141 - accuracy: 0.9792 - precision: 0.9701 - recall: 0.9860 - auc: 0.9988\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.8378 - accuracy: 0.9781 - precision: 0.9744 - recall: 0.9790 - auc: 0.9935\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.8054 - accuracy: 0.9825 - precision: 0.9836 - recall: 0.9790 - auc: 0.9982\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7977 - accuracy: 0.9792 - precision: 0.9789 - recall: 0.9766 - auc: 0.9961\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7507 - accuracy: 0.9923 - precision: 0.9953 - recall: 0.9883 - auc: 0.9995\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8240 - accuracy: 0.9639 - precision: 0.9736 - recall: 0.9486 - auc: 0.9939\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8268 - accuracy: 0.9770 - precision: 0.9744 - recall: 0.9766 - auc: 0.9940\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7696 - accuracy: 0.9890 - precision: 0.9883 - recall: 0.9883 - auc: 0.9993\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7473 - accuracy: 0.9869 - precision: 0.9837 - recall: 0.9883 - auc: 0.9987\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 10.2932 - accuracy: 0.5181 - precision_1: 0.4860 - recall_1: 0.4860 - auc_1: 0.5133\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 6.0060 - accuracy: 0.5378 - precision_1: 0.5058 - recall_1: 0.6145 - auc_1: 0.5676\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 4.3906 - accuracy: 0.6396 - precision_1: 0.6143 - recall_1: 0.6215 - auc_1: 0.6672\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 3.7439 - accuracy: 0.6867 - precision_1: 0.6983 - recall_1: 0.5841 - auc_1: 0.7746\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 73ms/step - loss: 3.2426 - accuracy: 0.7678 - precision_1: 0.7160 - recall_1: 0.8364 - auc_1: 0.8533\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.8099 - accuracy: 0.8697 - precision_1: 0.8670 - recall_1: 0.8528 - auc_1: 0.9399\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 2.4980 - accuracy: 0.9168 - precision_1: 0.9000 - recall_1: 0.9252 - auc_1: 0.9673\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.3591 - accuracy: 0.9047 - precision_1: 0.8974 - recall_1: 0.8995 - auc_1: 0.9630\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.3023 - accuracy: 0.8620 - precision_1: 0.8813 - recall_1: 0.8154 - auc_1: 0.9460\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 2.1307 - accuracy: 0.9255 - precision_1: 0.9167 - recall_1: 0.9252 - auc_1: 0.9728\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.0016 - accuracy: 0.9343 - precision_1: 0.9279 - recall_1: 0.9322 - auc_1: 0.9802\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.8595 - accuracy: 0.9485 - precision_1: 0.9339 - recall_1: 0.9579 - auc_1: 0.9883\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.7502 - accuracy: 0.9573 - precision_1: 0.9598 - recall_1: 0.9486 - auc_1: 0.9909\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.6674 - accuracy: 0.9617 - precision_1: 0.9667 - recall_1: 0.9509 - auc_1: 0.9919\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.5803 - accuracy: 0.9737 - precision_1: 0.9810 - recall_1: 0.9626 - auc_1: 0.9948\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4933 - accuracy: 0.9825 - precision_1: 0.9858 - recall_1: 0.9766 - auc_1: 0.9963\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.4330 - accuracy: 0.9792 - precision_1: 0.9812 - recall_1: 0.9743 - auc_1: 0.9964\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3776 - accuracy: 0.9803 - precision_1: 0.9835 - recall_1: 0.9743 - auc_1: 0.9969\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.3587 - accuracy: 0.9737 - precision_1: 0.9720 - recall_1: 0.9720 - auc_1: 0.9934\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.3469 - accuracy: 0.9606 - precision_1: 0.9495 - recall_1: 0.9673 - auc_1: 0.9928\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.3076 - accuracy: 0.9737 - precision_1: 0.9833 - recall_1: 0.9603 - auc_1: 0.9929\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.2516 - accuracy: 0.9770 - precision_1: 0.9788 - recall_1: 0.9720 - auc_1: 0.9952\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.1840 - accuracy: 0.9880 - precision_1: 0.9906 - recall_1: 0.9836 - auc_1: 0.9982\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.1321 - accuracy: 0.9890 - precision_1: 0.9953 - recall_1: 0.9813 - auc_1: 0.9988\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.0989 - accuracy: 0.9901 - precision_1: 0.9953 - recall_1: 0.9836 - auc_1: 0.9983\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2071 - accuracy: 0.9354 - precision_1: 0.9146 - recall_1: 0.9509 - auc_1: 0.9808\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.2299 - accuracy: 0.9211 - precision_1: 0.9258 - recall_1: 0.9042 - auc_1: 0.9750\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1632 - accuracy: 0.9518 - precision_1: 0.9848 - recall_1: 0.9112 - auc_1: 0.9917\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.1480 - accuracy: 0.9573 - precision_1: 0.9492 - recall_1: 0.9603 - auc_1: 0.9860\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.0438 - accuracy: 0.9781 - precision_1: 0.9595 - recall_1: 0.9953 - auc_1: 0.9977\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0096 - accuracy: 0.9803 - precision_1: 0.9904 - recall_1: 0.9673 - auc_1: 0.9968\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9576 - accuracy: 0.9880 - precision_1: 0.9906 - recall_1: 0.9836 - auc_1: 0.9983\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9184 - accuracy: 0.9967 - precision_1: 0.9953 - recall_1: 0.9977 - auc_1: 0.9986\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.8926 - accuracy: 0.9945 - precision_1: 0.9976 - recall_1: 0.9907 - auc_1: 0.9998\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.8737 - accuracy: 0.9934 - precision_1: 0.9930 - recall_1: 0.9930 - auc_1: 0.9995\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.8459 - accuracy: 0.9967 - precision_1: 0.9953 - recall_1: 0.9977 - auc_1: 0.9997\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.8223 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.8051 - accuracy: 0.9989 - precision_1: 0.9977 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7942 - accuracy: 0.9934 - precision_1: 0.9930 - recall_1: 0.9930 - auc_1: 0.9999\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7826 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 0.9999\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.8017 - accuracy: 0.9836 - precision_1: 0.9836 - recall_1: 0.9813 - auc_1: 0.9993\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.8956 - accuracy: 0.9518 - precision_1: 0.9404 - recall_1: 0.9579 - auc_1: 0.9910\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8164 - accuracy: 0.9880 - precision_1: 0.9883 - recall_1: 0.9860 - auc_1: 0.9989\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.7735 - accuracy: 0.9934 - precision_1: 0.9976 - recall_1: 0.9883 - auc_1: 0.9999\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7392 - accuracy: 0.9967 - precision_1: 0.9930 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.7141 - accuracy: 0.9978 - precision_1: 0.9977 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7264 - accuracy: 0.9858 - precision_1: 0.9837 - recall_1: 0.9860 - auc_1: 0.9990\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6946 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6763 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6589 - accuracy: 0.9978 - precision_1: 0.9977 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 10.3481 - accuracy: 0.5476 - precision_2: 0.5182 - recall_2: 0.5000 - auc_2: 0.5366\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 6.0747 - accuracy: 0.5871 - precision_2: 0.5620 - recall_2: 0.5397 - auc_2: 0.6254\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.4093 - accuracy: 0.6867 - precision_2: 0.6599 - recall_2: 0.6846 - auc_2: 0.7565\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 3.7192 - accuracy: 0.7809 - precision_2: 0.7794 - recall_2: 0.7430 - auc_2: 0.8683\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.2703 - accuracy: 0.8226 - precision_2: 0.7681 - recall_2: 0.8902 - auc_2: 0.9029\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.8701 - accuracy: 0.9168 - precision_2: 0.9112 - recall_2: 0.9112 - auc_2: 0.9629\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.6112 - accuracy: 0.9266 - precision_2: 0.9207 - recall_2: 0.9229 - auc_2: 0.9717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.4136 - accuracy: 0.9430 - precision_2: 0.9372 - recall_2: 0.9416 - auc_2: 0.9783\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.2755 - accuracy: 0.9387 - precision_2: 0.9266 - recall_2: 0.9439 - auc_2: 0.9799\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.1604 - accuracy: 0.9365 - precision_2: 0.9243 - recall_2: 0.9416 - auc_2: 0.9851\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.0311 - accuracy: 0.9606 - precision_2: 0.9645 - recall_2: 0.9509 - auc_2: 0.9897\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.9245 - accuracy: 0.9617 - precision_2: 0.9602 - recall_2: 0.9579 - auc_2: 0.9905\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.9295 - accuracy: 0.9288 - precision_2: 0.9481 - recall_2: 0.8972 - auc_2: 0.9742\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 1.8616 - accuracy: 0.9288 - precision_2: 0.9079 - recall_2: 0.9439 - auc_2: 0.9814\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.7364 - accuracy: 0.9650 - precision_2: 0.9626 - recall_2: 0.9626 - auc_2: 0.9919\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.6151 - accuracy: 0.9803 - precision_2: 0.9767 - recall_2: 0.9813 - auc_2: 0.9940\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.5613 - accuracy: 0.9660 - precision_2: 0.9584 - recall_2: 0.9696 - auc_2: 0.9936\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.5724 - accuracy: 0.9507 - precision_2: 0.9402 - recall_2: 0.9556 - auc_2: 0.9841\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.5021 - accuracy: 0.9682 - precision_2: 0.9607 - recall_2: 0.9720 - auc_2: 0.9930\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.4222 - accuracy: 0.9770 - precision_2: 0.9788 - recall_2: 0.9720 - auc_2: 0.9955\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.4287 - accuracy: 0.9540 - precision_2: 0.9531 - recall_2: 0.9486 - auc_2: 0.9886\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.3587 - accuracy: 0.9814 - precision_2: 0.9881 - recall_2: 0.9720 - auc_2: 0.9941\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.3279 - accuracy: 0.9715 - precision_2: 0.9653 - recall_2: 0.9743 - auc_2: 0.9934\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.2530 - accuracy: 0.9880 - precision_2: 0.9929 - recall_2: 0.9813 - auc_2: 0.9984\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.2050 - accuracy: 0.9869 - precision_2: 0.9883 - recall_2: 0.9836 - auc_2: 0.9970\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.1566 - accuracy: 0.9912 - precision_2: 0.9907 - recall_2: 0.9907 - auc_2: 0.9974\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.1203 - accuracy: 0.9912 - precision_2: 0.9930 - recall_2: 0.9883 - auc_2: 0.9981\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0927 - accuracy: 0.9890 - precision_2: 0.9929 - recall_2: 0.9836 - auc_2: 0.9975\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.0990 - accuracy: 0.9836 - precision_2: 0.9836 - recall_2: 0.9813 - auc_2: 0.9932\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.1233 - accuracy: 0.9595 - precision_2: 0.9644 - recall_2: 0.9486 - auc_2: 0.9895\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.0882 - accuracy: 0.9650 - precision_2: 0.9541 - recall_2: 0.9720 - auc_2: 0.9956\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.1081 - accuracy: 0.9595 - precision_2: 0.9494 - recall_2: 0.9650 - auc_2: 0.9905\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.0452 - accuracy: 0.9858 - precision_2: 0.9814 - recall_2: 0.9883 - auc_2: 0.9974\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0012 - accuracy: 0.9869 - precision_2: 0.9860 - recall_2: 0.9860 - auc_2: 0.9967\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9573 - accuracy: 0.9934 - precision_2: 0.9976 - recall_2: 0.9883 - auc_2: 0.9982\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.9213 - accuracy: 0.9945 - precision_2: 0.9953 - recall_2: 0.9930 - auc_2: 0.9991\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.8985 - accuracy: 0.9923 - precision_2: 0.9930 - recall_2: 0.9907 - auc_2: 0.9987\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.8733 - accuracy: 0.9978 - precision_2: 1.0000 - recall_2: 0.9953 - auc_2: 0.9993\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.9083 - accuracy: 0.9726 - precision_2: 0.9675 - recall_2: 0.9743 - auc_2: 0.9965\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.1234 - accuracy: 0.9036 - precision_2: 0.8744 - recall_2: 0.9276 - auc_2: 0.9557\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0663 - accuracy: 0.9540 - precision_2: 0.9427 - recall_2: 0.9603 - auc_2: 0.9885\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9748 - accuracy: 0.9814 - precision_2: 0.9746 - recall_2: 0.9860 - auc_2: 0.9969\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.9175 - accuracy: 0.9847 - precision_2: 0.9882 - recall_2: 0.9790 - auc_2: 0.9966\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.8788 - accuracy: 0.9869 - precision_2: 1.0000 - recall_2: 0.9720 - auc_2: 0.9953\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.8473 - accuracy: 0.9814 - precision_2: 0.9813 - recall_2: 0.9790 - auc_2: 0.9976\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.8111 - accuracy: 0.9890 - precision_2: 0.9860 - recall_2: 0.9907 - auc_2: 0.9984\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.8204 - accuracy: 0.9759 - precision_2: 0.9743 - recall_2: 0.9743 - auc_2: 0.9946\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7760 - accuracy: 0.9869 - precision_2: 0.9976 - recall_2: 0.9743 - auc_2: 0.9986\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7568 - accuracy: 0.9912 - precision_2: 0.9884 - recall_2: 0.9930 - auc_2: 0.9986\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.7254 - accuracy: 0.9945 - precision_2: 0.9953 - recall_2: 0.9930 - auc_2: 0.9996\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 10.1293 - accuracy: 0.5597 - precision_3: 0.5394 - recall_3: 0.4159 - auc_3: 0.5894\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 5.8554 - accuracy: 0.6670 - precision_3: 0.6216 - recall_3: 0.7407 - auc_3: 0.7120\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 4.3029 - accuracy: 0.7503 - precision_3: 0.7283 - recall_3: 0.7453 - auc_3: 0.8333\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 3.6766 - accuracy: 0.8050 - precision_3: 0.7694 - recall_3: 0.8341 - auc_3: 0.8883\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 3.1737 - accuracy: 0.8817 - precision_3: 0.8604 - recall_3: 0.8925 - auc_3: 0.9547\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.8313 - accuracy: 0.9025 - precision_3: 0.9104 - recall_3: 0.8785 - auc_3: 0.9627\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.5930 - accuracy: 0.9113 - precision_3: 0.8864 - recall_3: 0.9299 - auc_3: 0.9726\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 2.3960 - accuracy: 0.9441 - precision_3: 0.9435 - recall_3: 0.9369 - auc_3: 0.9790\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.3471 - accuracy: 0.8828 - precision_3: 0.8607 - recall_3: 0.8949 - auc_3: 0.9566\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 51ms/step - loss: 2.1574 - accuracy: 0.9452 - precision_3: 0.9543 - recall_3: 0.9276 - auc_3: 0.9847\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 2.0412 - accuracy: 0.9485 - precision_3: 0.9568 - recall_3: 0.9322 - auc_3: 0.9835\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.9066 - accuracy: 0.9639 - precision_3: 0.9540 - recall_3: 0.9696 - auc_3: 0.9902\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.8132 - accuracy: 0.9682 - precision_3: 0.9650 - recall_3: 0.9673 - auc_3: 0.9917\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.7533 - accuracy: 0.9595 - precision_3: 0.9515 - recall_3: 0.9626 - auc_3: 0.9898\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.7113 - accuracy: 0.9573 - precision_3: 0.9534 - recall_3: 0.9556 - auc_3: 0.9882\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.6329 - accuracy: 0.9715 - precision_3: 0.9718 - recall_3: 0.9673 - auc_3: 0.9938\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.5420 - accuracy: 0.9792 - precision_3: 0.9745 - recall_3: 0.9813 - auc_3: 0.9949\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.4567 - accuracy: 0.9836 - precision_3: 0.9814 - recall_3: 0.9836 - auc_3: 0.9975\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.3850 - accuracy: 0.9901 - precision_3: 0.9883 - recall_3: 0.9907 - auc_3: 0.9981\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.4086 - accuracy: 0.9671 - precision_3: 0.9543 - recall_3: 0.9766 - auc_3: 0.9903\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.3658 - accuracy: 0.9759 - precision_3: 0.9856 - recall_3: 0.9626 - auc_3: 0.9954\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.4409 - accuracy: 0.9288 - precision_3: 0.9024 - recall_3: 0.9509 - auc_3: 0.9768\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.4119 - accuracy: 0.9310 - precision_3: 0.9274 - recall_3: 0.9252 - auc_3: 0.9797\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.2922 - accuracy: 0.9759 - precision_3: 0.9903 - recall_3: 0.9579 - auc_3: 0.9939\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.2218 - accuracy: 0.9858 - precision_3: 0.9905 - recall_3: 0.9790 - auc_3: 0.9980\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.2165 - accuracy: 0.9803 - precision_3: 0.9745 - recall_3: 0.9836 - auc_3: 0.9961\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.1759 - accuracy: 0.9803 - precision_3: 0.9790 - recall_3: 0.9790 - auc_3: 0.9987\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.1247 - accuracy: 0.9901 - precision_3: 0.9816 - recall_3: 0.9977 - auc_3: 0.9992\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0809 - accuracy: 0.9912 - precision_3: 0.9884 - recall_3: 0.9930 - auc_3: 0.9997\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.0461 - accuracy: 0.9956 - precision_3: 0.9977 - recall_3: 0.9930 - auc_3: 0.9976\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.0134 - accuracy: 0.9934 - precision_3: 0.9976 - recall_3: 0.9883 - auc_3: 0.9985\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.0031 - accuracy: 0.9945 - precision_3: 0.9976 - recall_3: 0.9907 - auc_3: 0.9999\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9964 - accuracy: 0.9956 - precision_3: 0.9953 - recall_3: 0.9953 - auc_3: 0.9998\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.9590 - accuracy: 0.9945 - precision_3: 0.9953 - recall_3: 0.9930 - auc_3: 0.9998\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.9383 - accuracy: 0.9912 - precision_3: 0.9930 - recall_3: 0.9883 - auc_3: 0.9992\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9169 - accuracy: 0.9934 - precision_3: 0.9930 - recall_3: 0.9930 - auc_3: 0.9985\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.9190 - accuracy: 0.9880 - precision_3: 0.9860 - recall_3: 0.9883 - auc_3: 0.9977\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0854 - accuracy: 0.9113 - precision_3: 0.8864 - recall_3: 0.9299 - auc_3: 0.9698\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.9571 - accuracy: 0.9836 - precision_3: 0.9976 - recall_3: 0.9673 - auc_3: 0.9978\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9324 - accuracy: 0.9814 - precision_3: 0.9790 - recall_3: 0.9813 - auc_3: 0.9952\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.9141 - accuracy: 0.9737 - precision_3: 0.9591 - recall_3: 0.9860 - auc_3: 0.9946\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8581 - accuracy: 0.9901 - precision_3: 0.9883 - recall_3: 0.9907 - auc_3: 0.9979\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.8240 - accuracy: 0.9945 - precision_3: 0.9953 - recall_3: 0.9930 - auc_3: 0.9985\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7999 - accuracy: 0.9923 - precision_3: 0.9884 - recall_3: 0.9953 - auc_3: 0.9994\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.7716 - accuracy: 0.9956 - precision_3: 0.9953 - recall_3: 0.9953 - auc_3: 0.9998\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7461 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7342 - accuracy: 0.9967 - precision_3: 0.9953 - recall_3: 0.9977 - auc_3: 0.9999\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7399 - accuracy: 0.9912 - precision_3: 0.9861 - recall_3: 0.9953 - auc_3: 0.9996\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7184 - accuracy: 0.9978 - precision_3: 0.9953 - recall_3: 1.0000 - auc_3: 0.9999\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7023 - accuracy: 0.9967 - precision_3: 0.9977 - recall_3: 0.9953 - auc_3: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 10.3400 - accuracy: 0.5367 - precision_4: 0.5066 - recall_4: 0.4509 - auc_4: 0.5230\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 6.1147 - accuracy: 0.5433 - precision_4: 0.5112 - recall_4: 0.5888 - auc_4: 0.5724\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 4.4956 - accuracy: 0.5947 - precision_4: 0.5704 - recall_4: 0.5491 - auc_4: 0.6358\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.8036 - accuracy: 0.6736 - precision_4: 0.6526 - recall_4: 0.6495 - auc_4: 0.7451\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 3.2704 - accuracy: 0.7689 - precision_4: 0.7313 - recall_4: 0.8014 - auc_4: 0.8578\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.8723 - accuracy: 0.8609 - precision_4: 0.8182 - recall_4: 0.9042 - auc_4: 0.9349\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 2.5508 - accuracy: 0.9113 - precision_4: 0.8916 - recall_4: 0.9229 - auc_4: 0.9607\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.3399 - accuracy: 0.9200 - precision_4: 0.9236 - recall_4: 0.9042 - auc_4: 0.9669\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.2129 - accuracy: 0.9047 - precision_4: 0.9189 - recall_4: 0.8738 - auc_4: 0.9627\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.0757 - accuracy: 0.9332 - precision_4: 0.9199 - recall_4: 0.9393 - auc_4: 0.9771\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.9463 - accuracy: 0.9496 - precision_4: 0.9442 - recall_4: 0.9486 - auc_4: 0.9790\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.8248 - accuracy: 0.9518 - precision_4: 0.9660 - recall_4: 0.9299 - auc_4: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.8050 - accuracy: 0.9266 - precision_4: 0.9093 - recall_4: 0.9369 - auc_4: 0.9755\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.6823 - accuracy: 0.9704 - precision_4: 0.9740 - recall_4: 0.9626 - auc_4: 0.9918\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.5920 - accuracy: 0.9671 - precision_4: 0.9671 - recall_4: 0.9626 - auc_4: 0.9935\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.5092 - accuracy: 0.9660 - precision_4: 0.9671 - recall_4: 0.9603 - auc_4: 0.9939\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.5023 - accuracy: 0.9507 - precision_4: 0.9323 - recall_4: 0.9650 - auc_4: 0.9866\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.4568 - accuracy: 0.9573 - precision_4: 0.9642 - recall_4: 0.9439 - auc_4: 0.9883\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.3644 - accuracy: 0.9715 - precision_4: 0.9718 - recall_4: 0.9673 - auc_4: 0.9949\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.3020 - accuracy: 0.9759 - precision_4: 0.9699 - recall_4: 0.9790 - auc_4: 0.9941\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.2175 - accuracy: 0.9912 - precision_4: 0.9930 - recall_4: 0.9883 - auc_4: 0.9989\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.1734 - accuracy: 0.9890 - precision_4: 0.9883 - recall_4: 0.9883 - auc_4: 0.9983\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.2107 - accuracy: 0.9595 - precision_4: 0.9711 - recall_4: 0.9416 - auc_4: 0.9931\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.1857 - accuracy: 0.9715 - precision_4: 0.9718 - recall_4: 0.9673 - auc_4: 0.9944\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.1759 - accuracy: 0.9737 - precision_4: 0.9720 - recall_4: 0.9720 - auc_4: 0.9938\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.1518 - accuracy: 0.9650 - precision_4: 0.9541 - recall_4: 0.9720 - auc_4: 0.9927\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.0981 - accuracy: 0.9803 - precision_4: 0.9790 - recall_4: 0.9790 - auc_4: 0.9938\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0480 - accuracy: 0.9847 - precision_4: 0.9882 - recall_4: 0.9790 - auc_4: 0.9970\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.0178 - accuracy: 0.9836 - precision_4: 0.9859 - recall_4: 0.9790 - auc_4: 0.9982\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.9878 - accuracy: 0.9934 - precision_4: 0.9976 - recall_4: 0.9883 - auc_4: 0.9986\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.9637 - accuracy: 0.9847 - precision_4: 0.9770 - recall_4: 0.9907 - auc_4: 0.9994\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9424 - accuracy: 0.9869 - precision_4: 0.9860 - recall_4: 0.9860 - auc_4: 0.9984\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.9154 - accuracy: 0.9912 - precision_4: 0.9907 - recall_4: 0.9907 - auc_4: 0.9994\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.8881 - accuracy: 0.9923 - precision_4: 0.9907 - recall_4: 0.9930 - auc_4: 0.9996\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.8704 - accuracy: 0.9912 - precision_4: 0.9884 - recall_4: 0.9930 - auc_4: 0.9996\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.8450 - accuracy: 0.9945 - precision_4: 0.9885 - recall_4: 1.0000 - auc_4: 0.9999\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.8392 - accuracy: 0.9923 - precision_4: 0.9930 - recall_4: 0.9907 - auc_4: 0.9994\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.8109 - accuracy: 0.9978 - precision_4: 0.9977 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7862 - accuracy: 0.9978 - precision_4: 0.9977 - recall_4: 0.9977 - auc_4: 0.9996\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7626 - accuracy: 0.9978 - precision_4: 1.0000 - recall_4: 0.9953 - auc_4: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7630 - accuracy: 0.9912 - precision_4: 0.9930 - recall_4: 0.9883 - auc_4: 0.9996\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.8377 - accuracy: 0.9595 - precision_4: 0.9494 - recall_4: 0.9650 - auc_4: 0.9928\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.8288 - accuracy: 0.9792 - precision_4: 0.9812 - recall_4: 0.9743 - auc_4: 0.9949\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7812 - accuracy: 0.9880 - precision_4: 0.9906 - recall_4: 0.9836 - auc_4: 0.9995\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7283 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7039 - accuracy: 0.9978 - precision_4: 0.9977 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6893 - accuracy: 0.9934 - precision_4: 0.9953 - recall_4: 0.9907 - auc_4: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6723 - accuracy: 0.9967 - precision_4: 0.9977 - recall_4: 0.9953 - auc_4: 0.9998\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6511 - accuracy: 0.9978 - precision_4: 0.9953 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6325 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f7ea21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " Accuracy: 98.079% (+/-1.477) \n",
      " Precision: 96.016% (+/-3.914) \n",
      " Recall: 99.318% (+/-0.557) \n",
      " AUC: 99.887% (+/-0.116) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 10.5451 - accuracy: 0.5104 - precision_5: 0.4545 - recall_5: 0.2220 - auc_5: 0.5323\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 6.4513 - accuracy: 0.5181 - precision_5: 0.4860 - recall_5: 0.4860 - auc_5: 0.5282\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 4.6756 - accuracy: 0.5915 - precision_5: 0.5514 - recall_5: 0.6893 - auc_5: 0.6494\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 3.8945 - accuracy: 0.6594 - precision_5: 0.6163 - recall_5: 0.7243 - auc_5: 0.7425\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.3455 - accuracy: 0.7525 - precision_5: 0.7149 - recall_5: 0.7850 - auc_5: 0.8335\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.9198 - accuracy: 0.8445 - precision_5: 0.7907 - recall_5: 0.9089 - auc_5: 0.9265\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 2.6162 - accuracy: 0.8795 - precision_5: 0.8822 - recall_5: 0.8575 - auc_5: 0.9528\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.3690 - accuracy: 0.9266 - precision_5: 0.9247 - recall_5: 0.9182 - auc_5: 0.9770\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 2.2250 - accuracy: 0.9277 - precision_5: 0.9269 - recall_5: 0.9182 - auc_5: 0.9780\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 2.0609 - accuracy: 0.9518 - precision_5: 0.9615 - recall_5: 0.9346 - auc_5: 0.9905\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.9539 - accuracy: 0.9628 - precision_5: 0.9690 - recall_5: 0.9509 - auc_5: 0.9900\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.8568 - accuracy: 0.9573 - precision_5: 0.9492 - recall_5: 0.9603 - auc_5: 0.9922\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.7999 - accuracy: 0.9441 - precision_5: 0.9586 - recall_5: 0.9206 - auc_5: 0.9870\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.7379 - accuracy: 0.9474 - precision_5: 0.9460 - recall_5: 0.9416 - auc_5: 0.9876\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 1.6215 - accuracy: 0.9726 - precision_5: 0.9719 - recall_5: 0.9696 - auc_5: 0.9942\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.5682 - accuracy: 0.9606 - precision_5: 0.9558 - recall_5: 0.9603 - auc_5: 0.9937\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.4971 - accuracy: 0.9715 - precision_5: 0.9718 - recall_5: 0.9673 - auc_5: 0.9937\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.4037 - accuracy: 0.9814 - precision_5: 0.9768 - recall_5: 0.9836 - auc_5: 0.9969\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.3467 - accuracy: 0.9858 - precision_5: 0.9792 - recall_5: 0.9907 - auc_5: 0.9992\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.2972 - accuracy: 0.9890 - precision_5: 0.9953 - recall_5: 0.9813 - auc_5: 0.9994\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.2819 - accuracy: 0.9748 - precision_5: 0.9742 - recall_5: 0.9720 - auc_5: 0.9980\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.2505 - accuracy: 0.9836 - precision_5: 0.9859 - recall_5: 0.9790 - auc_5: 0.9985\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.2484 - accuracy: 0.9671 - precision_5: 0.9693 - recall_5: 0.9603 - auc_5: 0.9966\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.2134 - accuracy: 0.9781 - precision_5: 0.9744 - recall_5: 0.9790 - auc_5: 0.9977\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1639 - accuracy: 0.9847 - precision_5: 0.9836 - recall_5: 0.9836 - auc_5: 0.9987\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.1194 - accuracy: 0.9814 - precision_5: 0.9746 - recall_5: 0.9860 - auc_5: 0.9986\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.1097 - accuracy: 0.9759 - precision_5: 0.9788 - recall_5: 0.9696 - auc_5: 0.9975\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.1515 - accuracy: 0.9671 - precision_5: 0.9671 - recall_5: 0.9626 - auc_5: 0.9955\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.1125 - accuracy: 0.9890 - precision_5: 0.9883 - recall_5: 0.9883 - auc_5: 0.9993\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.0652 - accuracy: 0.9869 - precision_5: 0.9815 - recall_5: 0.9907 - auc_5: 0.9994\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.0255 - accuracy: 0.9901 - precision_5: 0.9953 - recall_5: 0.9836 - auc_5: 0.9995\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.0145 - accuracy: 0.9880 - precision_5: 0.9906 - recall_5: 0.9836 - auc_5: 0.9975\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.9856 - accuracy: 0.9967 - precision_5: 1.0000 - recall_5: 0.9930 - auc_5: 0.9997\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9671 - accuracy: 0.9945 - precision_5: 0.9953 - recall_5: 0.9930 - auc_5: 0.9993\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.9116 - accuracy: 0.9978 - precision_5: 0.9977 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.8732 - accuracy: 0.9967 - precision_5: 0.9977 - recall_5: 0.9953 - auc_5: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8492 - accuracy: 0.9967 - precision_5: 1.0000 - recall_5: 0.9930 - auc_5: 0.9999\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.8614 - accuracy: 0.9847 - precision_5: 0.9814 - recall_5: 0.9860 - auc_5: 0.9989\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8322 - accuracy: 0.9934 - precision_5: 0.9930 - recall_5: 0.9930 - auc_5: 0.9999\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.8033 - accuracy: 0.9978 - precision_5: 1.0000 - recall_5: 0.9953 - auc_5: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.7785 - accuracy: 0.9989 - precision_5: 1.0000 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.7534 - accuracy: 0.9989 - precision_5: 1.0000 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7332 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7150 - accuracy: 0.9989 - precision_5: 1.0000 - recall_5: 0.9977 - auc_5: 1.0000: 0s - loss: 0.7150 - accuracy: 0.9989 - precision_5: 1.0000 - recall_5: 0.9977 - auc_5: 1.000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6989 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7014 - accuracy: 0.9934 - precision_5: 0.9930 - recall_5: 0.9930 - auc_5: 0.9999\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.7338 - accuracy: 0.9803 - precision_5: 0.9812 - recall_5: 0.9766 - auc_5: 0.9985\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7193 - accuracy: 0.9978 - precision_5: 1.0000 - recall_5: 0.9953 - auc_5: 0.9999\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7631 - accuracy: 0.9693 - precision_5: 0.9808 - recall_5: 0.9533 - auc_5: 0.9961\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7332 - accuracy: 0.9847 - precision_5: 0.9770 - recall_5: 0.9907 - auc_5: 0.9987\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f7fc4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 10.4904 - accuracy: 0.4962 - precision_6: 0.4563 - recall_6: 0.3902 - auc_6: 0.5088\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 6.3434 - accuracy: 0.6221 - precision_6: 0.6089 - recall_6: 0.5421 - auc_6: 0.6698\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 4.6465 - accuracy: 0.7393 - precision_6: 0.7093 - recall_6: 0.7523 - auc_6: 0.8087\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 3.9443 - accuracy: 0.7963 - precision_6: 0.8010 - recall_6: 0.7523 - auc_6: 0.8799\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 3.4567 - accuracy: 0.8784 - precision_6: 0.8856 - recall_6: 0.8505 - auc_6: 0.9429\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 3.0694 - accuracy: 0.9211 - precision_6: 0.9140 - recall_6: 0.9182 - auc_6: 0.9630\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.7752 - accuracy: 0.9452 - precision_6: 0.9458 - recall_6: 0.9369 - auc_6: 0.9838\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.5751 - accuracy: 0.9496 - precision_6: 0.9526 - recall_6: 0.9393 - auc_6: 0.9897\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 2.4397 - accuracy: 0.9529 - precision_6: 0.9425 - recall_6: 0.9579 - auc_6: 0.9857\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.3088 - accuracy: 0.9639 - precision_6: 0.9561 - recall_6: 0.9673 - auc_6: 0.9923\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.2110 - accuracy: 0.9562 - precision_6: 0.9554 - recall_6: 0.9509 - auc_6: 0.9937\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 2.0697 - accuracy: 0.9759 - precision_6: 0.9788 - recall_6: 0.9696 - auc_6: 0.9968\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.9294 - accuracy: 0.9858 - precision_6: 0.9859 - recall_6: 0.9836 - auc_6: 0.9978\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.8389 - accuracy: 0.9759 - precision_6: 0.9810 - recall_6: 0.9673 - auc_6: 0.9979\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.7633 - accuracy: 0.9792 - precision_6: 0.9745 - recall_6: 0.9813 - auc_6: 0.9982\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.6745 - accuracy: 0.9934 - precision_6: 0.9953 - recall_6: 0.9907 - auc_6: 0.9993\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.6529 - accuracy: 0.9726 - precision_6: 0.9632 - recall_6: 0.9790 - auc_6: 0.9968\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.5977 - accuracy: 0.9934 - precision_6: 0.9953 - recall_6: 0.9907 - auc_6: 0.9993\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 1.5575 - accuracy: 0.9923 - precision_6: 0.9953 - recall_6: 0.9883 - auc_6: 0.9979\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.5008 - accuracy: 0.9814 - precision_6: 0.9746 - recall_6: 0.9860 - auc_6: 0.9986\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.4277 - accuracy: 0.9923 - precision_6: 0.9907 - recall_6: 0.9930 - auc_6: 0.9997\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.3749 - accuracy: 0.9890 - precision_6: 0.9860 - recall_6: 0.9907 - auc_6: 0.9996\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.3152 - accuracy: 0.9967 - precision_6: 0.9953 - recall_6: 0.9977 - auc_6: 0.9994\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.2748 - accuracy: 0.9923 - precision_6: 0.9907 - recall_6: 0.9930 - auc_6: 0.9998\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2345 - accuracy: 0.9956 - precision_6: 0.9953 - recall_6: 0.9953 - auc_6: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.3322 - accuracy: 0.9441 - precision_6: 0.9333 - recall_6: 0.9486 - auc_6: 0.9839\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2832 - accuracy: 0.9803 - precision_6: 0.9858 - recall_6: 0.9720 - auc_6: 0.9976\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.2102 - accuracy: 0.9956 - precision_6: 0.9953 - recall_6: 0.9953 - auc_6: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.1558 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 0.9996\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1037 - accuracy: 0.9978 - precision_6: 0.9953 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.0635 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.0260 - accuracy: 0.9978 - precision_6: 0.9977 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9951 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.9723 - accuracy: 0.9989 - precision_6: 1.0000 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.9644 - accuracy: 0.9912 - precision_6: 0.9884 - recall_6: 0.9930 - auc_6: 0.9996\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9688 - accuracy: 0.9880 - precision_6: 0.9883 - recall_6: 0.9860 - auc_6: 0.9983\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.9509 - accuracy: 0.9912 - precision_6: 0.9930 - recall_6: 0.9883 - auc_6: 0.9985\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.9989 - accuracy: 0.9890 - precision_6: 0.9838 - recall_6: 0.9930 - auc_6: 0.9970\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.0605 - accuracy: 0.9650 - precision_6: 0.9648 - recall_6: 0.9603 - auc_6: 0.9937\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9951 - accuracy: 0.9869 - precision_6: 0.9793 - recall_6: 0.9930 - auc_6: 0.9977\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.9919 - accuracy: 0.9869 - precision_6: 0.9906 - recall_6: 0.9813 - auc_6: 0.9983\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.9654 - accuracy: 0.9934 - precision_6: 0.9976 - recall_6: 0.9883 - auc_6: 0.9989\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.9003 - accuracy: 0.9978 - precision_6: 0.9977 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8536 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.8211 - accuracy: 0.9989 - precision_6: 1.0000 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7907 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7671 - accuracy: 0.9978 - precision_6: 0.9953 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7703 - accuracy: 0.9880 - precision_6: 0.9793 - recall_6: 0.9953 - auc_6: 0.9997\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8048 - accuracy: 0.9759 - precision_6: 0.9810 - recall_6: 0.9673 - auc_6: 0.9958\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7666 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f704aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 10.6514 - accuracy: 0.5257 - precision_7: 0.4942 - recall_7: 0.4953 - auc_7: 0.5123\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 6.4856 - accuracy: 0.5849 - precision_7: 0.5602 - recall_7: 0.5327 - auc_7: 0.6240\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 4.6410 - accuracy: 0.6955 - precision_7: 0.6697 - recall_7: 0.6916 - auc_7: 0.7573\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 3.9005 - accuracy: 0.7163 - precision_7: 0.6952 - recall_7: 0.7033 - auc_7: 0.7993\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.3336 - accuracy: 0.8620 - precision_7: 0.8386 - recall_7: 0.8738 - auc_7: 0.9319\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 2.9473 - accuracy: 0.9014 - precision_7: 0.8912 - recall_7: 0.8995 - auc_7: 0.9487\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.7078 - accuracy: 0.9189 - precision_7: 0.9097 - recall_7: 0.9182 - auc_7: 0.9708\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.5138 - accuracy: 0.9354 - precision_7: 0.9467 - recall_7: 0.9136 - auc_7: 0.9802\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.3110 - accuracy: 0.9562 - precision_7: 0.9554 - recall_7: 0.9509 - auc_7: 0.9876\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.1755 - accuracy: 0.9540 - precision_7: 0.9468 - recall_7: 0.9556 - auc_7: 0.9899\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 2.0816 - accuracy: 0.9518 - precision_7: 0.9384 - recall_7: 0.9603 - auc_7: 0.9896\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.9933 - accuracy: 0.9617 - precision_7: 0.9667 - recall_7: 0.9509 - auc_7: 0.9918\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.9043 - accuracy: 0.9726 - precision_7: 0.9675 - recall_7: 0.9743 - auc_7: 0.9962\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.7950 - accuracy: 0.9825 - precision_7: 0.9836 - recall_7: 0.9790 - auc_7: 0.9972\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7196 - accuracy: 0.9858 - precision_7: 0.9905 - recall_7: 0.9790 - auc_7: 0.9984\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.7021 - accuracy: 0.9715 - precision_7: 0.9674 - recall_7: 0.9720 - auc_7: 0.9963\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.6230 - accuracy: 0.9858 - precision_7: 0.9952 - recall_7: 0.9743 - auc_7: 0.9986\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.5268 - accuracy: 0.9912 - precision_7: 0.9930 - recall_7: 0.9883 - auc_7: 0.9992\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.4416 - accuracy: 0.9934 - precision_7: 0.9953 - recall_7: 0.9907 - auc_7: 0.9997\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.3740 - accuracy: 0.9967 - precision_7: 1.0000 - recall_7: 0.9930 - auc_7: 0.9998\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.3101 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.6176 - accuracy: 0.8653 - precision_7: 0.8427 - recall_7: 0.8762 - auc_7: 0.9419\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.7118 - accuracy: 0.9036 - precision_7: 0.9857 - recall_7: 0.8061 - auc_7: 0.9789\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.5786 - accuracy: 0.9485 - precision_7: 0.9379 - recall_7: 0.9533 - auc_7: 0.9828\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.4097 - accuracy: 0.9650 - precision_7: 0.9626 - recall_7: 0.9626 - auc_7: 0.9939\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.3062 - accuracy: 0.9726 - precision_7: 0.9832 - recall_7: 0.9579 - auc_7: 0.9963\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.2336 - accuracy: 0.9847 - precision_7: 0.9882 - recall_7: 0.9790 - auc_7: 0.9976\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.1848 - accuracy: 0.9847 - precision_7: 0.9792 - recall_7: 0.9883 - auc_7: 0.9983\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.1771 - accuracy: 0.9682 - precision_7: 0.9716 - recall_7: 0.9603 - auc_7: 0.9946\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.1083 - accuracy: 0.9869 - precision_7: 0.9976 - recall_7: 0.9743 - auc_7: 0.9994\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 1.0741 - accuracy: 0.9923 - precision_7: 0.9976 - recall_7: 0.9860 - auc_7: 0.9989\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.0273 - accuracy: 0.9967 - precision_7: 0.9977 - recall_7: 0.9953 - auc_7: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9958 - accuracy: 0.9945 - precision_7: 0.9976 - recall_7: 0.9907 - auc_7: 0.9999\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9792 - accuracy: 0.9956 - precision_7: 1.0000 - recall_7: 0.9907 - auc_7: 0.9996\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.9581 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 0.9996\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9372 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 0.9998\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.9436 - accuracy: 0.9923 - precision_7: 0.9953 - recall_7: 0.9883 - auc_7: 0.9997\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.9375 - accuracy: 0.9945 - precision_7: 0.9976 - recall_7: 0.9907 - auc_7: 0.9998\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.0433 - accuracy: 0.9650 - precision_7: 0.9500 - recall_7: 0.9766 - auc_7: 0.9956\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.0445 - accuracy: 0.9858 - precision_7: 0.9929 - recall_7: 0.9766 - auc_7: 0.9989\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.9719 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 0.9995\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.9025 - accuracy: 0.9967 - precision_7: 0.9977 - recall_7: 0.9953 - auc_7: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.8537 - accuracy: 0.9967 - precision_7: 0.9953 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.8250 - accuracy: 0.9967 - precision_7: 1.0000 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.7921 - accuracy: 0.9989 - precision_7: 1.0000 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7820 - accuracy: 0.9934 - precision_7: 0.9907 - recall_7: 0.9953 - auc_7: 0.9997\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9249 - accuracy: 0.9321 - precision_7: 0.9256 - recall_7: 0.9299 - auc_7: 0.9796\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.8626 - accuracy: 0.9814 - precision_7: 0.9724 - recall_7: 0.9883 - auc_7: 0.9980\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8483 - accuracy: 0.9814 - precision_7: 0.9881 - recall_7: 0.9720 - auc_7: 0.9965\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7956 - accuracy: 0.9901 - precision_7: 0.9976 - recall_7: 0.9813 - auc_7: 0.9986\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f7f248c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 10.4148 - accuracy: 0.4918 - precision_8: 0.4552 - recall_8: 0.4276 - auc_8: 0.5109\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 6.1551 - accuracy: 0.6068 - precision_8: 0.5816 - recall_8: 0.5748 - auc_8: 0.6432\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 4.4371 - accuracy: 0.6955 - precision_8: 0.6689 - recall_8: 0.6939 - auc_8: 0.7754\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 3.7007 - accuracy: 0.8171 - precision_8: 0.7680 - recall_8: 0.8738 - auc_8: 0.9079\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 3.2585 - accuracy: 0.8576 - precision_8: 0.8565 - recall_8: 0.8364 - auc_8: 0.9363\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.8513 - accuracy: 0.9288 - precision_8: 0.9192 - recall_8: 0.9299 - auc_8: 0.9780\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.6044 - accuracy: 0.9485 - precision_8: 0.9568 - recall_8: 0.9322 - auc_8: 0.9818\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.4510 - accuracy: 0.9168 - precision_8: 0.9037 - recall_8: 0.9206 - auc_8: 0.9788\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.2971 - accuracy: 0.9485 - precision_8: 0.9504 - recall_8: 0.9393 - auc_8: 0.9865\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.1373 - accuracy: 0.9650 - precision_8: 0.9737 - recall_8: 0.9509 - auc_8: 0.9943\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.0107 - accuracy: 0.9748 - precision_8: 0.9787 - recall_8: 0.9673 - auc_8: 0.9953\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.9095 - accuracy: 0.9726 - precision_8: 0.9741 - recall_8: 0.9673 - auc_8: 0.9953\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.8356 - accuracy: 0.9693 - precision_8: 0.9785 - recall_8: 0.9556 - auc_8: 0.9961\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.7802 - accuracy: 0.9803 - precision_8: 0.9904 - recall_8: 0.9673 - auc_8: 0.9970\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.7648 - accuracy: 0.9628 - precision_8: 0.9646 - recall_8: 0.9556 - auc_8: 0.9929\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.7052 - accuracy: 0.9693 - precision_8: 0.9673 - recall_8: 0.9673 - auc_8: 0.9934\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.6471 - accuracy: 0.9660 - precision_8: 0.9671 - recall_8: 0.9603 - auc_8: 0.9965\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.5763 - accuracy: 0.9715 - precision_8: 0.9741 - recall_8: 0.9650 - auc_8: 0.9939\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.4769 - accuracy: 0.9836 - precision_8: 0.9836 - recall_8: 0.9813 - auc_8: 0.9980\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.3978 - accuracy: 0.9923 - precision_8: 0.9953 - recall_8: 0.9883 - auc_8: 0.9988\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.3293 - accuracy: 0.9901 - precision_8: 0.9929 - recall_8: 0.9860 - auc_8: 0.9998\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.2812 - accuracy: 0.9978 - precision_8: 0.9977 - recall_8: 0.9977 - auc_8: 0.9994\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2319 - accuracy: 0.9989 - precision_8: 1.0000 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.2088 - accuracy: 0.9956 - precision_8: 0.9977 - recall_8: 0.9930 - auc_8: 0.9994\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.2011 - accuracy: 0.9901 - precision_8: 0.9906 - recall_8: 0.9883 - auc_8: 0.9991\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.1703 - accuracy: 0.9923 - precision_8: 0.9930 - recall_8: 0.9907 - auc_8: 0.9996\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.2053 - accuracy: 0.9759 - precision_8: 0.9743 - recall_8: 0.9743 - auc_8: 0.9956: 0s - loss: 1.2370 - accuracy: 0.9609 - precision_8: 1.0000 - recall_8: 0.9174 - auc_8: \n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.2322 - accuracy: 0.9715 - precision_8: 0.9763 - recall_8: 0.9626 - auc_8: 0.9908\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.1293 - accuracy: 0.9945 - precision_8: 0.9976 - recall_8: 0.9907 - auc_8: 0.9999\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.0773 - accuracy: 0.9978 - precision_8: 0.9977 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.0314 - accuracy: 0.9989 - precision_8: 1.0000 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.9949 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9587 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9347 - accuracy: 0.9978 - precision_8: 0.9977 - recall_8: 0.9977 - auc_8: 0.9999\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.9087 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.8831 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.8602 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.8446 - accuracy: 0.9989 - precision_8: 0.9977 - recall_8: 1.0000 - auc_8: 0.9998\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.8254 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.8046 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7906 - accuracy: 0.9967 - precision_8: 0.9953 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 2.1132 - accuracy: 0.5630 - precision_8: 0.6408 - recall_8: 0.1542 - auc_8: 0.5216\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.2712 - accuracy: 0.7448 - precision_8: 0.7843 - recall_8: 0.6285 - auc_8: 0.8252\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.9541 - accuracy: 0.8050 - precision_8: 0.7948 - recall_8: 0.7874 - auc_8: 0.8844\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.6660 - accuracy: 0.8346 - precision_8: 0.8228 - recall_8: 0.8248 - auc_8: 0.9102\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.4374 - accuracy: 0.8927 - precision_8: 0.8892 - recall_8: 0.8808 - auc_8: 0.9598\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.3864 - accuracy: 0.8981 - precision_8: 0.8665 - recall_8: 0.9252 - auc_8: 0.9602\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.2752 - accuracy: 0.9398 - precision_8: 0.9368 - recall_8: 0.9346 - auc_8: 0.9780\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1816 - accuracy: 0.9573 - precision_8: 0.9451 - recall_8: 0.9650 - auc_8: 0.9907\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1773 - accuracy: 0.9507 - precision_8: 0.9323 - recall_8: 0.9650 - auc_8: 0.9867\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f7ea2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 10.4059 - accuracy: 0.5279 - precision_9: 0.4964 - recall_9: 0.4790 - auc_9: 0.5259\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 6.1165 - accuracy: 0.5652 - precision_9: 0.5522 - recall_9: 0.3832 - auc_9: 0.5891\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 4.4514 - accuracy: 0.6221 - precision_9: 0.5933 - recall_9: 0.6168 - auc_9: 0.6696\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 3.7880 - accuracy: 0.6966 - precision_9: 0.6837 - recall_9: 0.6565 - auc_9: 0.7600\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 3.3403 - accuracy: 0.7426 - precision_9: 0.6817 - recall_9: 0.8458 - auc_9: 0.8064\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.8890 - accuracy: 0.8642 - precision_9: 0.8333 - recall_9: 0.8879 - auc_9: 0.9416\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5766 - accuracy: 0.9036 - precision_9: 0.9009 - recall_9: 0.8925 - auc_9: 0.9693\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.3680 - accuracy: 0.9354 - precision_9: 0.9261 - recall_9: 0.9369 - auc_9: 0.9773\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.1960 - accuracy: 0.9474 - precision_9: 0.9419 - recall_9: 0.9463 - auc_9: 0.9857\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.0992 - accuracy: 0.9518 - precision_9: 0.9615 - recall_9: 0.9346 - auc_9: 0.9821\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.9506 - accuracy: 0.9650 - precision_9: 0.9670 - recall_9: 0.9579 - auc_9: 0.9917\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.8267 - accuracy: 0.9650 - precision_9: 0.9562 - recall_9: 0.9696 - auc_9: 0.9936\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.7077 - accuracy: 0.9814 - precision_9: 0.9835 - recall_9: 0.9766 - auc_9: 0.9971\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.6225 - accuracy: 0.9858 - precision_9: 0.9929 - recall_9: 0.9766 - auc_9: 0.9965\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.5525 - accuracy: 0.9737 - precision_9: 0.9879 - recall_9: 0.9556 - auc_9: 0.9978\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.5403 - accuracy: 0.9562 - precision_9: 0.9409 - recall_9: 0.9673 - auc_9: 0.9928\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5677 - accuracy: 0.9343 - precision_9: 0.9444 - recall_9: 0.9136 - auc_9: 0.9804\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.4565 - accuracy: 0.9737 - precision_9: 0.9720 - recall_9: 0.9720 - auc_9: 0.9958\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.3922 - accuracy: 0.9781 - precision_9: 0.9834 - recall_9: 0.9696 - auc_9: 0.9959\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.3257 - accuracy: 0.9847 - precision_9: 0.9929 - recall_9: 0.9743 - auc_9: 0.9989\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.2823 - accuracy: 0.9923 - precision_9: 0.9976 - recall_9: 0.9860 - auc_9: 0.9974\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.2480 - accuracy: 0.9880 - precision_9: 0.9883 - recall_9: 0.9860 - auc_9: 0.9985\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.1816 - accuracy: 0.9956 - precision_9: 0.9977 - recall_9: 0.9930 - auc_9: 0.9996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.1286 - accuracy: 0.9978 - precision_9: 1.0000 - recall_9: 0.9953 - auc_9: 0.9997\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.0930 - accuracy: 0.9967 - precision_9: 0.9953 - recall_9: 0.9977 - auc_9: 0.9997\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.0682 - accuracy: 0.9956 - precision_9: 0.9977 - recall_9: 0.9930 - auc_9: 0.9995\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.3942 - accuracy: 0.8565 - precision_9: 0.8264 - recall_9: 0.8785 - auc_9: 0.9367\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.3396 - accuracy: 0.9540 - precision_9: 0.9531 - recall_9: 0.9486 - auc_9: 0.9861\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.2166 - accuracy: 0.9759 - precision_9: 0.9856 - recall_9: 0.9626 - auc_9: 0.9956\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0858 - accuracy: 0.9934 - precision_9: 0.9976 - recall_9: 0.9883 - auc_9: 0.9996\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.0543 - accuracy: 0.9858 - precision_9: 0.9792 - recall_9: 0.9907 - auc_9: 0.9970\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.0082 - accuracy: 0.9912 - precision_9: 0.9884 - recall_9: 0.9930 - auc_9: 0.9996\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9588 - accuracy: 0.9945 - precision_9: 0.9953 - recall_9: 0.9930 - auc_9: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.9198 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.8896 - accuracy: 0.9978 - precision_9: 0.9953 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.8618 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.8401 - accuracy: 0.9989 - precision_9: 0.9977 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.8189 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7991 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.7894 - accuracy: 0.9978 - precision_9: 0.9953 - recall_9: 1.0000 - auc_9: 0.9996\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.8741 - accuracy: 0.9628 - precision_9: 0.9690 - recall_9: 0.9509 - auc_9: 0.9920\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.8769 - accuracy: 0.9759 - precision_9: 0.9656 - recall_9: 0.9836 - auc_9: 0.9952\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.8851 - accuracy: 0.9814 - precision_9: 0.9813 - recall_9: 0.9790 - auc_9: 0.9920\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.8483 - accuracy: 0.9923 - precision_9: 0.9884 - recall_9: 0.9953 - auc_9: 0.9996\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7991 - accuracy: 0.9978 - precision_9: 0.9977 - recall_9: 0.9977 - auc_9: 0.9996\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7613 - accuracy: 0.9956 - precision_9: 0.9977 - recall_9: 0.9930 - auc_9: 0.9998\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7260 - accuracy: 0.9978 - precision_9: 0.9977 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.7015 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6790 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6604 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8e8502d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 94.760% (+/-5.943) \n",
      " Precision: 90.354% (+/-10.636) \n",
      " Recall: 98.864% (+/-1.245) \n",
      " AUC: 99.728% (+/-0.212) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),input_shape=(None,n_length,n_features))))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 11.5042 - accuracy: 0.4962 - precision_10: 0.4608 - recall_10: 0.4393 - auc_10: 0.5040\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 8.0935 - accuracy: 0.6145 - precision_10: 0.5892 - recall_10: 0.5864 - auc_10: 0.6586\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 5.8668 - accuracy: 0.7240 - precision_10: 0.6888 - recall_10: 0.7500 - auc_10: 0.8100\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 4.6901 - accuracy: 0.7886 - precision_10: 0.7617 - recall_10: 0.7991 - auc_10: 0.8841\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 3.9700 - accuracy: 0.8554 - precision_10: 0.8364 - recall_10: 0.8598 - auc_10: 0.9429\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.4948 - accuracy: 0.9343 - precision_10: 0.9299 - recall_10: 0.9299 - auc_10: 0.9798\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.1575 - accuracy: 0.9693 - precision_10: 0.9630 - recall_10: 0.9720 - auc_10: 0.9922\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 2.9534 - accuracy: 0.9551 - precision_10: 0.9448 - recall_10: 0.9603 - auc_10: 0.9918\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 2.7708 - accuracy: 0.9770 - precision_10: 0.9788 - recall_10: 0.9720 - auc_10: 0.9974\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.6097 - accuracy: 0.9934 - precision_10: 0.9953 - recall_10: 0.9907 - auc_10: 0.9993\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.4291 - accuracy: 0.9956 - precision_10: 1.0000 - recall_10: 0.9907 - auc_10: 0.9998\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.2357 - accuracy: 0.9956 - precision_10: 0.9977 - recall_10: 0.9930 - auc_10: 1.0000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.0744 - accuracy: 0.9934 - precision_10: 0.9930 - recall_10: 0.9930 - auc_10: 0.9999\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.9406 - accuracy: 0.9956 - precision_10: 0.9930 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.8333 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.8605 - accuracy: 0.9682 - precision_10: 0.9544 - recall_10: 0.9790 - auc_10: 0.9971\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.9261 - accuracy: 0.9759 - precision_10: 0.9743 - recall_10: 0.9743 - auc_10: 0.9974\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.8972 - accuracy: 0.9890 - precision_10: 0.9883 - recall_10: 0.9883 - auc_10: 0.9986\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.8565 - accuracy: 0.9792 - precision_10: 0.9812 - recall_10: 0.9743 - auc_10: 0.9981\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.9018 - accuracy: 0.9715 - precision_10: 0.9855 - recall_10: 0.9533 - auc_10: 0.9980\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.9531 - accuracy: 0.9759 - precision_10: 0.9856 - recall_10: 0.9626 - auc_10: 0.9979\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.8936 - accuracy: 0.9858 - precision_10: 0.9770 - recall_10: 0.9930 - auc_10: 0.9993\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.7416 - accuracy: 0.9923 - precision_10: 0.9953 - recall_10: 0.9883 - auc_10: 0.9996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.5910 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.4571 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.3398 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.2495 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.1833 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.1328 - accuracy: 0.9989 - precision_10: 0.9977 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0899 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.0466 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.0076 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.9706 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9390 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.9149 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9015 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.9379 - accuracy: 0.9803 - precision_10: 0.9790 - recall_10: 0.9790 - auc_10: 0.9979\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.9769 - accuracy: 0.9858 - precision_10: 0.9792 - recall_10: 0.9907 - auc_10: 0.9986\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.9883 - accuracy: 0.9934 - precision_10: 0.9907 - recall_10: 0.9953 - auc_10: 0.9999\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.9465 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9103 - accuracy: 0.9901 - precision_10: 0.9929 - recall_10: 0.9860 - auc_10: 0.9997\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.8631 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.9156 - accuracy: 0.9715 - precision_10: 0.9786 - recall_10: 0.9603 - auc_10: 0.9980\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9213 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.8918 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 0.9998\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.8440 - accuracy: 0.9956 - precision_10: 0.9953 - recall_10: 0.9953 - auc_10: 0.9998\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7902 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7576 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7286 - accuracy: 0.9956 - precision_10: 0.9930 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7108 - accuracy: 0.9945 - precision_10: 0.9907 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8ecfd3bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 11.6311 - accuracy: 0.5148 - precision_11: 0.4835 - recall_11: 0.5140 - auc_11: 0.5184\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 8.3996 - accuracy: 0.6320 - precision_11: 0.5954 - recall_11: 0.6706 - auc_11: 0.6704\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 6.1880 - accuracy: 0.7130 - precision_11: 0.6895 - recall_11: 0.7056 - auc_11: 0.7753\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 4.8666 - accuracy: 0.7996 - precision_11: 0.7692 - recall_11: 0.8178 - auc_11: 0.8859\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 4.0669 - accuracy: 0.8795 - precision_11: 0.8614 - recall_11: 0.8855 - auc_11: 0.9492\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 3.5527 - accuracy: 0.9244 - precision_11: 0.9165 - recall_11: 0.9229 - auc_11: 0.9803\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 3.1851 - accuracy: 0.9562 - precision_11: 0.9491 - recall_11: 0.9579 - auc_11: 0.9893\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.9152 - accuracy: 0.9682 - precision_11: 0.9694 - recall_11: 0.9626 - auc_11: 0.9956\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.7208 - accuracy: 0.9573 - precision_11: 0.9555 - recall_11: 0.9533 - auc_11: 0.9951\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.5538 - accuracy: 0.9781 - precision_11: 0.9789 - recall_11: 0.9743 - auc_11: 0.9979\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.4094 - accuracy: 0.9836 - precision_11: 0.9882 - recall_11: 0.9766 - auc_11: 0.9989\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.2412 - accuracy: 0.9901 - precision_11: 0.9953 - recall_11: 0.9836 - auc_11: 0.9995\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.1220 - accuracy: 0.9890 - precision_11: 0.9906 - recall_11: 0.9860 - auc_11: 0.9998\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.0221 - accuracy: 0.9923 - precision_11: 0.9930 - recall_11: 0.9907 - auc_11: 0.9998\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.8857 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.7470 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.6217 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.5349 - accuracy: 0.9934 - precision_11: 0.9953 - recall_11: 0.9907 - auc_11: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.4914 - accuracy: 0.9956 - precision_11: 0.9930 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.4339 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.3612 - accuracy: 0.9967 - precision_11: 0.9977 - recall_11: 0.9953 - auc_11: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.3675 - accuracy: 0.9847 - precision_11: 0.9929 - recall_11: 0.9743 - auc_11: 0.9978\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.3879 - accuracy: 0.9934 - precision_11: 0.9907 - recall_11: 0.9953 - auc_11: 0.9996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.3808 - accuracy: 0.9956 - precision_11: 0.9977 - recall_11: 0.9930 - auc_11: 0.9997\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.3474 - accuracy: 0.9934 - precision_11: 0.9930 - recall_11: 0.9930 - auc_11: 0.9999\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.2806 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.2337 - accuracy: 0.9956 - precision_11: 0.9930 - recall_11: 0.9977 - auc_11: 0.9998\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1872 - accuracy: 0.9923 - precision_11: 0.9907 - recall_11: 0.9930 - auc_11: 0.9999\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1702 - accuracy: 0.9978 - precision_11: 1.0000 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.1881 - accuracy: 0.9836 - precision_11: 0.9814 - recall_11: 0.9836 - auc_11: 0.9993 0s - loss: 1.1711 - accuracy: 0.9896 - precision_11: 0.9784 - recall_11: 1.0000 - auc_\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.2018 - accuracy: 0.9934 - precision_11: 0.9907 - recall_11: 0.9953 - auc_11: 0.9981\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.1411 - accuracy: 0.9945 - precision_11: 0.9976 - recall_11: 0.9907 - auc_11: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0662 - accuracy: 0.9967 - precision_11: 0.9953 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.0066 - accuracy: 0.9934 - precision_11: 0.9930 - recall_11: 0.9930 - auc_11: 0.9999\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9619 - accuracy: 0.9978 - precision_11: 1.0000 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9316 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8854 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8412 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.8037 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7828 - accuracy: 0.9967 - precision_11: 0.9977 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7624 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000 0s - loss: 0.7642 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7742 - accuracy: 0.9890 - precision_11: 0.9860 - recall_11: 0.9907 - auc_11: 0.9995\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7912 - accuracy: 0.9901 - precision_11: 0.9906 - recall_11: 0.9883 - auc_11: 0.9992\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7784 - accuracy: 0.9956 - precision_11: 0.9930 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.8008 - accuracy: 0.9858 - precision_11: 0.9837 - recall_11: 0.9860 - auc_11: 0.9983\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8562 - accuracy: 0.9671 - precision_11: 0.9738 - recall_11: 0.9556 - auc_11: 0.9939\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8510 - accuracy: 0.9792 - precision_11: 0.9745 - recall_11: 0.9813 - auc_11: 0.9974\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.8200 - accuracy: 0.9869 - precision_11: 0.9815 - recall_11: 0.9907 - auc_11: 0.9995\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7763 - accuracy: 0.9945 - precision_11: 0.9930 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7323 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f78c5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 11.2679 - accuracy: 0.6057 - precision_12: 0.5810 - recall_12: 0.5701 - auc_12: 0.6378\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 7.8775 - accuracy: 0.7448 - precision_12: 0.6978 - recall_12: 0.8037 - auc_12: 0.8301\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 5.7385 - accuracy: 0.8346 - precision_12: 0.8031 - recall_12: 0.8575 - auc_12: 0.9193\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.5871 - accuracy: 0.9135 - precision_12: 0.9087 - recall_12: 0.9065 - auc_12: 0.9756\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.0119 - accuracy: 0.9157 - precision_12: 0.8874 - recall_12: 0.9393 - auc_12: 0.9759\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 3.5296 - accuracy: 0.9748 - precision_12: 0.9833 - recall_12: 0.9626 - auc_12: 0.9955\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 3.1758 - accuracy: 0.9847 - precision_12: 0.9836 - recall_12: 0.9836 - auc_12: 0.9989\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 2.8842 - accuracy: 0.9923 - precision_12: 0.9953 - recall_12: 0.9883 - auc_12: 0.9992\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 2.6452 - accuracy: 0.9923 - precision_12: 0.9884 - recall_12: 0.9953 - auc_12: 0.9997\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 2.4594 - accuracy: 0.9923 - precision_12: 0.9930 - recall_12: 0.9907 - auc_12: 0.9996\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.3057 - accuracy: 0.9836 - precision_12: 0.9859 - recall_12: 0.9790 - auc_12: 0.9977\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.3518 - accuracy: 0.9365 - precision_12: 0.9205 - recall_12: 0.9463 - auc_12: 0.9845\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 2.3620 - accuracy: 0.9671 - precision_12: 0.9543 - recall_12: 0.9766 - auc_12: 0.9956\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.2391 - accuracy: 0.9858 - precision_12: 0.9882 - recall_12: 0.9813 - auc_12: 0.9988\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.0636 - accuracy: 0.9956 - precision_12: 0.9977 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.9064 - accuracy: 0.9967 - precision_12: 0.9953 - recall_12: 0.9977 - auc_12: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.7685 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.6533 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.5558 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4775 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4124 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.4304 - accuracy: 0.9934 - precision_12: 0.9953 - recall_12: 0.9907 - auc_12: 0.9998\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4843 - accuracy: 0.9956 - precision_12: 0.9953 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4222 - accuracy: 0.9956 - precision_12: 0.9930 - recall_12: 0.9977 - auc_12: 0.9999\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3610 - accuracy: 0.9945 - precision_12: 0.9976 - recall_12: 0.9907 - auc_12: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3119 - accuracy: 0.9967 - precision_12: 0.9977 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.2398 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1720 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.1127 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0651 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.0237 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.9893 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9955 - accuracy: 0.9869 - precision_12: 0.9952 - recall_12: 0.9766 - auc_12: 0.9995\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.3696 - accuracy: 0.8532 - precision_12: 0.8238 - recall_12: 0.8738 - auc_12: 0.9293\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.2728 - accuracy: 0.9463 - precision_12: 0.9501 - recall_12: 0.9346 - auc_12: 0.9875\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.2283 - accuracy: 0.9726 - precision_12: 0.9719 - recall_12: 0.9696 - auc_12: 0.9954\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.1497 - accuracy: 0.9847 - precision_12: 0.9836 - recall_12: 0.9836 - auc_12: 0.9992\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0873 - accuracy: 0.9967 - precision_12: 0.9953 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.0406 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 0.9999\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9775 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9213 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8789 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.8352 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.7998 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7695 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7416 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.9642 - accuracy: 0.9069 - precision_12: 0.8803 - recall_12: 0.9276 - auc_12: 0.9764\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9955 - accuracy: 0.9562 - precision_12: 0.9732 - recall_12: 0.9322 - auc_12: 0.9939\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9439 - accuracy: 0.9912 - precision_12: 0.9884 - recall_12: 0.9930 - auc_12: 0.9997\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8795 - accuracy: 0.9967 - precision_12: 0.9930 - recall_12: 1.0000 - auc_12: 0.9999\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f76b89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 11.6818 - accuracy: 0.5170 - precision_13: 0.4870 - recall_13: 0.5701 - auc_13: 0.5143\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 8.4543 - accuracy: 0.5663 - precision_13: 0.5465 - recall_13: 0.4393 - auc_13: 0.6013\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 6.2485 - accuracy: 0.6265 - precision_13: 0.5841 - recall_13: 0.7056 - auc_13: 0.6947\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 4.9206 - accuracy: 0.7547 - precision_13: 0.7208 - recall_13: 0.7780 - auc_13: 0.8391\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 4.1159 - accuracy: 0.8620 - precision_13: 0.8479 - recall_13: 0.8598 - auc_13: 0.9327\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 3.6000 - accuracy: 0.9343 - precision_13: 0.9259 - recall_13: 0.9346 - auc_13: 0.9770\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 3.2573 - accuracy: 0.9595 - precision_13: 0.9536 - recall_13: 0.9603 - auc_13: 0.9902\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 2.9755 - accuracy: 0.9803 - precision_13: 0.9790 - recall_13: 0.9790 - auc_13: 0.9973\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 2.7409 - accuracy: 0.9814 - precision_13: 0.9858 - recall_13: 0.9743 - auc_13: 0.9992\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 2.5268 - accuracy: 0.9934 - precision_13: 0.9953 - recall_13: 0.9907 - auc_13: 0.9996\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 2.3452 - accuracy: 0.9923 - precision_13: 0.9907 - recall_13: 0.9930 - auc_13: 0.9996\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 2.2418 - accuracy: 0.9847 - precision_13: 0.9814 - recall_13: 0.9860 - auc_13: 0.9994 0s - loss: 2.2411 - accuracy: 0.9855 - precision_13: 0.9834 - recall_13: 0.9857 - auc_13: 0.99\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.2230 - accuracy: 0.9858 - precision_13: 0.9837 - recall_13: 0.9860 - auc_13: 0.9988\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 2.1582 - accuracy: 0.9923 - precision_13: 0.9953 - recall_13: 0.9883 - auc_13: 0.9997\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.0104 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.8574 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.7006 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.5756 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.4977 - accuracy: 0.9923 - precision_13: 0.9953 - recall_13: 0.9883 - auc_13: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.4429 - accuracy: 0.9956 - precision_13: 0.9953 - recall_13: 0.9953 - auc_13: 0.9999\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.3955 - accuracy: 0.9956 - precision_13: 0.9953 - recall_13: 0.9953 - auc_13: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.3658 - accuracy: 0.9912 - precision_13: 0.9930 - recall_13: 0.9883 - auc_13: 0.9996\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.4836 - accuracy: 0.9540 - precision_13: 0.9367 - recall_13: 0.9673 - auc_13: 0.9914\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5849 - accuracy: 0.9704 - precision_13: 0.9696 - recall_13: 0.9673 - auc_13: 0.9970\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.5336 - accuracy: 0.9912 - precision_13: 0.9930 - recall_13: 0.9883 - auc_13: 0.9994\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.4789 - accuracy: 0.9803 - precision_13: 0.9858 - recall_13: 0.9720 - auc_13: 0.9980\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.4034 - accuracy: 0.9945 - precision_13: 1.0000 - recall_13: 0.9883 - auc_13: 0.9998\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3267 - accuracy: 0.9934 - precision_13: 0.9930 - recall_13: 0.9930 - auc_13: 0.9999\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.2474 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.1654 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0911 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.0313 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9879 - accuracy: 0.9967 - precision_13: 1.0000 - recall_13: 0.9930 - auc_13: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9611 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9423 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.9219 - accuracy: 0.9956 - precision_13: 0.9930 - recall_13: 0.9977 - auc_13: 0.9999\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.0657 - accuracy: 0.9376 - precision_13: 0.9385 - recall_13: 0.9276 - auc_13: 0.9836\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1394 - accuracy: 0.9584 - precision_13: 0.9493 - recall_13: 0.9626 - auc_13: 0.9942\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.1446 - accuracy: 0.9956 - precision_13: 0.9930 - recall_13: 0.9977 - auc_13: 0.9996\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0802 - accuracy: 0.9945 - precision_13: 0.9930 - recall_13: 0.9953 - auc_13: 0.9999\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9765 - accuracy: 0.9978 - precision_13: 1.0000 - recall_13: 0.9953 - auc_13: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9023 - accuracy: 0.9978 - precision_13: 0.9953 - recall_13: 1.0000 - auc_13: 0.9999\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8473 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.8022 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7639 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7348 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7126 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.7449 - accuracy: 0.9803 - precision_13: 0.9812 - recall_13: 0.9766 - auc_13: 0.9979\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7612 - accuracy: 0.9858 - precision_13: 0.9859 - recall_13: 0.9836 - auc_13: 0.9991\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.7834 - accuracy: 0.9901 - precision_13: 0.9929 - recall_13: 0.9860 - auc_13: 0.9995\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8f744f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 11.3231 - accuracy: 0.5509 - precision_14: 0.5215 - recall_14: 0.5093 - auc_14: 0.5846\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 7.9155 - accuracy: 0.7152 - precision_14: 0.7165 - recall_14: 0.6495 - auc_14: 0.8154\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.7466 - accuracy: 0.8116 - precision_14: 0.7807 - recall_14: 0.8318 - auc_14: 0.8943\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 4.5104 - accuracy: 0.9091 - precision_14: 0.8842 - recall_14: 0.9276 - auc_14: 0.9695\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 3.8312 - accuracy: 0.9409 - precision_14: 0.9349 - recall_14: 0.9393 - auc_14: 0.9884\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.4097 - accuracy: 0.9606 - precision_14: 0.9537 - recall_14: 0.9626 - auc_14: 0.9944\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 3.1252 - accuracy: 0.9792 - precision_14: 0.9835 - recall_14: 0.9720 - auc_14: 0.9965\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 2.8977 - accuracy: 0.9770 - precision_14: 0.9700 - recall_14: 0.9813 - auc_14: 0.9976\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.6580 - accuracy: 0.9880 - precision_14: 0.9883 - recall_14: 0.9860 - auc_14: 0.9997\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.4671 - accuracy: 0.9901 - precision_14: 0.9906 - recall_14: 0.9883 - auc_14: 0.9995\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.2659 - accuracy: 0.9956 - precision_14: 0.9977 - recall_14: 0.9930 - auc_14: 1.0000\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0973 - accuracy: 0.9934 - precision_14: 0.9953 - recall_14: 0.9907 - auc_14: 0.9999\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.9522 - accuracy: 0.9901 - precision_14: 0.9929 - recall_14: 0.9860 - auc_14: 0.9996\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.0030 - accuracy: 0.9584 - precision_14: 0.9665 - recall_14: 0.9439 - auc_14: 0.9920\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 2.0696 - accuracy: 0.9836 - precision_14: 0.9791 - recall_14: 0.9860 - auc_14: 0.9988\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.0376 - accuracy: 0.9945 - precision_14: 0.9907 - recall_14: 0.9977 - auc_14: 0.9998\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.8884 - accuracy: 0.9934 - precision_14: 0.9907 - recall_14: 0.9953 - auc_14: 0.9998\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.7283 - accuracy: 0.9956 - precision_14: 0.9977 - recall_14: 0.9930 - auc_14: 0.9999\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6463 - accuracy: 0.9901 - precision_14: 0.9906 - recall_14: 0.9883 - auc_14: 0.9996\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6255 - accuracy: 0.9912 - precision_14: 0.9930 - recall_14: 0.9883 - auc_14: 0.9999\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5396 - accuracy: 0.9978 - precision_14: 0.9953 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4306 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3338 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2545 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1942 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1490 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1090 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0667 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.0257 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9897 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1335 - accuracy: 0.9419 - precision_14: 0.9630 - recall_14: 0.9112 - auc_14: 0.9819\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.2867 - accuracy: 0.9255 - precision_14: 0.9245 - recall_14: 0.9159 - auc_14: 0.9726\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.4070 - accuracy: 0.9650 - precision_14: 0.9605 - recall_14: 0.9650 - auc_14: 0.9926\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 1.3603 - accuracy: 0.9847 - precision_14: 0.9905 - recall_14: 0.9766 - auc_14: 0.9994\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2746 - accuracy: 0.9880 - precision_14: 0.9771 - recall_14: 0.9977 - auc_14: 0.9996\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1791 - accuracy: 0.9912 - precision_14: 0.9953 - recall_14: 0.9860 - auc_14: 0.9995\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0788 - accuracy: 0.9967 - precision_14: 0.9977 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9985 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9424 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9039 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8669 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8306 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7980 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7702 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7427 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7196 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7004 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6886 - accuracy: 0.9967 - precision_14: 0.9953 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7594 - accuracy: 0.9715 - precision_14: 0.9763 - recall_14: 0.9626 - auc_14: 0.9951\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7757 - accuracy: 0.9901 - precision_14: 1.0000 - recall_14: 0.9790 - auc_14: 0.9990\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8eccb89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 58.428% (+/-3.398) \n",
      " Precision: 48.128% (+/-2.106) \n",
      " Recall: 99.773% (+/-0.455) \n",
      " AUC: 89.443% (+/-1.573) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_3(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_3(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_3(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_3(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
