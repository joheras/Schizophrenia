{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[2], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 6250, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(accuracies,precisions,recalls,aucs):\n",
    "    m, s = mean(accuracies), std(accuracies)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(precisions), std(precisions)\n",
    "    print( ' Precision: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(recalls), std(recalls)\n",
    "    print( ' Recall: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(aucs), std(aucs)\n",
    "    print( ' AUC: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7162 - accuracy: 0.5356 - precision: 0.5054 - recall: 0.4369 - auc: 0.5444\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6329 - accuracy: 0.6418 - precision: 0.6135 - recall: 0.6379 - auc: 0.7001\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.5173 - accuracy: 0.7766 - precision: 0.7171 - recall: 0.8645 - auc: 0.8639\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3614 - accuracy: 0.8762 - precision: 0.8706 - recall: 0.8645 - auc: 0.9409\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2541 - accuracy: 0.9211 - precision: 0.9300 - recall: 0.8995 - auc: 0.9718\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2012 - accuracy: 0.9299 - precision: 0.9333 - recall: 0.9159 - auc: 0.9760\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1476 - accuracy: 0.9529 - precision: 0.9446 - recall: 0.9556 - auc: 0.9880\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1420 - accuracy: 0.9441 - precision: 0.9435 - recall: 0.9369 - auc: 0.9903\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1077 - accuracy: 0.9671 - precision: 0.9784 - recall: 0.9509 - auc: 0.9920\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0630 - accuracy: 0.9825 - precision: 0.9905 - recall: 0.9720 - auc: 0.9979\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0618 - accuracy: 0.9825 - precision: 0.9905 - recall: 0.9720 - auc: 0.9973\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0758 - accuracy: 0.9803 - precision: 0.9790 - recall: 0.9790 - auc: 0.9958\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0608 - accuracy: 0.9770 - precision: 0.9811 - recall: 0.9696 - auc: 0.9982\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0399 - accuracy: 0.9923 - precision: 0.9976 - recall: 0.9860 - auc: 0.9993\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0290 - accuracy: 0.9934 - precision: 0.9884 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0278 - accuracy: 0.9956 - precision: 0.9930 - recall: 0.9977 - auc: 0.9993\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0177 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9953 - auc: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0120 - accuracy: 0.9978 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0097 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9953 - auc: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0073 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0051 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0046 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0034 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0044 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0033 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0029 - accuracy: 0.9989 - precision: 0.9977 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 9.5514e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 9.9526e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 5.2952e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 5.9666e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 4.8644e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.7176 - accuracy: 0.5312 - precision_1: 0.5000 - recall_1: 0.4509 - auc_1: 0.5464\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6740 - accuracy: 0.5882 - precision_1: 0.5542 - recall_1: 0.6215 - auc_1: 0.6217\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.5989 - accuracy: 0.6670 - precision_1: 0.6297 - recall_1: 0.7033 - auc_1: 0.7504\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.4736 - accuracy: 0.8050 - precision_1: 0.7790 - recall_1: 0.8154 - auc_1: 0.8805\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 57ms/step - loss: 0.3425 - accuracy: 0.8927 - precision_1: 0.8947 - recall_1: 0.8738 - auc_1: 0.9554\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2557 - accuracy: 0.9179 - precision_1: 0.9133 - recall_1: 0.9112 - auc_1: 0.9725\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1842 - accuracy: 0.9551 - precision_1: 0.9574 - recall_1: 0.9463 - auc_1: 0.9857\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1742 - accuracy: 0.9441 - precision_1: 0.9333 - recall_1: 0.9486 - auc_1: 0.9812\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1354 - accuracy: 0.9617 - precision_1: 0.9538 - recall_1: 0.9650 - auc_1: 0.9886\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2065 - accuracy: 0.9211 - precision_1: 0.9258 - recall_1: 0.9042 - auc_1: 0.9735\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1167 - accuracy: 0.9606 - precision_1: 0.9516 - recall_1: 0.9650 - auc_1: 0.9926\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0886 - accuracy: 0.9781 - precision_1: 0.9880 - recall_1: 0.9650 - auc_1: 0.9951\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0666 - accuracy: 0.9814 - precision_1: 0.9746 - recall_1: 0.9860 - auc_1: 0.9968\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0452 - accuracy: 0.9923 - precision_1: 0.9953 - recall_1: 0.9883 - auc_1: 0.9985\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0671 - accuracy: 0.9814 - precision_1: 0.9703 - recall_1: 0.9907 - auc_1: 0.9974\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0329 - accuracy: 0.9945 - precision_1: 0.9953 - recall_1: 0.9930 - auc_1: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0354 - accuracy: 0.9912 - precision_1: 0.9907 - recall_1: 0.9907 - auc_1: 0.9995\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0237 - accuracy: 0.9956 - precision_1: 1.0000 - recall_1: 0.9907 - auc_1: 0.9998\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0157 - accuracy: 0.9967 - precision_1: 0.9977 - recall_1: 0.9953 - auc_1: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0183 - accuracy: 0.9956 - precision_1: 0.9907 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0139 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0100 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0099 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0137 - accuracy: 0.9956 - precision_1: 0.9907 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0092 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0080 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0057 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0076 - accuracy: 0.9967 - precision_1: 0.9977 - recall_1: 0.9953 - auc_1: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0057 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0042 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0040 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0034 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0028 - accuracy: 0.9989 - precision_1: 0.9977 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0037 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0028 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0030 - accuracy: 0.9989 - precision_1: 0.9977 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0023 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0028 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7339 - accuracy: 0.5268 - precision_2: 0.4951 - recall_2: 0.4743 - auc_2: 0.5381\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6450 - accuracy: 0.5980 - precision_2: 0.5682 - recall_2: 0.5935 - auc_2: 0.6659\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5171 - accuracy: 0.7689 - precision_2: 0.7343 - recall_2: 0.7944 - auc_2: 0.8532\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.3477 - accuracy: 0.8795 - precision_2: 0.8502 - recall_2: 0.9019 - auc_2: 0.9481\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2431 - accuracy: 0.9146 - precision_2: 0.9032 - recall_2: 0.9159 - auc_2: 0.9701\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.1561 - accuracy: 0.9430 - precision_2: 0.9455 - recall_2: 0.9322 - auc_2: 0.9858\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1471 - accuracy: 0.9584 - precision_2: 0.9493 - recall_2: 0.9626 - auc_2: 0.9850\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0862 - accuracy: 0.9792 - precision_2: 0.9789 - recall_2: 0.9766 - auc_2: 0.9933\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0728 - accuracy: 0.9770 - precision_2: 0.9744 - recall_2: 0.9766 - auc_2: 0.9968\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0524 - accuracy: 0.9880 - precision_2: 0.9860 - recall_2: 0.9883 - auc_2: 0.9964\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0406 - accuracy: 0.9912 - precision_2: 0.9907 - recall_2: 0.9907 - auc_2: 0.9976\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0300 - accuracy: 0.9945 - precision_2: 0.9976 - recall_2: 0.9907 - auc_2: 0.9982\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0250 - accuracy: 0.9934 - precision_2: 0.9953 - recall_2: 0.9907 - auc_2: 0.9993\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0131 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0134 - accuracy: 0.9978 - precision_2: 1.0000 - recall_2: 0.9953 - auc_2: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0097 - accuracy: 0.9978 - precision_2: 0.9977 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0059 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0124 - accuracy: 0.9978 - precision_2: 0.9977 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0120 - accuracy: 0.9978 - precision_2: 0.9977 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0099 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0144 - accuracy: 0.9956 - precision_2: 0.9930 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0068 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0075 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0047 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0044 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0027 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0035 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0048 - accuracy: 0.9978 - precision_2: 0.9977 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0038 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0033 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0035 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 9.5139e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 9.4086e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 6.1789e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 5.5138e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 8.0089e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 6.5960e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 5.9301e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 8.7406e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 4.3707e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 6.6635e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 4.6233e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 4.1229e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 7.0598e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.8330e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.0641e-04 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.7517 - accuracy: 0.4874 - precision_3: 0.4543 - recall_3: 0.4650 - auc_3: 0.4852\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.7001 - accuracy: 0.5367 - precision_3: 0.5051 - recall_3: 0.5748 - auc_3: 0.5492\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6570 - accuracy: 0.6090 - precision_3: 0.5820 - recall_3: 0.5888 - auc_3: 0.6443\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.5855 - accuracy: 0.7054 - precision_3: 0.6695 - recall_3: 0.7336 - auc_3: 0.7820\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.4795 - accuracy: 0.8171 - precision_3: 0.8071 - recall_3: 0.8014 - auc_3: 0.9050\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.3776 - accuracy: 0.8861 - precision_3: 0.8894 - recall_3: 0.8645 - auc_3: 0.9447\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.3085 - accuracy: 0.9025 - precision_3: 0.8988 - recall_3: 0.8925 - auc_3: 0.9569\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2390 - accuracy: 0.9233 - precision_3: 0.9262 - recall_3: 0.9089 - auc_3: 0.9756\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1765 - accuracy: 0.9551 - precision_3: 0.9510 - recall_3: 0.9533 - auc_3: 0.9856\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 74ms/step - loss: 0.1453 - accuracy: 0.9584 - precision_3: 0.9577 - recall_3: 0.9533 - auc_3: 0.9905\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1010 - accuracy: 0.9715 - precision_3: 0.9674 - recall_3: 0.9720 - auc_3: 0.9961\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0811 - accuracy: 0.9803 - precision_3: 0.9858 - recall_3: 0.9720 - auc_3: 0.9961\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0567 - accuracy: 0.9923 - precision_3: 0.9930 - recall_3: 0.9907 - auc_3: 0.9992\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0483 - accuracy: 0.9901 - precision_3: 0.9883 - recall_3: 0.9907 - auc_3: 0.9993\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0489 - accuracy: 0.9890 - precision_3: 0.9860 - recall_3: 0.9907 - auc_3: 0.9993\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0387 - accuracy: 0.9923 - precision_3: 0.9930 - recall_3: 0.9907 - auc_3: 0.9997\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0322 - accuracy: 0.9956 - precision_3: 0.9953 - recall_3: 0.9953 - auc_3: 0.9995\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0223 - accuracy: 0.9978 - precision_3: 1.0000 - recall_3: 0.9953 - auc_3: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0210 - accuracy: 0.9967 - precision_3: 0.9953 - recall_3: 0.9977 - auc_3: 0.9998\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0135 - accuracy: 0.9989 - precision_3: 0.9977 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0181 - accuracy: 0.9967 - precision_3: 0.9953 - recall_3: 0.9977 - auc_3: 0.9998\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0124 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0165 - accuracy: 0.9967 - precision_3: 1.0000 - recall_3: 0.9930 - auc_3: 0.9998\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0069 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0079 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0080 - accuracy: 0.9978 - precision_3: 1.0000 - recall_3: 0.9953 - auc_3: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0058 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0056 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0052 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0046 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0054 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0046 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0055 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0043 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0043 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0069 - accuracy: 0.9989 - precision_3: 1.0000 - recall_3: 0.9977 - auc_3: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0044 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0042 - accuracy: 0.9989 - precision_3: 1.0000 - recall_3: 0.9977 - auc_3: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0033 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0040 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0052 - accuracy: 0.9989 - precision_3: 0.9977 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0042 - accuracy: 0.9989 - precision_3: 1.0000 - recall_3: 0.9977 - auc_3: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0030 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0030 - accuracy: 0.9989 - precision_3: 0.9977 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0034 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7206 - accuracy: 0.5115 - precision_4: 0.4715 - recall_4: 0.3481 - auc_4: 0.5064\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.6950 - accuracy: 0.5411 - precision_4: 0.5101 - recall_4: 0.5304 - auc_4: 0.5511\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.6601 - accuracy: 0.5838 - precision_4: 0.5642 - recall_4: 0.4930 - auc_4: 0.6427\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.5896 - accuracy: 0.7196 - precision_4: 0.7077 - recall_4: 0.6846 - auc_4: 0.8042\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5118 - accuracy: 0.8083 - precision_4: 0.7780 - recall_4: 0.8271 - auc_4: 0.8793\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4007 - accuracy: 0.8740 - precision_4: 0.8486 - recall_4: 0.8902 - auc_4: 0.9394\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3113 - accuracy: 0.9058 - precision_4: 0.9014 - recall_4: 0.8972 - auc_4: 0.9654\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2246 - accuracy: 0.9452 - precision_4: 0.9500 - recall_4: 0.9322 - auc_4: 0.9791\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1602 - accuracy: 0.9562 - precision_4: 0.9554 - recall_4: 0.9509 - auc_4: 0.9894\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.1209 - accuracy: 0.9715 - precision_4: 0.9696 - recall_4: 0.9696 - auc_4: 0.9932\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.0923 - accuracy: 0.9770 - precision_4: 0.9744 - recall_4: 0.9766 - auc_4: 0.9950\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0552 - accuracy: 0.9901 - precision_4: 0.9883 - recall_4: 0.9907 - auc_4: 0.9989\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0502 - accuracy: 0.9890 - precision_4: 0.9883 - recall_4: 0.9883 - auc_4: 0.9986\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0404 - accuracy: 0.9934 - precision_4: 0.9953 - recall_4: 0.9907 - auc_4: 0.9992\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0339 - accuracy: 0.9912 - precision_4: 0.9907 - recall_4: 0.9907 - auc_4: 0.9995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0179 - accuracy: 0.9978 - precision_4: 0.9977 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0202 - accuracy: 0.9967 - precision_4: 1.0000 - recall_4: 0.9930 - auc_4: 0.9998\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0140 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0154 - accuracy: 0.9978 - precision_4: 0.9953 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0211 - accuracy: 0.9967 - precision_4: 0.9930 - recall_4: 1.0000 - auc_4: 0.9998\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0121 - accuracy: 0.9978 - precision_4: 0.9953 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0188 - accuracy: 0.9967 - precision_4: 0.9953 - recall_4: 0.9977 - auc_4: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0106 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0061 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0085 - accuracy: 0.9978 - precision_4: 1.0000 - recall_4: 0.9953 - auc_4: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0057 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0065 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0051 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0062 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0039 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0044 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0044 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0039 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0039 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0039 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0039 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0036 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 9.3348e-04 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0021 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb69c3d4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " Accuracy: 93.712% (+/-0.710) \n",
      " Precision: 89.098% (+/-2.505) \n",
      " Recall: 95.455% (+/-1.901) \n",
      " AUC: 96.371% (+/-0.628) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8198 - accuracy: 0.5093 - precision_5: 0.4788 - recall_5: 0.5280 - auc_5: 0.4984\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.6906 - accuracy: 0.5520 - precision_5: 0.5222 - recall_5: 0.5210 - auc_5: 0.5789\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.6692 - accuracy: 0.5739 - precision_5: 0.5589 - recall_5: 0.4322 - auc_5: 0.6181\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5746 - accuracy: 0.7097 - precision_5: 0.6927 - recall_5: 0.6846 - auc_5: 0.7869\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.4906 - accuracy: 0.7820 - precision_5: 0.8053 - recall_5: 0.7056 - auc_5: 0.8791\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3855 - accuracy: 0.8697 - precision_5: 0.8815 - recall_5: 0.8341 - auc_5: 0.9418\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2709 - accuracy: 0.9299 - precision_5: 0.9194 - recall_5: 0.9322 - auc_5: 0.9750\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2300 - accuracy: 0.9255 - precision_5: 0.9286 - recall_5: 0.9112 - auc_5: 0.9748\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1654 - accuracy: 0.9617 - precision_5: 0.9517 - recall_5: 0.9673 - auc_5: 0.9869\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1335 - accuracy: 0.9617 - precision_5: 0.9476 - recall_5: 0.9720 - auc_5: 0.9931\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1271 - accuracy: 0.9573 - precision_5: 0.9431 - recall_5: 0.9673 - auc_5: 0.9922\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1179 - accuracy: 0.9639 - precision_5: 0.9647 - recall_5: 0.9579 - auc_5: 0.9927\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0911 - accuracy: 0.9726 - precision_5: 0.9879 - recall_5: 0.9533 - auc_5: 0.9968\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0801 - accuracy: 0.9737 - precision_5: 0.9698 - recall_5: 0.9743 - auc_5: 0.9972\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0485 - accuracy: 0.9901 - precision_5: 0.9794 - recall_5: 1.0000 - auc_5: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0428 - accuracy: 0.9890 - precision_5: 0.9906 - recall_5: 0.9860 - auc_5: 0.9997\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0305 - accuracy: 0.9945 - precision_5: 0.9885 - recall_5: 1.0000 - auc_5: 0.9999\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0342 - accuracy: 0.9901 - precision_5: 0.9929 - recall_5: 0.9860 - auc_5: 0.9996\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0174 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0171 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0151 - accuracy: 0.9978 - precision_5: 0.9953 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0133 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0134 - accuracy: 0.9978 - precision_5: 0.9953 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0131 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0098 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0086 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0082 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0078 - accuracy: 0.9978 - precision_5: 0.9977 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0076 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0062 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0062 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0059 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0065 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0060 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0057 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0036 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0041 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0036 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0037 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0043 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0028 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0043 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0041 - accuracy: 0.9978 - precision_5: 0.9977 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0036 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb685c41510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.7266 - accuracy: 0.5159 - precision_6: 0.4823 - recall_6: 0.4463 - auc_6: 0.5239\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6488 - accuracy: 0.6156 - precision_6: 0.5877 - recall_6: 0.6028 - auc_6: 0.6580\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.5406 - accuracy: 0.7514 - precision_6: 0.7072 - recall_6: 0.8014 - auc_6: 0.8306\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.3915 - accuracy: 0.8565 - precision_6: 0.8180 - recall_6: 0.8925 - auc_6: 0.9376\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2978 - accuracy: 0.8938 - precision_6: 0.8858 - recall_6: 0.8879 - auc_6: 0.9535\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1916 - accuracy: 0.9398 - precision_6: 0.9368 - recall_6: 0.9346 - auc_6: 0.9821\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1470 - accuracy: 0.9573 - precision_6: 0.9620 - recall_6: 0.9463 - auc_6: 0.9877\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1158 - accuracy: 0.9617 - precision_6: 0.9456 - recall_6: 0.9743 - auc_6: 0.9924\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0870 - accuracy: 0.9748 - precision_6: 0.9765 - recall_6: 0.9696 - auc_6: 0.9959\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0455 - accuracy: 0.9890 - precision_6: 0.9953 - recall_6: 0.9813 - auc_6: 0.9991\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0442 - accuracy: 0.9847 - precision_6: 0.9836 - recall_6: 0.9836 - auc_6: 0.9990\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0240 - accuracy: 0.9967 - precision_6: 0.9953 - recall_6: 0.9977 - auc_6: 0.9999\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0161 - accuracy: 0.9978 - precision_6: 1.0000 - recall_6: 0.9953 - auc_6: 1.0000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0137 - accuracy: 0.9967 - precision_6: 0.9977 - recall_6: 0.9953 - auc_6: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0114 - accuracy: 0.9989 - precision_6: 1.0000 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0080 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0055 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 9.6132e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 6.0274e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 5.9830e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 7.0456e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 8.8187e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 5.0393e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 3.9887e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 5.2216e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 5.6702e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 6.0003e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.5392e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.4438e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 5.2569e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0020 - accuracy: 0.9989 - precision_6: 1.0000 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1082 - accuracy: 0.9551 - precision_6: 0.9490 - recall_6: 0.9556 - auc_6: 0.9921\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0611 - accuracy: 0.9781 - precision_6: 0.9789 - recall_6: 0.9743 - auc_6: 0.9978\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0613 - accuracy: 0.9770 - precision_6: 0.9951 - recall_6: 0.9556 - auc_6: 0.9978\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0448 - accuracy: 0.9825 - precision_6: 0.9769 - recall_6: 0.9860 - auc_6: 0.9988\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb679263400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.6702 - accuracy: 0.5893 - precision_7: 0.5681 - recall_7: 0.5164 - auc_7: 0.6240\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5681 - accuracy: 0.7065 - precision_7: 0.6732 - recall_7: 0.7266 - auc_7: 0.7708\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.4124 - accuracy: 0.8182 - precision_7: 0.7873 - recall_7: 0.8388 - auc_7: 0.9028\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.3127 - accuracy: 0.8751 - precision_7: 0.8428 - recall_7: 0.9019 - auc_7: 0.9449\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1871 - accuracy: 0.9430 - precision_7: 0.9393 - recall_7: 0.9393 - auc_7: 0.9832\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1296 - accuracy: 0.9573 - precision_7: 0.9534 - recall_7: 0.9556 - auc_7: 0.9899\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0996 - accuracy: 0.9628 - precision_7: 0.9581 - recall_7: 0.9626 - auc_7: 0.9936\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1088 - accuracy: 0.9639 - precision_7: 0.9561 - recall_7: 0.9673 - auc_7: 0.9911\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0821 - accuracy: 0.9748 - precision_7: 0.9810 - recall_7: 0.9650 - auc_7: 0.9949\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0357 - accuracy: 0.9901 - precision_7: 0.9906 - recall_7: 0.9883 - auc_7: 0.9997\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0299 - accuracy: 0.9890 - precision_7: 0.9838 - recall_7: 0.9930 - auc_7: 0.9997\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0175 - accuracy: 0.9967 - precision_7: 0.9930 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0105 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 1.0000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0067 - accuracy: 0.9989 - precision_7: 0.9977 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0055 - accuracy: 0.9989 - precision_7: 1.0000 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0058 - accuracy: 0.9989 - precision_7: 1.0000 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0038 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0021 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 7.9891e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 5.9651e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 6.9127e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 7.0580e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 5.1536e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 7.7773e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 4.3003e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 4.0347e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 5.2520e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 3.8085e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 2.5350e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 5.3831e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 3.4223e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 3.4742e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 3.5412e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.8745e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.1917e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.6777e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.9224e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.9545e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.5444e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.0368e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.7511e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.8124e-04 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb685fc3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7533 - accuracy: 0.4984 - precision_8: 0.4678 - recall_8: 0.5093 - auc_8: 0.5149\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6591 - accuracy: 0.6199 - precision_8: 0.6080 - recall_8: 0.5327 - auc_8: 0.6491\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5681 - accuracy: 0.7141 - precision_8: 0.6928 - recall_8: 0.7009 - auc_8: 0.7820\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.4099 - accuracy: 0.8324 - precision_8: 0.8345 - recall_8: 0.8014 - auc_8: 0.9170\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2747 - accuracy: 0.9069 - precision_8: 0.8820 - recall_8: 0.9252 - auc_8: 0.9635\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1923 - accuracy: 0.9387 - precision_8: 0.9326 - recall_8: 0.9369 - auc_8: 0.9821\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1348 - accuracy: 0.9606 - precision_8: 0.9667 - recall_8: 0.9486 - auc_8: 0.9889\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0830 - accuracy: 0.9715 - precision_8: 0.9809 - recall_8: 0.9579 - auc_8: 0.9967\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0906 - accuracy: 0.9693 - precision_8: 0.9717 - recall_8: 0.9626 - auc_8: 0.9960\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0421 - accuracy: 0.9945 - precision_8: 1.0000 - recall_8: 0.9883 - auc_8: 0.9998\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0319 - accuracy: 0.9912 - precision_8: 0.9953 - recall_8: 0.9860 - auc_8: 0.9997\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0251 - accuracy: 0.9967 - precision_8: 0.9930 - recall_8: 1.0000 - auc_8: 0.9999\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0223 - accuracy: 0.9934 - precision_8: 0.9930 - recall_8: 0.9930 - auc_8: 0.9999\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0100 - accuracy: 0.9989 - precision_8: 1.0000 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0087 - accuracy: 0.9978 - precision_8: 0.9977 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0066 - accuracy: 0.9989 - precision_8: 0.9977 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0045 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0036 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0043 - accuracy: 0.9989 - precision_8: 1.0000 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0021 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 9.3595e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 7.7320e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 8.5658e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 6.1572e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 9.1166e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 7.0828e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.8270e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.9620e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 5.0284e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.6566e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 3.5321e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.0148e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 6.2079e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 8.8388e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.7638e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 4.0817e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.9196e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 5.4048e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.5175e-04 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb679a19e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.8380 - accuracy: 0.5148 - precision_9: 0.4661 - recall_9: 0.2407 - auc_9: 0.4883\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.7104 - accuracy: 0.5060 - precision_9: 0.4811 - recall_9: 0.6846 - auc_9: 0.5236\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.6791 - accuracy: 0.5608 - precision_9: 0.5271 - recall_9: 0.6145 - auc_9: 0.5914\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.6545 - accuracy: 0.6112 - precision_9: 0.5788 - recall_9: 0.6262 - auc_9: 0.6647\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.5976 - accuracy: 0.7032 - precision_9: 0.7289 - recall_9: 0.5841 - auc_9: 0.7927\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.5034 - accuracy: 0.8061 - precision_9: 0.8329 - recall_9: 0.7336 - auc_9: 0.9095\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4034 - accuracy: 0.8861 - precision_9: 0.8913 - recall_9: 0.8621 - auc_9: 0.9537\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3308 - accuracy: 0.9124 - precision_9: 0.8973 - recall_9: 0.9182 - auc_9: 0.9625\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2544 - accuracy: 0.9387 - precision_9: 0.9346 - recall_9: 0.9346 - auc_9: 0.9751\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2233 - accuracy: 0.9463 - precision_9: 0.9356 - recall_9: 0.9509 - auc_9: 0.9775\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.1856 - accuracy: 0.9485 - precision_9: 0.9441 - recall_9: 0.9463 - auc_9: 0.9838\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.1429 - accuracy: 0.9682 - precision_9: 0.9716 - recall_9: 0.9603 - auc_9: 0.9902\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1239 - accuracy: 0.9671 - precision_9: 0.9784 - recall_9: 0.9509 - auc_9: 0.9925\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1078 - accuracy: 0.9759 - precision_9: 0.9656 - recall_9: 0.9836 - auc_9: 0.9943\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0828 - accuracy: 0.9825 - precision_9: 0.9836 - recall_9: 0.9790 - auc_9: 0.9978\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0672 - accuracy: 0.9825 - precision_9: 0.9952 - recall_9: 0.9673 - auc_9: 0.9986\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0567 - accuracy: 0.9901 - precision_9: 0.9976 - recall_9: 0.9813 - auc_9: 0.9992\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1084 - accuracy: 0.9660 - precision_9: 0.9853 - recall_9: 0.9416 - auc_9: 0.9942\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0885 - accuracy: 0.9682 - precision_9: 0.9784 - recall_9: 0.9533 - auc_9: 0.9961\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0558 - accuracy: 0.9847 - precision_9: 0.9748 - recall_9: 0.9930 - auc_9: 0.9988\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0612 - accuracy: 0.9814 - precision_9: 0.9928 - recall_9: 0.9673 - auc_9: 0.9972\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0487 - accuracy: 0.9890 - precision_9: 0.9838 - recall_9: 0.9930 - auc_9: 0.9994\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0383 - accuracy: 0.9934 - precision_9: 0.9930 - recall_9: 0.9930 - auc_9: 0.9996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0287 - accuracy: 0.9956 - precision_9: 0.9930 - recall_9: 0.9977 - auc_9: 0.9998\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0263 - accuracy: 0.9967 - precision_9: 1.0000 - recall_9: 0.9930 - auc_9: 0.9998\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0228 - accuracy: 0.9956 - precision_9: 0.9953 - recall_9: 0.9953 - auc_9: 0.9997\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0207 - accuracy: 0.9956 - precision_9: 0.9977 - recall_9: 0.9930 - auc_9: 0.9998\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0150 - accuracy: 0.9978 - precision_9: 0.9977 - recall_9: 0.9977 - auc_9: 0.9999\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0154 - accuracy: 0.9978 - precision_9: 0.9977 - recall_9: 0.9977 - auc_9: 0.9998\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0110 - accuracy: 0.9989 - precision_9: 0.9977 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0119 - accuracy: 0.9978 - precision_9: 0.9977 - recall_9: 0.9977 - auc_9: 0.9999\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0128 - accuracy: 0.9978 - precision_9: 1.0000 - recall_9: 0.9953 - auc_9: 0.9999\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0086 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0092 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 0.9999\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0068 - accuracy: 0.9989 - precision_9: 0.9977 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0078 - accuracy: 0.9978 - precision_9: 1.0000 - recall_9: 0.9953 - auc_9: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0073 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0080 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 0.9999\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0068 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0058 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0039 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0038 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0050 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0045 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0047 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0061 - accuracy: 0.9989 - precision_9: 0.9977 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0029 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0054 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58062fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 74.061% (+/-19.978) \n",
      " Precision: 65.837% (+/-27.499) \n",
      " Recall: 58.409% (+/-32.916) \n",
      " AUC: 78.327% (+/-20.994) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3),input_shape=(None,n_length,n_features)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.8642 - accuracy: 0.5323 - precision_10: 0.5010 - recall_10: 0.5864 - auc_10: 0.5382\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.6801 - accuracy: 0.5641 - precision_10: 0.5421 - recall_10: 0.4509 - auc_10: 0.6133\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.5721 - accuracy: 0.7076 - precision_10: 0.6716 - recall_10: 0.7360 - auc_10: 0.7795\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.4658 - accuracy: 0.7974 - precision_10: 0.7900 - recall_10: 0.7734 - auc_10: 0.8740\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3541 - accuracy: 0.8554 - precision_10: 0.8491 - recall_10: 0.8411 - auc_10: 0.9294\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2703 - accuracy: 0.9036 - precision_10: 0.8846 - recall_10: 0.9136 - auc_10: 0.9629\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2267 - accuracy: 0.9157 - precision_10: 0.8980 - recall_10: 0.9252 - auc_10: 0.9702\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1670 - accuracy: 0.9463 - precision_10: 0.9356 - recall_10: 0.9509 - auc_10: 0.9853\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1222 - accuracy: 0.9595 - precision_10: 0.9474 - recall_10: 0.9673 - auc_10: 0.9917\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0956 - accuracy: 0.9715 - precision_10: 0.9718 - recall_10: 0.9673 - auc_10: 0.9953\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0697 - accuracy: 0.9825 - precision_10: 0.9858 - recall_10: 0.9766 - auc_10: 0.9981\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0615 - accuracy: 0.9836 - precision_10: 0.9859 - recall_10: 0.9790 - auc_10: 0.9971\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0513 - accuracy: 0.9890 - precision_10: 0.9976 - recall_10: 0.9790 - auc_10: 0.9986\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0497 - accuracy: 0.9869 - precision_10: 0.9929 - recall_10: 0.9790 - auc_10: 0.9984\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0355 - accuracy: 0.9923 - precision_10: 0.9861 - recall_10: 0.9977 - auc_10: 0.9990\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0588 - accuracy: 0.9759 - precision_10: 0.9856 - recall_10: 0.9626 - auc_10: 0.9980\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0541 - accuracy: 0.9825 - precision_10: 0.9952 - recall_10: 0.9673 - auc_10: 0.9985\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0375 - accuracy: 0.9912 - precision_10: 0.9839 - recall_10: 0.9977 - auc_10: 0.9991\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0378 - accuracy: 0.9890 - precision_10: 0.9953 - recall_10: 0.9813 - auc_10: 0.9982\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0358 - accuracy: 0.9934 - precision_10: 0.9884 - recall_10: 0.9977 - auc_10: 0.9981\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0264 - accuracy: 0.9912 - precision_10: 0.9930 - recall_10: 0.9883 - auc_10: 0.9998\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0242 - accuracy: 0.9923 - precision_10: 0.9907 - recall_10: 0.9930 - auc_10: 0.9997\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0162 - accuracy: 0.9945 - precision_10: 0.9976 - recall_10: 0.9907 - auc_10: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0201 - accuracy: 0.9945 - precision_10: 1.0000 - recall_10: 0.9883 - auc_10: 0.9996\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0143 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 0.9995\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0106 - accuracy: 0.9978 - precision_10: 0.9953 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0126 - accuracy: 0.9945 - precision_10: 0.9976 - recall_10: 0.9907 - auc_10: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0115 - accuracy: 0.9967 - precision_10: 1.0000 - recall_10: 0.9930 - auc_10: 0.9998\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0072 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0060 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0068 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0059 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9976 - auc_10: 1.00 - 1s 63ms/step - loss: 0.0052 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0044 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0054 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0048 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0061 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0078 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0048 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0041 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0055 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0061 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0032 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0033 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 8.6531e-04 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb69c3d4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7793 - accuracy: 0.5750 - precision_11: 0.5565 - recall_11: 0.4603 - auc_11: 0.5854\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6318 - accuracy: 0.6484 - precision_11: 0.6055 - recall_11: 0.7173 - auc_11: 0.7038\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.5240 - accuracy: 0.7349 - precision_11: 0.7204 - recall_11: 0.7103 - auc_11: 0.8184\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.3782 - accuracy: 0.8313 - precision_11: 0.8072 - recall_11: 0.8411 - auc_11: 0.9215\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2735 - accuracy: 0.8872 - precision_11: 0.8753 - recall_11: 0.8855 - auc_11: 0.9581\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1755 - accuracy: 0.9332 - precision_11: 0.9318 - recall_11: 0.9252 - auc_11: 0.9823\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.1433 - accuracy: 0.9551 - precision_11: 0.9532 - recall_11: 0.9509 - auc_11: 0.9880\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0995 - accuracy: 0.9650 - precision_11: 0.9806 - recall_11: 0.9439 - auc_11: 0.9950\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0773 - accuracy: 0.9792 - precision_11: 0.9928 - recall_11: 0.9626 - auc_11: 0.9971\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0547 - accuracy: 0.9847 - precision_11: 0.9836 - recall_11: 0.9836 - auc_11: 0.9979\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0477 - accuracy: 0.9858 - precision_11: 0.9837 - recall_11: 0.9860 - auc_11: 0.9991\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0461 - accuracy: 0.9858 - precision_11: 0.9882 - recall_11: 0.9813 - auc_11: 0.9988\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0341 - accuracy: 0.9912 - precision_11: 1.0000 - recall_11: 0.9813 - auc_11: 0.9996\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0314 - accuracy: 0.9901 - precision_11: 0.9929 - recall_11: 0.9860 - auc_11: 0.9997\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0264 - accuracy: 0.9923 - precision_11: 0.9930 - recall_11: 0.9907 - auc_11: 0.9997\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0229 - accuracy: 0.9945 - precision_11: 1.0000 - recall_11: 0.9883 - auc_11: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0244 - accuracy: 0.9934 - precision_11: 0.9907 - recall_11: 0.9953 - auc_11: 0.9992\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0265 - accuracy: 0.9912 - precision_11: 1.0000 - recall_11: 0.9813 - auc_11: 0.9998\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0191 - accuracy: 0.9923 - precision_11: 0.9884 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0331 - accuracy: 0.9869 - precision_11: 0.9749 - recall_11: 0.9977 - auc_11: 0.9997\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0419 - accuracy: 0.9836 - precision_11: 0.9905 - recall_11: 0.9743 - auc_11: 0.9993\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0217 - accuracy: 0.9923 - precision_11: 1.0000 - recall_11: 0.9836 - auc_11: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0253 - accuracy: 0.9912 - precision_11: 0.9930 - recall_11: 0.9883 - auc_11: 0.9997\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0198 - accuracy: 0.9934 - precision_11: 0.9953 - recall_11: 0.9907 - auc_11: 0.9999\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0161 - accuracy: 0.9945 - precision_11: 0.9976 - recall_11: 0.9907 - auc_11: 0.9999\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0119 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0062 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0056 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0110 - accuracy: 0.9956 - precision_11: 0.9953 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0088 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0045 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0043 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0052 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0039 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0024 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0020 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0044 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0033 - accuracy: 0.9978 - precision_11: 1.0000 - recall_11: 0.9953 - auc_11: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0033 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 9.5340e-04 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 7.5696e-04 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0052 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0046 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0019 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0041 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0047 - accuracy: 0.9978 - precision_11: 1.0000 - recall_11: 0.9953 - auc_11: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb67e19f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.9311 - accuracy: 0.4896 - precision_12: 0.4632 - recall_12: 0.5584 - auc_12: 0.4991\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7377 - accuracy: 0.5411 - precision_12: 0.5130 - recall_12: 0.4159 - auc_12: 0.5498\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6835 - accuracy: 0.5936 - precision_12: 0.5714 - recall_12: 0.5327 - auc_12: 0.6170\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6329 - accuracy: 0.6331 - precision_12: 0.6274 - recall_12: 0.5350 - auc_12: 0.6903\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5471 - accuracy: 0.7317 - precision_12: 0.7226 - recall_12: 0.6939 - auc_12: 0.7978\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4458 - accuracy: 0.8050 - precision_12: 0.7976 - recall_12: 0.7827 - auc_12: 0.8857\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3528 - accuracy: 0.8642 - precision_12: 0.8455 - recall_12: 0.8692 - auc_12: 0.9371\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2931 - accuracy: 0.8938 - precision_12: 0.8805 - recall_12: 0.8949 - auc_12: 0.9544\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2298 - accuracy: 0.9189 - precision_12: 0.9155 - recall_12: 0.9112 - auc_12: 0.9729\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1700 - accuracy: 0.9452 - precision_12: 0.9522 - recall_12: 0.9299 - auc_12: 0.9887\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1266 - accuracy: 0.9628 - precision_12: 0.9477 - recall_12: 0.9743 - auc_12: 0.9940\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1111 - accuracy: 0.9584 - precision_12: 0.9621 - recall_12: 0.9486 - auc_12: 0.9938\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0879 - accuracy: 0.9715 - precision_12: 0.9855 - recall_12: 0.9533 - auc_12: 0.9958\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0637 - accuracy: 0.9858 - precision_12: 0.9882 - recall_12: 0.9813 - auc_12: 0.9985\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0557 - accuracy: 0.9847 - precision_12: 0.9929 - recall_12: 0.9743 - auc_12: 0.9992\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0489 - accuracy: 0.9836 - precision_12: 0.9791 - recall_12: 0.9860 - auc_12: 0.9991\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0325 - accuracy: 0.9945 - precision_12: 0.9976 - recall_12: 0.9907 - auc_12: 0.9996\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0359 - accuracy: 0.9912 - precision_12: 0.9907 - recall_12: 0.9907 - auc_12: 0.9995\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0302 - accuracy: 0.9912 - precision_12: 0.9953 - recall_12: 0.9860 - auc_12: 0.9997\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0328 - accuracy: 0.9923 - precision_12: 0.9907 - recall_12: 0.9930 - auc_12: 0.9989\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0273 - accuracy: 0.9923 - precision_12: 0.9953 - recall_12: 0.9883 - auc_12: 0.9997\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0236 - accuracy: 0.9934 - precision_12: 0.9930 - recall_12: 0.9930 - auc_12: 0.9996\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0195 - accuracy: 0.9978 - precision_12: 1.0000 - recall_12: 0.9953 - auc_12: 0.9995\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0200 - accuracy: 0.9934 - precision_12: 0.9930 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0191 - accuracy: 0.9923 - precision_12: 0.9907 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0091 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0115 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0140 - accuracy: 0.9945 - precision_12: 0.9953 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0071 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0064 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0094 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0070 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0056 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0092 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0066 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0043 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0054 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0051 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0035 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0038 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0035 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0038 - accuracy: 0.9978 - precision_12: 1.0000 - recall_12: 0.9953 - auc_12: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0036 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0038 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0032 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0039 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0023 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58046c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6803 - accuracy: 0.5816 - precision_13: 0.5553 - recall_13: 0.5397 - auc_13: 0.6338\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5228 - accuracy: 0.7426 - precision_13: 0.7292 - recall_13: 0.7173 - auc_13: 0.8165\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3760 - accuracy: 0.8215 - precision_13: 0.7964 - recall_13: 0.8318 - auc_13: 0.9141\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2311 - accuracy: 0.9069 - precision_13: 0.9016 - recall_13: 0.8995 - auc_13: 0.9706\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1282 - accuracy: 0.9562 - precision_13: 0.9597 - recall_13: 0.9463 - auc_13: 0.9922\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0709 - accuracy: 0.9825 - precision_13: 0.9769 - recall_13: 0.9860 - auc_13: 0.9980\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0492 - accuracy: 0.9858 - precision_13: 0.9837 - recall_13: 0.9860 - auc_13: 0.9987\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0431 - accuracy: 0.9880 - precision_13: 0.9929 - recall_13: 0.9813 - auc_13: 0.9993 0s - loss: 0.0515 - accuracy: 0.9844 - precision_13: 0.9884 - recall_13: 0.9770 - auc_\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0368 - accuracy: 0.9847 - precision_13: 0.9882 - recall_13: 0.9790 - auc_13: 0.9993 0s - loss: 0.0374 - accuracy: 0.9844 - precision_13: 0.9880 - recall_13: 0.9787 - auc_13: 0.99\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0396 - accuracy: 0.9880 - precision_13: 0.9860 - recall_13: 0.9883 - auc_13: 0.9994\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0241 - accuracy: 0.9945 - precision_13: 0.9907 - recall_13: 0.9977 - auc_13: 0.9999\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0227 - accuracy: 0.9945 - precision_13: 0.9953 - recall_13: 0.9930 - auc_13: 0.9999\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0217 - accuracy: 0.9923 - precision_13: 0.9976 - recall_13: 0.9860 - auc_13: 0.9999\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0139 - accuracy: 0.9978 - precision_13: 0.9953 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0066 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0050 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0047 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0033 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0022 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0010 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0015 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0026 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 7.9249e-04 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0024 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0046 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0079 - accuracy: 0.9978 - precision_13: 1.0000 - recall_13: 0.9953 - auc_13: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0200 - accuracy: 0.9934 - precision_13: 0.9884 - recall_13: 0.9977 - auc_13: 0.9997\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0321 - accuracy: 0.9869 - precision_13: 0.9883 - recall_13: 0.9836 - auc_13: 0.9983\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0190 - accuracy: 0.9890 - precision_13: 1.0000 - recall_13: 0.9766 - auc_13: 0.9999\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0228 - accuracy: 0.9934 - precision_13: 0.9884 - recall_13: 0.9977 - auc_13: 0.9997\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0045 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0055 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0032 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 8.6536e-04 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0013 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0016 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0028 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 7.2222e-04 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 9.0164e-04 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58046cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8367 - accuracy: 0.5246 - precision_14: 0.4935 - recall_14: 0.5304 - auc_14: 0.5347\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.6451 - accuracy: 0.6320 - precision_14: 0.5954 - recall_14: 0.6706 - auc_14: 0.6881\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5360 - accuracy: 0.7327 - precision_14: 0.7738 - recall_14: 0.6075 - auc_14: 0.8165\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4115 - accuracy: 0.8226 - precision_14: 0.8037 - recall_14: 0.8224 - auc_14: 0.9042\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2798 - accuracy: 0.9102 - precision_14: 0.8932 - recall_14: 0.9182 - auc_14: 0.9558\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2148 - accuracy: 0.9113 - precision_14: 0.8934 - recall_14: 0.9206 - auc_14: 0.9750\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1661 - accuracy: 0.9452 - precision_14: 0.9375 - recall_14: 0.9463 - auc_14: 0.9856\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1175 - accuracy: 0.9682 - precision_14: 0.9694 - recall_14: 0.9626 - auc_14: 0.9935\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1231 - accuracy: 0.9573 - precision_14: 0.9576 - recall_14: 0.9509 - auc_14: 0.9913\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0582 - accuracy: 0.9847 - precision_14: 0.9836 - recall_14: 0.9836 - auc_14: 0.9986\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0539 - accuracy: 0.9814 - precision_14: 0.9858 - recall_14: 0.9743 - auc_14: 0.9990\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0355 - accuracy: 0.9923 - precision_14: 0.9953 - recall_14: 0.9883 - auc_14: 0.9998\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0259 - accuracy: 0.9956 - precision_14: 0.9930 - recall_14: 0.9977 - auc_14: 0.9998\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0351 - accuracy: 0.9869 - precision_14: 0.9929 - recall_14: 0.9790 - auc_14: 0.9994\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0295 - accuracy: 0.9934 - precision_14: 1.0000 - recall_14: 0.9860 - auc_14: 0.9995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0173 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0154 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0139 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 0.9999\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0126 - accuracy: 0.9956 - precision_14: 1.0000 - recall_14: 0.9907 - auc_14: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0115 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0125 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 0.9999\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0114 - accuracy: 0.9967 - precision_14: 0.9977 - recall_14: 0.9953 - auc_14: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0086 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0057 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0077 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0130 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 0.9998\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0086 - accuracy: 0.9967 - precision_14: 1.0000 - recall_14: 0.9930 - auc_14: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0082 - accuracy: 0.9967 - precision_14: 0.9930 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0075 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0072 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0045 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0042 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0037 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0035 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0033 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0055 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0054 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0042 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0042 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0043 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0038 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0037 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0022 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0027 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0031 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb67ddde268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 59.738% (+/-1.472) \n",
      " Precision: 41.140% (+/-6.920) \n",
      " Recall: 8.409% (+/-3.182) \n",
      " AUC: 50.951% (+/-2.379) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_3(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu'),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='selu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_3(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_3(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_3(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
