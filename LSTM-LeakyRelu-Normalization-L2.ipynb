{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[3], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 30, 16\n",
    "    n_timesteps, n_features = trainX.shape[1], trainX.shape[2]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01), input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(accuracies,precisions,recalls,aucs):\n",
    "    m, s = mean(accuracies), std(accuracies)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(precisions), std(precisions)\n",
    "    print( ' Precision: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(recalls), std(recalls)\n",
    "    print( ' Recall: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(aucs), std(aucs)\n",
    "    print( ' AUC: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "58/58 [==============================] - 9s 160ms/step - loss: 3.1730 - accuracy: 0.5356 - precision: 0.5070 - recall: 0.3388 - auc: 0.5642\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 2.1605 - accuracy: 0.6013 - precision: 0.5860 - recall: 0.5093 - auc: 0.6515\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 10s 175ms/step - loss: 1.7069 - accuracy: 0.6835 - precision: 0.6675 - recall: 0.6472 - auc: 0.7400\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 10s 176ms/step - loss: 1.4562 - accuracy: 0.7185 - precision: 0.7221 - recall: 0.6495 - auc: 0.7976\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.2822 - accuracy: 0.7689 - precision: 0.7304 - recall: 0.8037 - auc: 0.8303\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 10s 176ms/step - loss: 1.1813 - accuracy: 0.7700 - precision: 0.7243 - recall: 0.8224 - auc: 0.8397\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.0523 - accuracy: 0.8138 - precision: 0.7792 - recall: 0.8411 - auc: 0.8742\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 1.0679 - accuracy: 0.7371 - precision: 0.7098 - recall: 0.7430 - auc: 0.8189\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 10s 177ms/step - loss: 0.9628 - accuracy: 0.7919 - precision: 0.7861 - recall: 0.7640 - auc: 0.8605\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 10s 177ms/step - loss: 0.8940 - accuracy: 0.8094 - precision: 0.7981 - recall: 0.7944 - auc: 0.8811\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.8703 - accuracy: 0.8083 - precision: 0.8155 - recall: 0.7640 - auc: 0.8718\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 0.8853 - accuracy: 0.7645 - precision: 0.7494 - recall: 0.7477 - auc: 0.8428\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 0.8342 - accuracy: 0.8061 - precision: 0.7676 - recall: 0.8411 - auc: 0.8520\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 10s 177ms/step - loss: 0.9213 - accuracy: 0.7415 - precision: 0.6875 - recall: 0.8224 - auc: 0.7550\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 0.8273 - accuracy: 0.7667 - precision: 0.6965 - recall: 0.8902 - auc: 0.7740\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 10s 176ms/step - loss: 0.7885 - accuracy: 0.7864 - precision: 0.7473 - recall: 0.8224 - auc: 0.7943\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.0736 - accuracy: 0.5652 - precision: 0.5375 - recall: 0.5187 - auc: 0.5992\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.1209 - accuracy: 0.4754 - precision: 0.4388 - recall: 0.4276 - auc: 0.4673\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 1.0717 - accuracy: 0.5312 - precision: 0.5000 - recall: 0.4509 - auc: 0.5271\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 1.0484 - accuracy: 0.5027 - precision: 0.4508 - recall: 0.2780 - auc: 0.5172\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 1.0317 - accuracy: 0.5071 - precision: 0.4481 - recall: 0.2220 - auc: 0.4976\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.0136 - accuracy: 0.4995 - precision: 0.4378 - recall: 0.2383 - auc: 0.4899\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.9986 - accuracy: 0.5235 - precision: 0.4706 - recall: 0.1308 - auc: 0.4930\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9829 - accuracy: 0.5192 - precision: 0.4641 - recall: 0.1659 - auc: 0.5274\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.9738 - accuracy: 0.5389 - precision: 0.5354 - recall: 0.1238 - auc: 0.4970\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.9639 - accuracy: 0.5027 - precision: 0.3375 - recall: 0.0631 - auc: 0.4977\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9513 - accuracy: 0.5159 - precision: 0.4818 - recall: 0.4322 - auc: 0.5225\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9415 - accuracy: 0.5422 - precision: 0.5806 - recall: 0.0841 - auc: 0.5299\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.9347 - accuracy: 0.5159 - precision: 0.3654 - recall: 0.0444 - auc: 0.5214\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.9247 - accuracy: 0.5400 - precision: 0.6667 - recall: 0.0374 - auc: 0.5444\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 10s 175ms/step - loss: 3.1557 - accuracy: 0.5203 - precision_1: 0.4845 - recall_1: 0.3645 - auc_1: 0.5496\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 10s 176ms/step - loss: 2.1169 - accuracy: 0.6177 - precision_1: 0.6193 - recall_1: 0.4790 - auc_1: 0.6835\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 10s 175ms/step - loss: 1.6905 - accuracy: 0.6703 - precision_1: 0.6299 - recall_1: 0.7196 - auc_1: 0.7436\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 1.5111 - accuracy: 0.6835 - precision_1: 0.6234 - recall_1: 0.8201 - auc_1: 0.7325\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.3350 - accuracy: 0.7317 - precision_1: 0.6723 - recall_1: 0.8341 - auc_1: 0.7682\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.2403 - accuracy: 0.7667 - precision_1: 0.7929 - recall_1: 0.6799 - auc_1: 0.7970\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.2920 - accuracy: 0.6276 - precision_1: 0.7075 - recall_1: 0.3505 - auc_1: 0.6181\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.2108 - accuracy: 0.5958 - precision_1: 0.6057 - recall_1: 0.3949 - auc_1: 0.6691\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.1201 - accuracy: 0.6484 - precision_1: 0.7149 - recall_1: 0.4159 - auc_1: 0.7321\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.0158 - accuracy: 0.7174 - precision_1: 0.7322 - recall_1: 0.6262 - auc_1: 0.7922\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.9444 - accuracy: 0.7744 - precision_1: 0.7392 - recall_1: 0.8014 - auc_1: 0.8141\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.9464 - accuracy: 0.6999 - precision_1: 0.7081 - recall_1: 0.6121 - auc_1: 0.7874\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.8527 - accuracy: 0.7897 - precision_1: 0.7906 - recall_1: 0.7500 - auc_1: 0.8375\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.8341 - accuracy: 0.7755 - precision_1: 0.8232 - recall_1: 0.6636 - auc_1: 0.8240\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.8609 - accuracy: 0.7196 - precision_1: 0.7251 - recall_1: 0.6472 - auc_1: 0.8061\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.8525 - accuracy: 0.7054 - precision_1: 0.6556 - recall_1: 0.7827 - auc_1: 0.7821\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.7940 - accuracy: 0.7536 - precision_1: 0.7026 - recall_1: 0.8224 - auc_1: 0.8270\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.7281 - accuracy: 0.7831 - precision_1: 0.7522 - recall_1: 0.8014 - auc_1: 0.8615\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7098 - accuracy: 0.7919 - precision_1: 0.7793 - recall_1: 0.7757 - auc_1: 0.8599\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7631 - accuracy: 0.7733 - precision_1: 0.7483 - recall_1: 0.7780 - auc_1: 0.8198\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.8918 - accuracy: 0.6550 - precision_1: 0.6438 - recall_1: 0.5911 - auc_1: 0.6699\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.7310 - accuracy: 0.7788 - precision_1: 0.8038 - recall_1: 0.6986 - auc_1: 0.8112\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 10s 181ms/step - loss: 0.7401 - accuracy: 0.7766 - precision_1: 0.7843 - recall_1: 0.7220 - auc_1: 0.7886\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.6473 - accuracy: 0.8204 - precision_1: 0.7946 - recall_1: 0.8318 - auc_1: 0.8494\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.0089 - accuracy: 0.5827 - precision_1: 0.5781 - recall_1: 0.4065 - auc_1: 0.5940\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.9317 - accuracy: 0.5915 - precision_1: 0.5779 - recall_1: 0.4766 - auc_1: 0.5897\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.8982 - accuracy: 0.6002 - precision_1: 0.5908 - recall_1: 0.4790 - auc_1: 0.5969\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.8716 - accuracy: 0.6166 - precision_1: 0.6161 - recall_1: 0.4836 - auc_1: 0.6109\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.8478 - accuracy: 0.6320 - precision_1: 0.6285 - recall_1: 0.5257 - auc_1: 0.6135\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.8242 - accuracy: 0.6386 - precision_1: 0.6424 - recall_1: 0.5164 - auc_1: 0.6482\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 3.1604 - accuracy: 0.5279 - precision_2: 0.4954 - recall_2: 0.3738 - auc_2: 0.5593\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 2.1324 - accuracy: 0.6320 - precision_2: 0.6217 - recall_2: 0.5491 - auc_2: 0.6665\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 10s 176ms/step - loss: 1.6748 - accuracy: 0.6583 - precision_2: 0.6495 - recall_2: 0.5888 - auc_2: 0.7469\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 1.4874 - accuracy: 0.6988 - precision_2: 0.6521 - recall_2: 0.7664 - auc_2: 0.7481\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 1.2844 - accuracy: 0.7514 - precision_2: 0.7289 - recall_2: 0.7477 - auc_2: 0.8146\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.1722 - accuracy: 0.7547 - precision_2: 0.7065 - recall_2: 0.8154 - auc_2: 0.8290\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 1.0677 - accuracy: 0.7722 - precision_2: 0.7444 - recall_2: 0.7827 - auc_2: 0.8562\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 1.1150 - accuracy: 0.7174 - precision_2: 0.7249 - recall_2: 0.6402 - auc_2: 0.7873\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9958 - accuracy: 0.7590 - precision_2: 0.7281 - recall_2: 0.7757 - auc_2: 0.8309\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 11s 183ms/step - loss: 0.9082 - accuracy: 0.7842 - precision_2: 0.7495 - recall_2: 0.8107 - auc_2: 0.8646\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.8581 - accuracy: 0.7974 - precision_2: 0.7743 - recall_2: 0.8014 - auc_2: 0.8669\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.8143 - accuracy: 0.8127 - precision_2: 0.7981 - recall_2: 0.8037 - auc_2: 0.8793\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7513 - accuracy: 0.8357 - precision_2: 0.8159 - recall_2: 0.8388 - auc_2: 0.8902\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7362 - accuracy: 0.8291 - precision_2: 0.8148 - recall_2: 0.8224 - auc_2: 0.8903\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7800 - accuracy: 0.7612 - precision_2: 0.7638 - recall_2: 0.7103 - auc_2: 0.8517\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6888 - accuracy: 0.8313 - precision_2: 0.7953 - recall_2: 0.8621 - auc_2: 0.8980\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.7133 - accuracy: 0.8204 - precision_2: 0.8143 - recall_2: 0.7991 - auc_2: 0.8683\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.8214 - accuracy: 0.6988 - precision_2: 0.7167 - recall_2: 0.5911 - auc_2: 0.7714\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.7576 - accuracy: 0.7547 - precision_2: 0.7287 - recall_2: 0.7593 - auc_2: 0.8326\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.8434 - accuracy: 0.6988 - precision_2: 0.6997 - recall_2: 0.6262 - auc_2: 0.7626\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7178 - accuracy: 0.7952 - precision_2: 0.7876 - recall_2: 0.7710 - auc_2: 0.8546\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.7239 - accuracy: 0.7733 - precision_2: 0.7089 - recall_2: 0.8762 - auc_2: 0.8247\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6891 - accuracy: 0.8193 - precision_2: 0.7852 - recall_2: 0.8458 - auc_2: 0.8540\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.6304 - accuracy: 0.8302 - precision_2: 0.8289 - recall_2: 0.8037 - auc_2: 0.8851\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 11s 183ms/step - loss: 0.6564 - accuracy: 0.8072 - precision_2: 0.7414 - recall_2: 0.9042 - auc_2: 0.8659\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6181 - accuracy: 0.8368 - precision_2: 0.7987 - recall_2: 0.8715 - auc_2: 0.8768\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.5638 - accuracy: 0.8642 - precision_2: 0.8671 - recall_2: 0.8388 - auc_2: 0.8973\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.5942 - accuracy: 0.8324 - precision_2: 0.7932 - recall_2: 0.8692 - auc_2: 0.8828\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.6922 - accuracy: 0.7678 - precision_2: 0.6935 - recall_2: 0.9042 - auc_2: 0.8400\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6007 - accuracy: 0.8182 - precision_2: 0.7937 - recall_2: 0.8271 - auc_2: 0.8873\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 3.1622 - accuracy: 0.5334 - precision_3: 0.5031 - recall_3: 0.3785 - auc_3: 0.5583\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 2.1307 - accuracy: 0.5871 - precision_3: 0.5836 - recall_3: 0.4159 - auc_3: 0.6541\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 10s 177ms/step - loss: 1.6876 - accuracy: 0.6506 - precision_3: 0.6518 - recall_3: 0.5467 - auc_3: 0.7295\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.5417 - accuracy: 0.6112 - precision_3: 0.5855 - recall_3: 0.5841 - auc_3: 0.67631s - loss: 1.5632 - accuracy: 0.6117 - precision_3: 0.5671 - recall_3: 0.6070 - a\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.3437 - accuracy: 0.6627 - precision_3: 0.6255 - recall_3: 0.6986 - auc_3: 0.7372\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 1.1881 - accuracy: 0.7404 - precision_3: 0.6840 - recall_3: 0.8294 - auc_3: 0.8061\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 1.1119 - accuracy: 0.7360 - precision_3: 0.6816 - recall_3: 0.8201 - auc_3: 0.8025\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.0782 - accuracy: 0.7284 - precision_3: 0.7000 - recall_3: 0.7360 - auc_3: 0.7866\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.9607 - accuracy: 0.7853 - precision_3: 0.7762 - recall_3: 0.7617 - auc_3: 0.84090s - loss: 0.9611 - accuracy: 0.7851 - precision_3: 0.7757 - recall_3: 0.7611 - auc_3: 0.84\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.9491 - accuracy: 0.7558 - precision_3: 0.7079 - recall_3: 0.8154 - auc_3: 0.8249\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9077 - accuracy: 0.7733 - precision_3: 0.7397 - recall_3: 0.7967 - auc_3: 0.8319\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.8601 - accuracy: 0.7656 - precision_3: 0.7229 - recall_3: 0.8107 - auc_3: 0.8305\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 11s 181ms/step - loss: 0.8033 - accuracy: 0.7842 - precision_3: 0.7352 - recall_3: 0.8435 - auc_3: 0.8536\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.7603 - accuracy: 0.8094 - precision_3: 0.7749 - recall_3: 0.8364 - auc_3: 0.8595\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7179 - accuracy: 0.8248 - precision_3: 0.7965 - recall_3: 0.8411 - auc_3: 0.8829\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7702 - accuracy: 0.7568 - precision_3: 0.7994 - recall_3: 0.6425 - auc_3: 0.8368\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7377 - accuracy: 0.7755 - precision_3: 0.7942 - recall_3: 0.7033 - auc_3: 0.8481\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7309 - accuracy: 0.7831 - precision_3: 0.7468 - recall_3: 0.8131 - auc_3: 0.8387\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6837 - accuracy: 0.8105 - precision_3: 0.7958 - recall_3: 0.8014 - auc_3: 0.8680\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.6980 - accuracy: 0.7930 - precision_3: 0.7201 - recall_3: 0.9136 - auc_3: 0.8356\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.6621 - accuracy: 0.8204 - precision_3: 0.7672 - recall_3: 0.8855 - auc_3: 0.8522\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.6185 - accuracy: 0.8390 - precision_3: 0.8230 - recall_3: 0.8364 - auc_3: 0.8677\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.7277 - accuracy: 0.7788 - precision_3: 0.9065 - recall_3: 0.5888 - auc_3: 0.7902\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6564 - accuracy: 0.8007 - precision_3: 0.8555 - recall_3: 0.6916 - auc_3: 0.8261\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.7061 - accuracy: 0.7306 - precision_3: 0.7809 - recall_3: 0.5911 - auc_3: 0.7997\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6948 - accuracy: 0.7755 - precision_3: 0.7599 - recall_3: 0.7617 - auc_3: 0.8415\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6085 - accuracy: 0.8269 - precision_3: 0.8140 - recall_3: 0.8178 - auc_3: 0.8816\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.6216 - accuracy: 0.8105 - precision_3: 0.7742 - recall_3: 0.8411 - auc_3: 0.8782\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.5945 - accuracy: 0.8160 - precision_3: 0.8368 - recall_3: 0.7547 - auc_3: 0.8960\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.5682 - accuracy: 0.8291 - precision_3: 0.8178 - recall_3: 0.8178 - auc_3: 0.9025\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 3.1416 - accuracy: 0.5279 - precision_4: 0.4940 - recall_4: 0.2897 - auc_4: 0.5674\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 2.1003 - accuracy: 0.6265 - precision_4: 0.6113 - recall_4: 0.5584 - auc_4: 0.6920\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 1.6814 - accuracy: 0.6835 - precision_4: 0.6675 - recall_4: 0.6472 - auc_4: 0.7335\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 10s 175ms/step - loss: 1.4238 - accuracy: 0.7273 - precision_4: 0.6876 - recall_4: 0.7664 - auc_4: 0.7936\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 11s 185ms/step - loss: 1.2802 - accuracy: 0.7437 - precision_4: 0.7165 - recall_4: 0.7500 - auc_4: 0.8172\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.1860 - accuracy: 0.7820 - precision_4: 0.7827 - recall_4: 0.7407 - auc_4: 0.8103\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.3658 - accuracy: 0.5268 - precision_4: 0.4920 - recall_4: 0.2874 - auc_4: 0.5062\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 1.2666 - accuracy: 0.5246 - precision_4: 0.4930 - recall_4: 0.4930 - auc_4: 0.5189\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.2000 - accuracy: 0.5290 - precision_4: 0.4934 - recall_4: 0.1752 - auc_4: 0.5084\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 1.1431 - accuracy: 0.5520 - precision_4: 0.6863 - recall_4: 0.0818 - auc_4: 0.5691\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.1005 - accuracy: 0.5422 - precision_4: 0.5145 - recall_4: 0.4136 - auc_4: 0.5577\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 1.0587 - accuracy: 0.5619 - precision_4: 0.7000 - recall_4: 0.1145 - auc_4: 0.5437\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 1.0232 - accuracy: 0.5575 - precision_4: 0.7308 - recall_4: 0.0888 - auc_4: 0.5665\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9926 - accuracy: 0.5476 - precision_4: 0.5949 - recall_4: 0.1098 - auc_4: 0.5676\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 11s 181ms/step - loss: 0.9658 - accuracy: 0.5531 - precision_4: 0.6282 - recall_4: 0.1145 - auc_4: 0.5608\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.9401 - accuracy: 0.5444 - precision_4: 0.5517 - recall_4: 0.1495 - auc_4: 0.5756\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.9177 - accuracy: 0.5060 - precision_4: 0.4506 - recall_4: 0.2453 - auc_4: 0.5527\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.8954 - accuracy: 0.5290 - precision_4: 0.4928 - recall_4: 0.1589 - auc_4: 0.5610\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 0.8754 - accuracy: 0.5422 - precision_4: 0.5137 - recall_4: 0.4393 - auc_4: 0.5793\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.8377 - accuracy: 0.6637 - precision_4: 0.7283 - recall_4: 0.4509 - auc_4: 0.7019\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.8012 - accuracy: 0.6878 - precision_4: 0.7241 - recall_4: 0.5397 - auc_4: 0.7249\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 0.7858 - accuracy: 0.6857 - precision_4: 0.6606 - recall_4: 0.6776 - auc_4: 0.7454\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7474 - accuracy: 0.7218 - precision_4: 0.7062 - recall_4: 0.6963 - auc_4: 0.7784\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6888 - accuracy: 0.7733 - precision_4: 0.7376 - recall_4: 0.8014 - auc_4: 0.8280\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.7101 - accuracy: 0.7525 - precision_4: 0.7131 - recall_4: 0.7897 - auc_4: 0.8036\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.7084 - accuracy: 0.7536 - precision_4: 0.7051 - recall_4: 0.8154 - auc_4: 0.7959\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.6569 - accuracy: 0.7886 - precision_4: 0.7255 - recall_4: 0.8832 - auc_4: 0.8482\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.6401 - accuracy: 0.8028 - precision_4: 0.7756 - recall_4: 0.8154 - auc_4: 0.8604\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 10s 178ms/step - loss: 0.6236 - accuracy: 0.8116 - precision_4: 0.7700 - recall_4: 0.8528 - auc_4: 0.8624\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 10s 179ms/step - loss: 0.6680 - accuracy: 0.7777 - precision_4: 0.7563 - recall_4: 0.7757 - auc_4: 0.8372\n",
      " Accuracy: 72.314% (+/-8.375) \n",
      " Precision: 56.037% (+/-29.317) \n",
      " Recall: 51.591% (+/-29.768) \n",
      " AUC: 74.525% (+/-12.283) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 30, 16\n",
    "    n_timesteps, n_features = trainX.shape[1], trainX.shape[2]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01), return_sequences=True, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(LSTM(50, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 4.4369 - accuracy: 0.5520 - precision_5: 0.5404 - recall_5: 0.2967 - auc_5: 0.5877\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 2.6620 - accuracy: 0.6265 - precision_5: 0.6390 - recall_5: 0.4673 - auc_5: 0.6899\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 2.0245 - accuracy: 0.6911 - precision_5: 0.6560 - recall_5: 0.7173 - auc_5: 0.7491\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 1.7125 - accuracy: 0.7547 - precision_5: 0.7073 - recall_5: 0.8131 - auc_5: 0.8028\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.5441 - accuracy: 0.7481 - precision_5: 0.7230 - recall_5: 0.7500 - auc_5: 0.8148\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 1.3781 - accuracy: 0.7930 - precision_5: 0.7661 - recall_5: 0.8037 - auc_5: 0.8536\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.2401 - accuracy: 0.8160 - precision_5: 0.7851 - recall_5: 0.8364 - auc_5: 0.8773\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 1.1402 - accuracy: 0.8324 - precision_5: 0.8132 - recall_5: 0.8341 - auc_5: 0.8833\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 1.0518 - accuracy: 0.8357 - precision_5: 0.8117 - recall_5: 0.8458 - auc_5: 0.8964\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.9733 - accuracy: 0.8467 - precision_5: 0.8349 - recall_5: 0.8388 - auc_5: 0.9007\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 18s 312ms/step - loss: 1.0494 - accuracy: 0.7952 - precision_5: 0.7660 - recall_5: 0.8107 - auc_5: 0.8122\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 1.0037 - accuracy: 0.8050 - precision_5: 0.8005 - recall_5: 0.7780 - auc_5: 0.8511\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.9154 - accuracy: 0.8302 - precision_5: 0.7803 - recall_5: 0.8879 - auc_5: 0.8547\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 0.8648 - accuracy: 0.8149 - precision_5: 0.7648 - recall_5: 0.8738 - auc_5: 0.8639\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8105 - accuracy: 0.8302 - precision_5: 0.8027 - recall_5: 0.8458 - auc_5: 0.8907\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.7455 - accuracy: 0.8521 - precision_5: 0.8415 - recall_5: 0.8435 - auc_5: 0.9099\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.7669 - accuracy: 0.8248 - precision_5: 0.8252 - recall_5: 0.7944 - auc_5: 0.8846\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.6883 - accuracy: 0.8686 - precision_5: 0.8468 - recall_5: 0.8785 - auc_5: 0.9119\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.6639 - accuracy: 0.8620 - precision_5: 0.8528 - recall_5: 0.8528 - auc_5: 0.9175\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.6494 - accuracy: 0.8587 - precision_5: 0.8360 - recall_5: 0.8692 - auc_5: 0.9168\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 0.6523 - accuracy: 0.8467 - precision_5: 0.8013 - recall_5: 0.8949 - auc_5: 0.9050\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.6549 - accuracy: 0.8499 - precision_5: 0.8721 - recall_5: 0.7967 - auc_5: 0.9065\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6680 - accuracy: 0.8368 - precision_5: 0.8378 - recall_5: 0.8084 - auc_5: 0.8967\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6242 - accuracy: 0.8642 - precision_5: 0.8470 - recall_5: 0.8668 - auc_5: 0.9154\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 0.7075 - accuracy: 0.7974 - precision_5: 0.7229 - recall_5: 0.9206 - auc_5: 0.8654\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.6464 - accuracy: 0.8401 - precision_5: 0.7901 - recall_5: 0.8972 - auc_5: 0.8977\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.5839 - accuracy: 0.8675 - precision_5: 0.8529 - recall_5: 0.8668 - auc_5: 0.9217\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.5647 - accuracy: 0.8740 - precision_5: 0.8455 - recall_5: 0.8949 - auc_5: 0.9220\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.5511 - accuracy: 0.8806 - precision_5: 0.8701 - recall_5: 0.8762 - auc_5: 0.9286\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 0.5709 - accuracy: 0.8740 - precision_5: 0.9003 - recall_5: 0.8224 - auc_5: 0.9201\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 4.3963 - accuracy: 0.5531 - precision_6: 0.5394 - recall_6: 0.3201 - auc_6: 0.5708\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 2.6229 - accuracy: 0.5871 - precision_6: 0.5714 - recall_6: 0.4766 - auc_6: 0.6361\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 18s 309ms/step - loss: 1.9804 - accuracy: 0.6857 - precision_6: 0.6466 - recall_6: 0.7266 - auc_6: 0.7426\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.7182 - accuracy: 0.7119 - precision_6: 0.6673 - recall_6: 0.7687 - auc_6: 0.7653\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 18s 311ms/step - loss: 1.5294 - accuracy: 0.7338 - precision_6: 0.6679 - recall_6: 0.8598 - auc_6: 0.7941\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.3727 - accuracy: 0.7919 - precision_6: 0.7511 - recall_6: 0.8318 - auc_6: 0.8376\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 18s 312ms/step - loss: 1.2682 - accuracy: 0.7766 - precision_6: 0.7435 - recall_6: 0.7991 - auc_6: 0.8570\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.1807 - accuracy: 0.7919 - precision_6: 0.7656 - recall_6: 0.8014 - auc_6: 0.8580\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.0678 - accuracy: 0.8346 - precision_6: 0.8017 - recall_6: 0.8598 - auc_6: 0.8740\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 18s 313ms/step - loss: 1.0412 - accuracy: 0.7886 - precision_6: 0.7196 - recall_6: 0.8995 - auc_6: 0.8554\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 1.0608 - accuracy: 0.7273 - precision_6: 0.6546 - recall_6: 0.8855 - auc_6: 0.8083\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 18s 313ms/step - loss: 0.9392 - accuracy: 0.8083 - precision_6: 0.7697 - recall_6: 0.8435 - auc_6: 0.8599\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 18s 313ms/step - loss: 0.9143 - accuracy: 0.7886 - precision_6: 0.7791 - recall_6: 0.7664 - auc_6: 0.8509\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.9706 - accuracy: 0.7306 - precision_6: 0.7004 - recall_6: 0.7430 - auc_6: 0.7705\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8902 - accuracy: 0.7755 - precision_6: 0.7377 - recall_6: 0.8084 - auc_6: 0.8140\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8206 - accuracy: 0.7974 - precision_6: 0.7694 - recall_6: 0.8107 - auc_6: 0.8483\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.7562 - accuracy: 0.8182 - precision_6: 0.7787 - recall_6: 0.8551 - auc_6: 0.8667\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.7075 - accuracy: 0.8423 - precision_6: 0.8381 - recall_6: 0.8224 - auc_6: 0.8890\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.8002 - accuracy: 0.7777 - precision_6: 0.8049 - recall_6: 0.6939 - auc_6: 0.8259\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.9489 - accuracy: 0.5674 - precision_6: 0.5943 - recall_6: 0.2430 - auc_6: 0.5281\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.8663 - accuracy: 0.6407 - precision_6: 0.8731 - recall_6: 0.2734 - auc_6: 0.6009\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 18s 315ms/step - loss: 0.7707 - accuracy: 0.7382 - precision_6: 0.9056 - recall_6: 0.4930 - auc_6: 0.7469\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.7438 - accuracy: 0.7536 - precision_6: 0.8441 - recall_6: 0.5818 - auc_6: 0.7881\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.7381 - accuracy: 0.7459 - precision_6: 0.7593 - recall_6: 0.6706 - auc_6: 0.8288\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6507 - accuracy: 0.8116 - precision_6: 0.8441 - recall_6: 0.7336 - auc_6: 0.8829\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 18s 311ms/step - loss: 0.6369 - accuracy: 0.8171 - precision_6: 0.7831 - recall_6: 0.8435 - auc_6: 0.8868\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.6748 - accuracy: 0.8018 - precision_6: 0.7763 - recall_6: 0.8107 - auc_6: 0.8561\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6177 - accuracy: 0.8324 - precision_6: 0.8009 - recall_6: 0.8551 - auc_6: 0.8834\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.6066 - accuracy: 0.8357 - precision_6: 0.8145 - recall_6: 0.8411 - auc_6: 0.8854\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.6213 - accuracy: 0.8324 - precision_6: 0.7957 - recall_6: 0.8645 - auc_6: 0.8832\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 18s 313ms/step - loss: 4.4340 - accuracy: 0.5126 - precision_7: 0.4719 - recall_7: 0.3341 - auc_7: 0.5121\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 18s 313ms/step - loss: 2.6665 - accuracy: 0.5553 - precision_7: 0.5809 - recall_7: 0.1846 - auc_7: 0.6365\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 2.0294 - accuracy: 0.6035 - precision_7: 0.6012 - recall_7: 0.4579 - auc_7: 0.6789\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 18s 308ms/step - loss: 1.7408 - accuracy: 0.6758 - precision_7: 0.6416 - recall_7: 0.6986 - auc_7: 0.7345\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.5453 - accuracy: 0.6922 - precision_7: 0.6278 - recall_7: 0.8435 - auc_7: 0.7717\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 1.3975 - accuracy: 0.7470 - precision_7: 0.6801 - recall_7: 0.8692 - auc_7: 0.7993\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 1.2853 - accuracy: 0.7503 - precision_7: 0.6887 - recall_7: 0.8528 - auc_7: 0.8216\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.1701 - accuracy: 0.7996 - precision_7: 0.7536 - recall_7: 0.8505 - auc_7: 0.8438\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.1200 - accuracy: 0.7788 - precision_7: 0.7260 - recall_7: 0.8481 - auc_7: 0.8303\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.0102 - accuracy: 0.8127 - precision_7: 0.7683 - recall_7: 0.8598 - auc_7: 0.8676\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.9452 - accuracy: 0.8138 - precision_7: 0.7676 - recall_7: 0.8645 - auc_7: 0.8744\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8874 - accuracy: 0.8280 - precision_7: 0.8031 - recall_7: 0.8388 - auc_7: 0.8772\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.9391 - accuracy: 0.7755 - precision_7: 0.7165 - recall_7: 0.8621 - auc_7: 0.8350\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.8951 - accuracy: 0.8018 - precision_7: 0.7600 - recall_7: 0.8435 - auc_7: 0.8467\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8155 - accuracy: 0.8258 - precision_7: 0.7785 - recall_7: 0.8785 - auc_7: 0.8713\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8684 - accuracy: 0.7755 - precision_7: 0.7140 - recall_7: 0.8692 - auc_7: 0.8311\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 0.8433 - accuracy: 0.7667 - precision_7: 0.7163 - recall_7: 0.8318 - auc_7: 0.8325\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.7555 - accuracy: 0.8237 - precision_7: 0.7822 - recall_7: 0.8645 - auc_7: 0.8693\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.7239 - accuracy: 0.8258 - precision_7: 0.7820 - recall_7: 0.8715 - auc_7: 0.8784\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.6714 - accuracy: 0.8379 - precision_7: 0.7905 - recall_7: 0.8902 - auc_7: 0.8916\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6676 - accuracy: 0.8357 - precision_7: 0.8022 - recall_7: 0.8621 - auc_7: 0.8860\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6554 - accuracy: 0.8510 - precision_7: 0.8160 - recall_7: 0.8808 - auc_7: 0.8880\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.6293 - accuracy: 0.8499 - precision_7: 0.8284 - recall_7: 0.8575 - auc_7: 0.8966\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.6222 - accuracy: 0.8532 - precision_7: 0.8114 - recall_7: 0.8949 - auc_7: 0.8969\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.5958 - accuracy: 0.8609 - precision_7: 0.8223 - recall_7: 0.8972 - auc_7: 0.9074\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.5950 - accuracy: 0.8598 - precision_7: 0.8425 - recall_7: 0.8621 - auc_7: 0.9101\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.5987 - accuracy: 0.8423 - precision_7: 0.8170 - recall_7: 0.8551 - auc_7: 0.9067\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.5637 - accuracy: 0.8697 - precision_7: 0.8519 - recall_7: 0.8738 - auc_7: 0.9226\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 0.6282 - accuracy: 0.8302 - precision_7: 0.7791 - recall_7: 0.8902 - auc_7: 0.8956\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.5765 - accuracy: 0.8686 - precision_7: 0.8581 - recall_7: 0.8621 - auc_7: 0.9117\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 4.4021 - accuracy: 0.5444 - precision_8: 0.5270 - recall_8: 0.2734 - auc_8: 0.5953\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 2.6368 - accuracy: 0.6134 - precision_8: 0.6081 - recall_8: 0.4930 - auc_8: 0.6602\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 1.9948 - accuracy: 0.6791 - precision_8: 0.6471 - recall_8: 0.6939 - auc_8: 0.7388\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 18s 313ms/step - loss: 1.7169 - accuracy: 0.7240 - precision_8: 0.6692 - recall_8: 0.8131 - auc_8: 0.7882\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.5330 - accuracy: 0.7700 - precision_8: 0.7206 - recall_8: 0.8318 - auc_8: 0.8131\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 1.4412 - accuracy: 0.7612 - precision_8: 0.7206 - recall_8: 0.8014 - auc_8: 0.7853\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 1.3776 - accuracy: 0.7108 - precision_8: 0.6898 - recall_8: 0.6963 - auc_8: 0.7486\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 1.2323 - accuracy: 0.7612 - precision_8: 0.7293 - recall_8: 0.7804 - auc_8: 0.8213\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 1.1008 - accuracy: 0.7930 - precision_8: 0.7661 - recall_8: 0.8037 - auc_8: 0.8589\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 1.0318 - accuracy: 0.8258 - precision_8: 0.8150 - recall_8: 0.8131 - auc_8: 0.8519\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.9989 - accuracy: 0.7963 - precision_8: 0.7654 - recall_8: 0.8154 - auc_8: 0.8470\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 1.0016 - accuracy: 0.7601 - precision_8: 0.7459 - recall_8: 0.7407 - auc_8: 0.8036\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 19s 320ms/step - loss: 0.8816 - accuracy: 0.8116 - precision_8: 0.7783 - recall_8: 0.8364 - auc_8: 0.8662\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.8483 - accuracy: 0.8138 - precision_8: 0.7780 - recall_8: 0.8435 - auc_8: 0.8549\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.8502 - accuracy: 0.7963 - precision_8: 0.8399 - recall_8: 0.6986 - auc_8: 0.8562\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.8977 - accuracy: 0.7777 - precision_8: 0.7635 - recall_8: 0.7617 - auc_8: 0.8422\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.8084 - accuracy: 0.8138 - precision_8: 0.7804 - recall_8: 0.8388 - auc_8: 0.8716\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.7643 - accuracy: 0.8193 - precision_8: 0.7828 - recall_8: 0.8505 - auc_8: 0.8775\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 0.7377 - accuracy: 0.8269 - precision_8: 0.8140 - recall_8: 0.8178 - auc_8: 0.8816\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.8077 - accuracy: 0.7809 - precision_8: 0.7938 - recall_8: 0.7196 - auc_8: 0.8226\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 0.9406 - accuracy: 0.6528 - precision_8: 0.7876 - recall_8: 0.3551 - auc_8: 0.6554\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.8984 - accuracy: 0.6780 - precision_8: 0.8490 - recall_8: 0.3808 - auc_8: 0.6652\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 0.7782 - accuracy: 0.7809 - precision_8: 0.8167 - recall_8: 0.6869 - auc_8: 0.8182\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.7319 - accuracy: 0.8039 - precision_8: 0.7689 - recall_8: 0.8318 - auc_8: 0.8336\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.7120 - accuracy: 0.8018 - precision_8: 0.7446 - recall_8: 0.8785 - auc_8: 0.8408\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 0.7043 - accuracy: 0.8050 - precision_8: 0.7615 - recall_8: 0.8505 - auc_8: 0.8432\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 0.6699 - accuracy: 0.8280 - precision_8: 0.8073 - recall_8: 0.8318 - auc_8: 0.8487\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.6317 - accuracy: 0.8368 - precision_8: 0.8252 - recall_8: 0.8271 - auc_8: 0.8756\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.6981 - accuracy: 0.7985 - precision_8: 0.7837 - recall_8: 0.7874 - auc_8: 0.8280\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 0.6965 - accuracy: 0.7963 - precision_8: 0.8218 - recall_8: 0.7220 - auc_8: 0.8234\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 4.4526 - accuracy: 0.5608 - precision_9: 0.5349 - recall_9: 0.4836 - auc_9: 0.5680\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 18s 314ms/step - loss: 2.6820 - accuracy: 0.6276 - precision_9: 0.6560 - recall_9: 0.4322 - auc_9: 0.7115\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 2.0127 - accuracy: 0.7327 - precision_9: 0.6797 - recall_9: 0.8131 - auc_9: 0.7874\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 1.7381 - accuracy: 0.7470 - precision_9: 0.6905 - recall_9: 0.8341 - auc_9: 0.8046\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 18s 311ms/step - loss: 1.6143 - accuracy: 0.7207 - precision_9: 0.6593 - recall_9: 0.8364 - auc_9: 0.7915\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 1.4182 - accuracy: 0.7974 - precision_9: 0.7526 - recall_9: 0.8458 - auc_9: 0.8417\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.2747 - accuracy: 0.8072 - precision_9: 0.7751 - recall_9: 0.8294 - auc_9: 0.8775\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 1.2167 - accuracy: 0.8083 - precision_9: 0.7608 - recall_9: 0.8621 - auc_9: 0.8471\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 18s 315ms/step - loss: 1.1063 - accuracy: 0.8127 - precision_9: 0.7824 - recall_9: 0.8318 - auc_9: 0.8769\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 1.0556 - accuracy: 0.8050 - precision_9: 0.7551 - recall_9: 0.8645 - auc_9: 0.8675\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 0.9617 - accuracy: 0.8258 - precision_9: 0.7762 - recall_9: 0.8832 - auc_9: 0.8829\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.8895 - accuracy: 0.8456 - precision_9: 0.8034 - recall_9: 0.8879 - auc_9: 0.8967\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.8388 - accuracy: 0.8488 - precision_9: 0.8033 - recall_9: 0.8972 - auc_9: 0.8983\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.7849 - accuracy: 0.8631 - precision_9: 0.8374 - recall_9: 0.8785 - auc_9: 0.9045\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.7322 - accuracy: 0.8740 - precision_9: 0.8425 - recall_9: 0.8995 - auc_9: 0.9131\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 0.8985 - accuracy: 0.7415 - precision_9: 0.7424 - recall_9: 0.6869 - auc_9: 0.7974\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 0.7885 - accuracy: 0.7809 - precision_9: 0.8016 - recall_9: 0.7079 - auc_9: 0.8726\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.6804 - accuracy: 0.8598 - precision_9: 0.8304 - recall_9: 0.8808 - auc_9: 0.9133\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 0.6451 - accuracy: 0.8773 - precision_9: 0.8709 - recall_9: 0.8668 - auc_9: 0.9180\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.6411 - accuracy: 0.8697 - precision_9: 0.8381 - recall_9: 0.8949 - auc_9: 0.9106\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.6652 - accuracy: 0.8445 - precision_9: 0.8667 - recall_9: 0.7897 - auc_9: 0.8937\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.9232 - accuracy: 0.6156 - precision_9: 0.6726 - recall_9: 0.3505 - auc_9: 0.6273\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 0.8986 - accuracy: 0.6977 - precision_9: 0.6792 - recall_9: 0.6729 - auc_9: 0.6757\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.8328 - accuracy: 0.7273 - precision_9: 0.7878 - recall_9: 0.5724 - auc_9: 0.7137\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.7867 - accuracy: 0.7601 - precision_9: 0.7879 - recall_9: 0.6682 - auc_9: 0.7368\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.8044 - accuracy: 0.6966 - precision_9: 0.8545 - recall_9: 0.4252 - auc_9: 0.7367\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 18s 317ms/step - loss: 0.7863 - accuracy: 0.7130 - precision_9: 0.8640 - recall_9: 0.4603 - auc_9: 0.7041\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 18s 316ms/step - loss: 0.7746 - accuracy: 0.7021 - precision_9: 0.8750 - recall_9: 0.4252 - auc_9: 0.7147\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 0.8679 - accuracy: 0.5739 - precision_9: 0.7826 - recall_9: 0.1262 - auc_9: 0.5434\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 18s 318ms/step - loss: 0.8303 - accuracy: 0.6002 - precision_9: 0.7333 - recall_9: 0.2313 - auc_9: 0.6099\n",
      " Accuracy: 76.681% (+/-6.516) \n",
      " Precision: 70.791% (+/-9.955) \n",
      " Recall: 76.818% (+/-23.800) \n",
      " AUC: 80.300% (+/-9.382) \n"
     ]
    }
   ],
   "source": [
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
