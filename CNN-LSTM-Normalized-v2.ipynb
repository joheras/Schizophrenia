{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.metrics import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[3], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 6250, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(accuracies,precisions,recalls,aucs):\n",
    "    m, s = mean(accuracies), std(accuracies)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(precisions), std(precisions)\n",
    "    print( ' Precision: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(recalls), std(recalls)\n",
    "    print( ' Recall: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(aucs), std(aucs)\n",
    "    print( ' AUC: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.3595 - accuracy: 0.5071 - precision: 0.4714 - recall: 0.4229 - auc: 0.4981\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.2844 - accuracy: 0.5170 - precision: 0.4835 - recall: 0.4439 - auc: 0.5248\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.2228 - accuracy: 0.5323 - precision: 0.5013 - recall: 0.4673 - auc: 0.5570\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.1555 - accuracy: 0.5926 - precision: 0.5711 - recall: 0.5257 - auc: 0.6337: 0s - loss: 1.1891 - accuracy: 0.5430 - precision: 0.5046 - recall: 0.4661 - auc: \n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.0799 - accuracy: 0.6594 - precision: 0.6333 - recall: 0.6495 - auc: 0.7295\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.9533 - accuracy: 0.7842 - precision: 0.7667 - recall: 0.7757 - auc: 0.8589\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8006 - accuracy: 0.8565 - precision: 0.8561 - recall: 0.8341 - auc: 0.9186\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.6588 - accuracy: 0.9014 - precision: 0.8986 - recall: 0.8902 - auc: 0.9503\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.5637 - accuracy: 0.9277 - precision: 0.9289 - recall: 0.9159 - auc: 0.9718\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.4514 - accuracy: 0.9639 - precision: 0.9669 - recall: 0.9556 - auc: 0.9873\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4246 - accuracy: 0.9617 - precision: 0.9602 - recall: 0.9579 - auc: 0.9854\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.3675 - accuracy: 0.9715 - precision: 0.9718 - recall: 0.9673 - auc: 0.9912\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3221 - accuracy: 0.9792 - precision: 0.9789 - recall: 0.9766 - auc: 0.9957\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2829 - accuracy: 0.9858 - precision: 0.9905 - recall: 0.9790 - auc: 0.9981\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2825 - accuracy: 0.9770 - precision: 0.9766 - recall: 0.9743 - auc: 0.9953\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2291 - accuracy: 0.9923 - precision: 0.9976 - recall: 0.9860 - auc: 0.9996\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2090 - accuracy: 0.9901 - precision: 0.9953 - recall: 0.9836 - auc: 0.9996\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1865 - accuracy: 0.9978 - precision: 0.9977 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1770 - accuracy: 0.9945 - precision: 0.9953 - recall: 0.9930 - auc: 0.9998\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1598 - accuracy: 0.9967 - precision: 1.0000 - recall: 0.9930 - auc: 0.9999\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1463 - accuracy: 0.9978 - precision: 0.9977 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1360 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9953 - auc: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1235 - accuracy: 0.9978 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.1135 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1069 - accuracy: 0.9967 - precision: 0.9930 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0975 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0930 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0838 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0765 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0735 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0671 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0625 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0582 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0563 - accuracy: 0.9989 - precision: 0.9977 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0509 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0474 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0455 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0421 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0406 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0371 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0351 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0345 - accuracy: 0.9978 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000: 0s - loss: 0.0344 - accuracy: 0.9980 - precision: 1.0000 - recall: 0.9958 - auc: 1.\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0310 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0297 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0286 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0292 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0267 - accuracy: 0.9989 - precision: 1.0000 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0241 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0222 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0216 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.3528 - accuracy: 0.5203 - precision_1: 0.4811 - recall_1: 0.2967 - auc_1: 0.5094\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2783 - accuracy: 0.5279 - precision_1: 0.4932 - recall_1: 0.2547 - auc_1: 0.5260\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.1994 - accuracy: 0.5915 - precision_1: 0.5745 - recall_1: 0.4953 - auc_1: 0.6150\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 80ms/step - loss: 1.1098 - accuracy: 0.6528 - precision_1: 0.6231 - recall_1: 0.6565 - auc_1: 0.7218\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.9827 - accuracy: 0.7809 - precision_1: 0.7426 - recall_1: 0.8154 - auc_1: 0.8522\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.8147 - accuracy: 0.8543 - precision_1: 0.8315 - recall_1: 0.8645 - auc_1: 0.9288\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.6588 - accuracy: 0.9124 - precision_1: 0.8867 - recall_1: 0.9322 - auc_1: 0.9612\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5554 - accuracy: 0.9277 - precision_1: 0.9289 - recall_1: 0.9159 - auc_1: 0.9737\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4543 - accuracy: 0.9660 - precision_1: 0.9649 - recall_1: 0.9626 - auc_1: 0.9866\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.3886 - accuracy: 0.9737 - precision_1: 0.9742 - recall_1: 0.9696 - auc_1: 0.9935\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.3355 - accuracy: 0.9836 - precision_1: 0.9814 - recall_1: 0.9836 - auc_1: 0.9965\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.3251 - accuracy: 0.9704 - precision_1: 0.9630 - recall_1: 0.9743 - auc_1: 0.9962: 0s - loss: 0.3482 - accuracy: 0.9688 - precision_1: 0.9424 - recall_1: 1.0000 - auc_1: \n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2614 - accuracy: 0.9890 - precision_1: 0.9860 - recall_1: 0.9907 - auc_1: 0.9995\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2364 - accuracy: 0.9923 - precision_1: 0.9953 - recall_1: 0.9883 - auc_1: 0.9998\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2084 - accuracy: 0.9945 - precision_1: 0.9930 - recall_1: 0.9953 - auc_1: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1835 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1684 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1549 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1411 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1287 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1189 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1097 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0999 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0927 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0853 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0777 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0718 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0662 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0616 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0571 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0529 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0496 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0456 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0431 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0412 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0377 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0363 - accuracy: 0.9989 - precision_1: 1.0000 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0337 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0312 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0293 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0284 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0258 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0251 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0230 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0217 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0212 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0199 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0189 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0177 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0171 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.3584 - accuracy: 0.5235 - precision_2: 0.4925 - recall_2: 0.5350 - auc_2: 0.5188\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2821 - accuracy: 0.5444 - precision_2: 0.5138 - recall_2: 0.5210 - auc_2: 0.5509\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.1993 - accuracy: 0.5926 - precision_2: 0.5757 - recall_2: 0.4977 - auc_2: 0.6375\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.0939 - accuracy: 0.6933 - precision_2: 0.6947 - recall_2: 0.6168 - auc_2: 0.7756\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.9925 - accuracy: 0.7623 - precision_2: 0.7425 - recall_2: 0.7547 - auc_2: 0.8441\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 78ms/step - loss: 0.8328 - accuracy: 0.8719 - precision_2: 0.8642 - recall_2: 0.8621 - auc_2: 0.9327\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.6789 - accuracy: 0.9157 - precision_2: 0.9016 - recall_2: 0.9206 - auc_2: 0.9642\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.5478 - accuracy: 0.9398 - precision_2: 0.9451 - recall_2: 0.9252 - auc_2: 0.9792\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.5155 - accuracy: 0.9332 - precision_2: 0.9297 - recall_2: 0.9276 - auc_2: 0.9762\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4690 - accuracy: 0.9365 - precision_2: 0.9343 - recall_2: 0.9299 - auc_2: 0.9807\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.3661 - accuracy: 0.9748 - precision_2: 0.9634 - recall_2: 0.9836 - auc_2: 0.9940\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3219 - accuracy: 0.9748 - precision_2: 0.9677 - recall_2: 0.9790 - auc_2: 0.9960\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.4013 - accuracy: 0.9430 - precision_2: 0.9476 - recall_2: 0.9299 - auc_2: 0.9782\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2925 - accuracy: 0.9770 - precision_2: 0.9636 - recall_2: 0.9883 - auc_2: 0.9961\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2579 - accuracy: 0.9825 - precision_2: 0.9928 - recall_2: 0.9696 - auc_2: 0.9971\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2326 - accuracy: 0.9847 - precision_2: 0.9836 - recall_2: 0.9836 - auc_2: 0.9985\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1985 - accuracy: 0.9890 - precision_2: 0.9860 - recall_2: 0.9907 - auc_2: 0.9996\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1771 - accuracy: 0.9923 - precision_2: 0.9976 - recall_2: 0.9860 - auc_2: 0.9996\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1572 - accuracy: 0.9967 - precision_2: 0.9977 - recall_2: 0.9953 - auc_2: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1435 - accuracy: 0.9967 - precision_2: 0.9930 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1343 - accuracy: 0.9956 - precision_2: 0.9977 - recall_2: 0.9930 - auc_2: 0.9999\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1191 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.1069 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0978 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0920 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0866 - accuracy: 0.9978 - precision_2: 0.9953 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0774 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0724 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0665 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0623 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0605 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0554 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0526 - accuracy: 0.9989 - precision_2: 0.9977 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0516 - accuracy: 0.9978 - precision_2: 1.0000 - recall_2: 0.9953 - auc_2: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0448 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0449 - accuracy: 0.9978 - precision_2: 0.9977 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0391 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0363 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0340 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0320 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0305 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0280 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0289 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0255 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0248 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0231 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0213 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0206 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000: 0s - loss: 0.0221 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: \n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0202 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0215 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.3566 - accuracy: 0.5367 - precision_3: 0.5077 - recall_3: 0.3855 - auc_3: 0.5328\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.2663 - accuracy: 0.5706 - precision_3: 0.5407 - recall_3: 0.5584 - auc_3: 0.5924\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.1891 - accuracy: 0.6123 - precision_3: 0.5740 - recall_3: 0.6706 - auc_3: 0.6698\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0616 - accuracy: 0.7393 - precision_3: 0.7013 - recall_3: 0.7734 - auc_3: 0.8252\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9012 - accuracy: 0.8368 - precision_3: 0.8394 - recall_3: 0.8061 - auc_3: 0.9213\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.7709 - accuracy: 0.8806 - precision_3: 0.8667 - recall_3: 0.8808 - auc_3: 0.9390\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.6353 - accuracy: 0.9233 - precision_3: 0.9282 - recall_3: 0.9065 - auc_3: 0.9694\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 62ms/step - loss: 0.5624 - accuracy: 0.9310 - precision_3: 0.9294 - recall_3: 0.9229 - auc_3: 0.9782\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.4786 - accuracy: 0.9518 - precision_3: 0.9507 - recall_3: 0.9463 - auc_3: 0.9879\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.4124 - accuracy: 0.9726 - precision_3: 0.9697 - recall_3: 0.9720 - auc_3: 0.9935\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.3685 - accuracy: 0.9737 - precision_3: 0.9720 - recall_3: 0.9720 - auc_3: 0.9968\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3256 - accuracy: 0.9890 - precision_3: 0.9838 - recall_3: 0.9930 - auc_3: 0.9952\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2883 - accuracy: 0.9901 - precision_3: 0.9929 - recall_3: 0.9860 - auc_3: 0.9986\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2554 - accuracy: 0.9934 - precision_3: 0.9953 - recall_3: 0.9907 - auc_3: 0.9998\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2393 - accuracy: 0.9967 - precision_3: 0.9953 - recall_3: 0.9977 - auc_3: 0.9995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2205 - accuracy: 0.9934 - precision_3: 0.9930 - recall_3: 0.9930 - auc_3: 0.9996\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2055 - accuracy: 0.9912 - precision_3: 0.9907 - recall_3: 0.9907 - auc_3: 0.9997\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1801 - accuracy: 0.9978 - precision_3: 1.0000 - recall_3: 0.9953 - auc_3: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1640 - accuracy: 0.9967 - precision_3: 1.0000 - recall_3: 0.9930 - auc_3: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1514 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1353 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1241 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1142 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1055 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0968 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000: 0s - loss: 0.0988 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: \n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0920 - accuracy: 0.9989 - precision_3: 0.9977 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0830 - accuracy: 0.9989 - precision_3: 1.0000 - recall_3: 0.9977 - auc_3: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0781 - accuracy: 0.9989 - precision_3: 0.9977 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0721 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0667 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0610 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0561 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0524 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0490 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0457 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0421 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0388 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0365 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0340 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0322 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0303 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0284 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0257 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0245 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0232 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0218 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0201 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0192 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0183 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0172 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.3603 - accuracy: 0.5422 - precision_4: 0.5143 - recall_4: 0.4206 - auc_4: 0.5481\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.2956 - accuracy: 0.5389 - precision_4: 0.5108 - recall_4: 0.3855 - auc_4: 0.5464\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.1617 - accuracy: 0.6528 - precision_4: 0.6350 - recall_4: 0.6098 - auc_4: 0.7321\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.0210 - accuracy: 0.7798 - precision_4: 0.7888 - recall_4: 0.7243 - auc_4: 0.8631\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.8800 - accuracy: 0.8280 - precision_4: 0.8346 - recall_4: 0.7897 - auc_4: 0.9078\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7768 - accuracy: 0.8664 - precision_4: 0.8446 - recall_4: 0.8762 - auc_4: 0.9309\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7157 - accuracy: 0.8806 - precision_4: 0.8701 - recall_4: 0.8762 - auc_4: 0.9378\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.6228 - accuracy: 0.9135 - precision_4: 0.9395 - recall_4: 0.8715 - auc_4: 0.9581\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.5040 - accuracy: 0.9452 - precision_4: 0.9632 - recall_4: 0.9182 - auc_4: 0.9833\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 76ms/step - loss: 0.4574 - accuracy: 0.9562 - precision_4: 0.9663 - recall_4: 0.9393 - auc_4: 0.9867\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.4256 - accuracy: 0.9496 - precision_4: 0.9463 - recall_4: 0.9463 - auc_4: 0.9893\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3689 - accuracy: 0.9682 - precision_4: 0.9586 - recall_4: 0.9743 - auc_4: 0.9955\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.3093 - accuracy: 0.9836 - precision_4: 0.9814 - recall_4: 0.9836 - auc_4: 0.9989\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2799 - accuracy: 0.9858 - precision_4: 0.9837 - recall_4: 0.9860 - auc_4: 0.9988\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2481 - accuracy: 0.9912 - precision_4: 0.9907 - recall_4: 0.9907 - auc_4: 0.9995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2220 - accuracy: 0.9956 - precision_4: 0.9977 - recall_4: 0.9930 - auc_4: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2087 - accuracy: 0.9934 - precision_4: 0.9976 - recall_4: 0.9883 - auc_4: 0.9998\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1864 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 0.9999\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1698 - accuracy: 0.9989 - precision_4: 0.9977 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1552 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1439 - accuracy: 0.9989 - precision_4: 0.9977 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1310 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1214 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.1131 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1034 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0975 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0892 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0829 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0768 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.0727 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0680 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0632 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0583 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0556 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0522 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0479 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0451 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0431 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0396 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0373 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0351 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0336 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0314 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0293 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0276 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0277 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0255 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0245 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0234 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0223 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe938f91d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " Accuracy: 94.760% (+/-1.235) \n",
      " Precision: 90.794% (+/-1.914) \n",
      " Recall: 96.136% (+/-1.541) \n",
      " AUC: 97.296% (+/-0.500) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3567 - accuracy: 0.5246 - precision_5: 0.4922 - recall_5: 0.4416 - auc_5: 0.5483\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2328 - accuracy: 0.6407 - precision_5: 0.6096 - recall_5: 0.6495 - auc_5: 0.7021\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.1109 - accuracy: 0.7426 - precision_5: 0.7169 - recall_5: 0.7453 - auc_5: 0.8104\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.9273 - accuracy: 0.8291 - precision_5: 0.8192 - recall_5: 0.8154 - auc_5: 0.9121\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7845 - accuracy: 0.8905 - precision_5: 0.8744 - recall_5: 0.8949 - auc_5: 0.9488: 0s - loss: 0.8233 - accuracy: 0.8646 - precision_5: 0.7930 - recall_5: 0.9730 - auc_5: \n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6825 - accuracy: 0.9102 - precision_5: 0.8896 - recall_5: 0.9229 - auc_5: 0.9659\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.5554 - accuracy: 0.9551 - precision_5: 0.9640 - recall_5: 0.9393 - auc_5: 0.9874\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4995 - accuracy: 0.9671 - precision_5: 0.9543 - recall_5: 0.9766 - auc_5: 0.9914\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4285 - accuracy: 0.9726 - precision_5: 0.9654 - recall_5: 0.9766 - auc_5: 0.9978\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.3805 - accuracy: 0.9847 - precision_5: 0.9814 - recall_5: 0.9860 - auc_5: 0.9988\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.3436 - accuracy: 0.9858 - precision_5: 0.9859 - recall_5: 0.9836 - auc_5: 0.9992\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3127 - accuracy: 0.9890 - precision_5: 0.9953 - recall_5: 0.9813 - auc_5: 0.9997\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2789 - accuracy: 0.9956 - precision_5: 0.9907 - recall_5: 1.0000 - auc_5: 0.9999\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2502 - accuracy: 0.9945 - precision_5: 0.9930 - recall_5: 0.9953 - auc_5: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2312 - accuracy: 0.9945 - precision_5: 1.0000 - recall_5: 0.9883 - auc_5: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2102 - accuracy: 0.9967 - precision_5: 0.9953 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1918 - accuracy: 0.9967 - precision_5: 0.9977 - recall_5: 0.9953 - auc_5: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1739 - accuracy: 0.9967 - precision_5: 1.0000 - recall_5: 0.9930 - auc_5: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1575 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.1406 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.1283 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1163 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1080 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1003 - accuracy: 0.9989 - precision_5: 1.0000 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0895 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0814 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0739 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0695 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0626 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0570 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0522 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0492 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0442 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0409 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0385 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0344 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0318 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0297 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0274 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0252 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0237 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0222 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0204 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0194 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0178 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0171 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0155 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0147 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0137 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0133 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe9383bc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.3884 - accuracy: 0.5115 - precision_6: 0.4729 - recall_6: 0.3668 - auc_6: 0.5134\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.2910 - accuracy: 0.5542 - precision_6: 0.5190 - recall_6: 0.6706 - auc_6: 0.5864\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.2152 - accuracy: 0.6068 - precision_6: 0.5844 - recall_6: 0.5584 - auc_6: 0.6500\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.1518 - accuracy: 0.6342 - precision_6: 0.6526 - recall_6: 0.4696 - auc_6: 0.7125\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0219 - accuracy: 0.7536 - precision_6: 0.7411 - recall_6: 0.7290 - auc_6: 0.8311\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.8265 - accuracy: 0.8795 - precision_6: 0.8768 - recall_6: 0.8645 - auc_6: 0.9441\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.6541 - accuracy: 0.9441 - precision_6: 0.9314 - recall_6: 0.9509 - auc_6: 0.9797\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.6158 - accuracy: 0.9332 - precision_6: 0.9318 - recall_6: 0.9252 - auc_6: 0.9757\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.5041 - accuracy: 0.9715 - precision_6: 0.9763 - recall_6: 0.9626 - auc_6: 0.9916\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.4432 - accuracy: 0.9781 - precision_6: 0.9744 - recall_6: 0.9790 - auc_6: 0.9977\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.4022 - accuracy: 0.9880 - precision_6: 0.9860 - recall_6: 0.9883 - auc_6: 0.9980\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.3533 - accuracy: 0.9934 - precision_6: 0.9930 - recall_6: 0.9930 - auc_6: 0.9998\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.3177 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2964 - accuracy: 0.9967 - precision_6: 0.9977 - recall_6: 0.9953 - auc_6: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2743 - accuracy: 0.9978 - precision_6: 0.9953 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2540 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2345 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2180 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2009 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1870 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1734 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1623 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1668 - accuracy: 0.9934 - precision_6: 0.9907 - recall_6: 0.9953 - auc_6: 0.9996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1565 - accuracy: 0.9956 - precision_6: 0.9953 - recall_6: 0.9953 - auc_6: 0.9998\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.1324 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1219 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1133 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.1053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0979 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0908 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0851 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0780 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0731 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0682 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0637 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0589 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0552 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0513 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0480 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0450 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0416 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0391 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0369 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0344 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0323 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0303 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0285 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0266 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0251 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0236 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe93977ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.3815 - accuracy: 0.4962 - precision_7: 0.4641 - recall_7: 0.4836 - auc_7: 0.5127\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.2756 - accuracy: 0.5728 - precision_7: 0.5448 - recall_7: 0.5397 - auc_7: 0.6048\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.1846 - accuracy: 0.6495 - precision_7: 0.6371 - recall_7: 0.5864 - auc_7: 0.7126\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.0312 - accuracy: 0.7853 - precision_7: 0.7871 - recall_7: 0.7430 - auc_7: 0.8650\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.8861 - accuracy: 0.8412 - precision_7: 0.8194 - recall_7: 0.8481 - auc_7: 0.9133\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7158 - accuracy: 0.9091 - precision_7: 0.8966 - recall_7: 0.9112 - auc_7: 0.9691\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.5800 - accuracy: 0.9529 - precision_7: 0.9446 - recall_7: 0.9556 - auc_7: 0.9828\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.5097 - accuracy: 0.9617 - precision_7: 0.9517 - recall_7: 0.9673 - auc_7: 0.9891\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.4223 - accuracy: 0.9781 - precision_7: 0.9744 - recall_7: 0.9790 - auc_7: 0.9971\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.3834 - accuracy: 0.9825 - precision_7: 0.9836 - recall_7: 0.9790 - auc_7: 0.9980\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.3349 - accuracy: 0.9912 - precision_7: 0.9907 - recall_7: 0.9907 - auc_7: 0.9981\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2999 - accuracy: 0.9956 - precision_7: 0.9977 - recall_7: 0.9930 - auc_7: 0.9996\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2669 - accuracy: 0.9967 - precision_7: 1.0000 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2448 - accuracy: 0.9956 - precision_7: 0.9930 - recall_7: 0.9977 - auc_7: 0.9999\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2205 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2038 - accuracy: 0.9967 - precision_7: 0.9977 - recall_7: 0.9953 - auc_7: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.1821 - accuracy: 0.9978 - precision_7: 0.9953 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1665 - accuracy: 0.9989 - precision_7: 1.0000 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1491 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.1358 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1236 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1130 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1019 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0962 - accuracy: 0.9989 - precision_7: 1.0000 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0860 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0806 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0737 - accuracy: 0.9989 - precision_7: 0.9977 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0668 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0606 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0549 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0500 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0460 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0424 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0390 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0357 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0327 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0305 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0278 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0259 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0246 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0225 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0213 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0197 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0179 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0170 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0159 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0151 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0143 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0132 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0122 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe938fa2e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.3966 - accuracy: 0.5257 - precision_8: 0.4938 - recall_8: 0.4650 - auc_8: 0.5197\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.2829 - accuracy: 0.5816 - precision_8: 0.5453 - recall_8: 0.6472 - auc_8: 0.6121\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.1703 - accuracy: 0.6648 - precision_8: 0.6473 - recall_8: 0.6262 - auc_8: 0.7372\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9889 - accuracy: 0.8171 - precision_8: 0.8000 - recall_8: 0.8131 - auc_8: 0.8987\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.8975 - accuracy: 0.8467 - precision_8: 0.8172 - recall_8: 0.8668 - auc_8: 0.9117\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7145 - accuracy: 0.9189 - precision_8: 0.9041 - recall_8: 0.9252 - auc_8: 0.9744\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6428 - accuracy: 0.9376 - precision_8: 0.9324 - recall_8: 0.9346 - auc_8: 0.9754\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5496 - accuracy: 0.9584 - precision_8: 0.9577 - recall_8: 0.9533 - auc_8: 0.9895\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.4903 - accuracy: 0.9682 - precision_8: 0.9629 - recall_8: 0.9696 - auc_8: 0.9934\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.4349 - accuracy: 0.9825 - precision_8: 0.9905 - recall_8: 0.9720 - auc_8: 0.9970\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3942 - accuracy: 0.9847 - precision_8: 0.9792 - recall_8: 0.9883 - auc_8: 0.9974\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.3452 - accuracy: 0.9956 - precision_8: 0.9930 - recall_8: 0.9977 - auc_8: 0.9994\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.3197 - accuracy: 0.9934 - precision_8: 0.9930 - recall_8: 0.9930 - auc_8: 0.9998\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2941 - accuracy: 0.9956 - precision_8: 0.9977 - recall_8: 0.9930 - auc_8: 0.9998\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2769 - accuracy: 0.9912 - precision_8: 0.9884 - recall_8: 0.9930 - auc_8: 0.9998\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2544 - accuracy: 0.9945 - precision_8: 0.9907 - recall_8: 0.9977 - auc_8: 0.9998\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2294 - accuracy: 0.9989 - precision_8: 1.0000 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2099 - accuracy: 0.9978 - precision_8: 0.9953 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1943 - accuracy: 0.9978 - precision_8: 0.9977 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.1796 - accuracy: 0.9967 - precision_8: 0.9953 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1674 - accuracy: 0.9956 - precision_8: 0.9930 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.1520 - accuracy: 0.9978 - precision_8: 0.9953 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.1373 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1281 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1179 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1069 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0987 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0931 - accuracy: 0.9989 - precision_8: 0.9977 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0851 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0782 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0726 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0668 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0616 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0571 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0534 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0489 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0458 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0432 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0409 - accuracy: 0.9989 - precision_8: 1.0000 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0373 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0349 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0321 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0300 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0281 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0267 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0245 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0239 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0228 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0209 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0199 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe938f11158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.3563 - accuracy: 0.5389 - precision_9: 0.5087 - recall_9: 0.4766 - auc_9: 0.5577\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.2589 - accuracy: 0.5860 - precision_9: 0.5691 - recall_9: 0.4813 - auc_9: 0.6175\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.0962 - accuracy: 0.7426 - precision_9: 0.7102 - recall_9: 0.7617 - auc_9: 0.8282\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9119 - accuracy: 0.8554 - precision_9: 0.8246 - recall_9: 0.8785 - auc_9: 0.9319\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.7076 - accuracy: 0.9200 - precision_9: 0.9118 - recall_9: 0.9182 - auc_9: 0.9762\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.5858 - accuracy: 0.9518 - precision_9: 0.9550 - recall_9: 0.9416 - auc_9: 0.9866\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.5012 - accuracy: 0.9737 - precision_9: 0.9698 - recall_9: 0.9743 - auc_9: 0.9945\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.4404 - accuracy: 0.9770 - precision_9: 0.9700 - recall_9: 0.9813 - auc_9: 0.9974\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3854 - accuracy: 0.9880 - precision_9: 0.9883 - recall_9: 0.9860 - auc_9: 0.9993\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.3505 - accuracy: 0.9923 - precision_9: 0.9884 - recall_9: 0.9953 - auc_9: 0.9993\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3166 - accuracy: 0.9912 - precision_9: 0.9839 - recall_9: 0.9977 - auc_9: 0.9995\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2791 - accuracy: 0.9945 - precision_9: 0.9907 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2500 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2266 - accuracy: 0.9989 - precision_9: 0.9977 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2037 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1834 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1688 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1514 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1358 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1229 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1110 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1005 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0906 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0814 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0741 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0669 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0608 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0552 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0496 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0451 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0408 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0370 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0340 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0313 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0290 - accuracy: 0.9989 - precision_9: 1.0000 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0260 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0237 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0220 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0196 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0184 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0168 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0157 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0145 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0134 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0126 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0114 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0109 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0099 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0096 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.000 - 0s 50ms/step - loss: 0.0090 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe94c981f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 79.039% (+/-12.193) \n",
      " Precision: 71.511% (+/-25.935) \n",
      " Recall: 58.409% (+/-36.375) \n",
      " AUC: 85.795% (+/-16.624) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3),input_shape=(None,n_length,n_features)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.5360 - accuracy: 0.5279 - precision_10: 0.4962 - recall_10: 0.4556 - auc_10: 0.5329\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.3687 - accuracy: 0.5696 - precision_10: 0.5331 - recall_10: 0.6589 - auc_10: 0.6199\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.2239 - accuracy: 0.6681 - precision_10: 0.6667 - recall_10: 0.5841 - auc_10: 0.7354\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0853 - accuracy: 0.7525 - precision_10: 0.7512 - recall_10: 0.7056 - auc_10: 0.8448\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.9414 - accuracy: 0.8467 - precision_10: 0.8333 - recall_10: 0.8411 - auc_10: 0.9176\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.8393 - accuracy: 0.8806 - precision_10: 0.8684 - recall_10: 0.8785 - auc_10: 0.9509\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7499 - accuracy: 0.9189 - precision_10: 0.9097 - recall_10: 0.9182 - auc_10: 0.9722\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7454 - accuracy: 0.9102 - precision_10: 0.9179 - recall_10: 0.8879 - auc_10: 0.9680\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6704 - accuracy: 0.9387 - precision_10: 0.9673 - recall_10: 0.8995 - auc_10: 0.9843\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.6061 - accuracy: 0.9584 - precision_10: 0.9333 - recall_10: 0.9813 - auc_10: 0.9928\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.5516 - accuracy: 0.9682 - precision_10: 0.9784 - recall_10: 0.9533 - auc_10: 0.9970\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.4976 - accuracy: 0.9869 - precision_10: 0.9793 - recall_10: 0.9930 - auc_10: 0.9987\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.4804 - accuracy: 0.9803 - precision_10: 0.9928 - recall_10: 0.9650 - auc_10: 0.9982\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.4460 - accuracy: 0.9945 - precision_10: 0.9907 - recall_10: 0.9977 - auc_10: 0.9997\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.4283 - accuracy: 0.9890 - precision_10: 0.9953 - recall_10: 0.9813 - auc_10: 0.9995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.4074 - accuracy: 0.9923 - precision_10: 0.9930 - recall_10: 0.9907 - auc_10: 0.9992\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.3839 - accuracy: 0.9956 - precision_10: 1.0000 - recall_10: 0.9907 - auc_10: 0.9999\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.3622 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 0.9994\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3488 - accuracy: 0.9956 - precision_10: 0.9930 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3339 - accuracy: 0.9945 - precision_10: 0.9976 - recall_10: 0.9907 - auc_10: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3184 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.3035 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2899 - accuracy: 0.9967 - precision_10: 1.0000 - recall_10: 0.9930 - auc_10: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2749 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2636 - accuracy: 0.9978 - precision_10: 0.9953 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2521 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2361 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2252 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2144 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2052 - accuracy: 0.9989 - precision_10: 0.9977 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1971 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1859 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.1776 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1673 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.1585 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1515 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.1434 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1393 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1315 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1227 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.1180 - accuracy: 0.9989 - precision_10: 0.9977 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1111 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.1089 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.1003 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.0948 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0912 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0854 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0845 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0777 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0741 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe9384e4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.6146 - accuracy: 0.5367 - precision_11: 0.5057 - recall_11: 0.5140 - auc_11: 0.5549\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.4022 - accuracy: 0.5619 - precision_11: 0.5293 - recall_11: 0.5911 - auc_11: 0.5886\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.2498 - accuracy: 0.6648 - precision_11: 0.6597 - recall_11: 0.5888 - auc_11: 0.7134\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 1.0784 - accuracy: 0.7634 - precision_11: 0.7573 - recall_11: 0.7290 - auc_11: 0.8413\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0091 - accuracy: 0.7941 - precision_11: 0.7703 - recall_11: 0.7991 - auc_11: 0.8756\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.9057 - accuracy: 0.8543 - precision_11: 0.8471 - recall_11: 0.8411 - auc_11: 0.9210\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7771 - accuracy: 0.9058 - precision_11: 0.9052 - recall_11: 0.8925 - auc_11: 0.9624\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.7130 - accuracy: 0.9168 - precision_11: 0.9131 - recall_11: 0.9089 - auc_11: 0.9746\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6267 - accuracy: 0.9398 - precision_11: 0.9307 - recall_11: 0.9416 - auc_11: 0.9892\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.5943 - accuracy: 0.9573 - precision_11: 0.9555 - recall_11: 0.9533 - auc_11: 0.9894\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.5277 - accuracy: 0.9715 - precision_11: 0.9741 - recall_11: 0.9650 - auc_11: 0.9968\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.4925 - accuracy: 0.9836 - precision_11: 0.9836 - recall_11: 0.9813 - auc_11: 0.9969\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.4550 - accuracy: 0.9858 - precision_11: 0.9792 - recall_11: 0.9907 - auc_11: 0.9996\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.4338 - accuracy: 0.9890 - precision_11: 0.9953 - recall_11: 0.9813 - auc_11: 0.9994 0s - loss: 0.4473 - accuracy: 0.9870 - precision_11: 1.0000 - recall_11: 0.9725 - auc_\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.4142 - accuracy: 0.9869 - precision_11: 0.9837 - recall_11: 0.9883 - auc_11: 0.9993\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.3891 - accuracy: 0.9956 - precision_11: 0.9977 - recall_11: 0.9930 - auc_11: 0.9997\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.3681 - accuracy: 0.9945 - precision_11: 0.9930 - recall_11: 0.9953 - auc_11: 0.9998\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3617 - accuracy: 0.9890 - precision_11: 0.9883 - recall_11: 0.9883 - auc_11: 0.9994\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.3260 - accuracy: 0.9978 - precision_11: 0.9953 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.3186 - accuracy: 0.9923 - precision_11: 0.9953 - recall_11: 0.9883 - auc_11: 0.9999\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3013 - accuracy: 0.9956 - precision_11: 0.9930 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2894 - accuracy: 0.9967 - precision_11: 0.9977 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2789 - accuracy: 0.9945 - precision_11: 0.9930 - recall_11: 0.9953 - auc_11: 0.9997\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2580 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2485 - accuracy: 0.9956 - precision_11: 0.9977 - recall_11: 0.9930 - auc_11: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2383 - accuracy: 0.9967 - precision_11: 1.0000 - recall_11: 0.9930 - auc_11: 0.9999\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2267 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2144 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2030 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1947 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1822 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1813 - accuracy: 0.9945 - precision_11: 0.9930 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1673 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1578 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1480 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.1401 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1360 - accuracy: 0.9978 - precision_11: 1.0000 - recall_11: 0.9953 - auc_11: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.1287 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1205 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.1160 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1186 - accuracy: 0.9956 - precision_11: 1.0000 - recall_11: 0.9907 - auc_11: 0.9999\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1130 - accuracy: 0.9967 - precision_11: 0.9977 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1017 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0966 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0980 - accuracy: 0.9956 - precision_11: 1.0000 - recall_11: 0.9907 - auc_11: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0886 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0838 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0788 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0727 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0681 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe94ca118c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.4075 - accuracy: 0.5816 - precision_12: 0.5575 - recall_12: 0.5210 - auc_12: 0.5947\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1895 - accuracy: 0.7141 - precision_12: 0.6811 - recall_12: 0.7336 - auc_12: 0.7819\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0544 - accuracy: 0.7831 - precision_12: 0.7614 - recall_12: 0.7827 - auc_12: 0.8641\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.8969 - accuracy: 0.8565 - precision_12: 0.8414 - recall_12: 0.8551 - auc_12: 0.9308\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7616 - accuracy: 0.9036 - precision_12: 0.9048 - recall_12: 0.8879 - auc_12: 0.9681\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.6605 - accuracy: 0.9376 - precision_12: 0.9206 - recall_12: 0.9486 - auc_12: 0.9877\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6154 - accuracy: 0.9463 - precision_12: 0.9417 - recall_12: 0.9439 - auc_12: 0.9894\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5396 - accuracy: 0.9715 - precision_12: 0.9741 - recall_12: 0.9650 - auc_12: 0.9958\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.5007 - accuracy: 0.9704 - precision_12: 0.9609 - recall_12: 0.9766 - auc_12: 0.9973\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4434 - accuracy: 0.9901 - precision_12: 0.9929 - recall_12: 0.9860 - auc_12: 0.9994\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4102 - accuracy: 0.9901 - precision_12: 0.9953 - recall_12: 0.9836 - auc_12: 0.9997\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.3749 - accuracy: 0.9956 - precision_12: 0.9977 - recall_12: 0.9930 - auc_12: 1.0000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.3564 - accuracy: 0.9945 - precision_12: 0.9930 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.3326 - accuracy: 0.9945 - precision_12: 0.9976 - recall_12: 0.9907 - auc_12: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3116 - accuracy: 0.9967 - precision_12: 0.9930 - recall_12: 1.0000 - auc_12: 1.0000 0s - loss: 0.3161 - accuracy: 0.9953 - precision_12: 0.9901 - recall_12: 1.0000 - auc_12: \n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2948 - accuracy: 0.9934 - precision_12: 0.9976 - recall_12: 0.9883 - auc_12: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2730 - accuracy: 0.9967 - precision_12: 0.9930 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2568 - accuracy: 0.9978 - precision_12: 1.0000 - recall_12: 0.9953 - auc_12: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2461 - accuracy: 0.9956 - precision_12: 0.9953 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2260 - accuracy: 0.9978 - precision_12: 1.0000 - recall_12: 0.9953 - auc_12: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2106 - accuracy: 0.9978 - precision_12: 0.9953 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1937 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1878 - accuracy: 0.9978 - precision_12: 1.0000 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1708 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1597 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1509 - accuracy: 0.9978 - precision_12: 1.0000 - recall_12: 0.9953 - auc_12: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1400 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.1321 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1216 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1120 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1042 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0977 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0910 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000 0s - loss: 0.0911 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.00\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0858 - accuracy: 0.9989 - precision_12: 0.9977 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0787 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0746 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0683 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0638 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0600 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0565 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0519 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0487 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0459 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0418 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0387 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0363 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0340 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0315 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0293 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0274 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe94c79af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.5361 - accuracy: 0.5674 - precision_13: 0.5363 - recall_13: 0.5701 - auc_13: 0.5674\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.4125 - accuracy: 0.5411 - precision_13: 0.5106 - recall_13: 0.5047 - auc_13: 0.5709\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.2788 - accuracy: 0.6331 - precision_13: 0.6126 - recall_13: 0.5911 - auc_13: 0.6707\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.1005 - accuracy: 0.7459 - precision_13: 0.7333 - recall_13: 0.7196 - auc_13: 0.8166\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9671 - accuracy: 0.8050 - precision_13: 0.7765 - recall_13: 0.8201 - auc_13: 0.8912\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.8296 - accuracy: 0.8806 - precision_13: 0.8552 - recall_13: 0.8972 - auc_13: 0.9452\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7336 - accuracy: 0.9047 - precision_13: 0.8866 - recall_13: 0.9136 - auc_13: 0.9695\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6404 - accuracy: 0.9398 - precision_13: 0.9307 - recall_13: 0.9416 - auc_13: 0.9856\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6276 - accuracy: 0.9398 - precision_13: 0.9628 - recall_13: 0.9065 - auc_13: 0.9841\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6309 - accuracy: 0.9200 - precision_13: 0.9157 - recall_13: 0.9136 - auc_13: 0.9779\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.5283 - accuracy: 0.9595 - precision_13: 0.9374 - recall_13: 0.9790 - auc_13: 0.9934\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4891 - accuracy: 0.9639 - precision_13: 0.9647 - recall_13: 0.9579 - auc_13: 0.9958\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.4470 - accuracy: 0.9803 - precision_13: 0.9767 - recall_13: 0.9813 - auc_13: 0.9974\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.4211 - accuracy: 0.9803 - precision_13: 0.9812 - recall_13: 0.9766 - auc_13: 0.9978\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.4034 - accuracy: 0.9781 - precision_13: 0.9744 - recall_13: 0.9790 - auc_13: 0.9975\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3750 - accuracy: 0.9803 - precision_13: 0.9680 - recall_13: 0.9907 - auc_13: 0.9991\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.3435 - accuracy: 0.9901 - precision_13: 0.9976 - recall_13: 0.9813 - auc_13: 0.9998\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3426 - accuracy: 0.9890 - precision_13: 0.9794 - recall_13: 0.9977 - auc_13: 0.9983\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.3244 - accuracy: 0.9847 - precision_13: 0.9976 - recall_13: 0.9696 - auc_13: 0.9993\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.3026 - accuracy: 0.9869 - precision_13: 0.9749 - recall_13: 0.9977 - auc_13: 0.9997\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2881 - accuracy: 0.9847 - precision_13: 0.9905 - recall_13: 0.9766 - auc_13: 0.9996\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2738 - accuracy: 0.9890 - precision_13: 0.9838 - recall_13: 0.9930 - auc_13: 0.9996\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2660 - accuracy: 0.9847 - precision_13: 0.9726 - recall_13: 0.9953 - auc_13: 0.9996\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2485 - accuracy: 0.9901 - precision_13: 0.9976 - recall_13: 0.9813 - auc_13: 0.9998\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2328 - accuracy: 0.9934 - precision_13: 0.9930 - recall_13: 0.9930 - auc_13: 0.9997\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2205 - accuracy: 0.9945 - precision_13: 0.9930 - recall_13: 0.9953 - auc_13: 0.9997\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2122 - accuracy: 0.9956 - precision_13: 1.0000 - recall_13: 0.9907 - auc_13: 0.9998\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.1951 - accuracy: 0.9956 - precision_13: 0.9977 - recall_13: 0.9930 - auc_13: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1807 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1721 - accuracy: 0.9978 - precision_13: 0.9977 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.1619 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1546 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.1467 - accuracy: 0.9978 - precision_13: 1.0000 - recall_13: 0.9953 - auc_13: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1399 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1317 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1264 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1222 - accuracy: 0.9978 - precision_13: 1.0000 - recall_13: 0.9953 - auc_13: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1173 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1112 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1049 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0995 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0948 - accuracy: 0.9978 - precision_13: 0.9953 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0882 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0843 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0830 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0805 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0796 - accuracy: 0.9967 - precision_13: 0.9977 - recall_13: 0.9953 - auc_13: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0746 - accuracy: 0.9978 - precision_13: 0.9953 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0685 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0657 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe9398cac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.4606 - accuracy: 0.5509 - precision_14: 0.5211 - recall_14: 0.5187 - auc_14: 0.5780\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.2014 - accuracy: 0.7065 - precision_14: 0.6702 - recall_14: 0.7360 - auc_14: 0.7727\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.0638 - accuracy: 0.7777 - precision_14: 0.7368 - recall_14: 0.8178 - auc_14: 0.8629\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9386 - accuracy: 0.8258 - precision_14: 0.8150 - recall_14: 0.8131 - auc_14: 0.9155\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.8100 - accuracy: 0.8959 - precision_14: 0.8955 - recall_14: 0.8808 - auc_14: 0.9578\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.7319 - accuracy: 0.9080 - precision_14: 0.8981 - recall_14: 0.9065 - auc_14: 0.9727\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6222 - accuracy: 0.9573 - precision_14: 0.9313 - recall_14: 0.9813 - auc_14: 0.9923\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5596 - accuracy: 0.9650 - precision_14: 0.9626 - recall_14: 0.9626 - auc_14: 0.9966\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5152 - accuracy: 0.9792 - precision_14: 0.9701 - recall_14: 0.9860 - auc_14: 0.9972\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.4619 - accuracy: 0.9890 - precision_14: 0.9906 - recall_14: 0.9860 - auc_14: 0.9995\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4360 - accuracy: 0.9901 - precision_14: 0.9906 - recall_14: 0.9883 - auc_14: 0.9995\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.4053 - accuracy: 0.9912 - precision_14: 0.9884 - recall_14: 0.9930 - auc_14: 0.9995\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.3789 - accuracy: 0.9934 - precision_14: 0.9907 - recall_14: 0.9953 - auc_14: 0.9998\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.3490 - accuracy: 0.9967 - precision_14: 1.0000 - recall_14: 0.9930 - auc_14: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3354 - accuracy: 0.9934 - precision_14: 0.9930 - recall_14: 0.9930 - auc_14: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.9967 - precision_14: 0.9977 - recall_14: 0.9953 - auc_14: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2911 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2705 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2528 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2395 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2244 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2083 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1966 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1821 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1707 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1603 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1510 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.1465 - accuracy: 0.9978 - precision_14: 0.9953 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.1346 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1257 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1176 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1086 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.1010 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0951 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0892 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0824 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0769 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0719 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0670 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0625 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0589 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0545 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0509 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0477 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0443 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0417 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0392 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0363 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0341 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0323 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe94c8c0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 59.651% (+/-3.020) \n",
      " Precision: 43.786% (+/-8.607) \n",
      " Recall: 10.909% (+/-3.262) \n",
      " AUC: 61.162% (+/-5.177) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_3(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu'),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='selu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'selu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_3(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_3(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_3(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
