{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[3], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 6250, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(accuracies,precisions,recalls,aucs):\n",
    "    m, s = mean(accuracies), std(accuracies)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(precisions), std(precisions)\n",
    "    print( ' Precision: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(recalls), std(recalls)\n",
    "    print( ' Recall: %.3f%% (+/-%.3f) ' % (m, s))\n",
    "    m, s = mean(aucs), std(aucs)\n",
    "    print( ' AUC: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 10.7656 - accuracy: 0.5356 - precision: 0.5066 - recall: 0.3575 - auc: 0.5351\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.3737 - accuracy: 0.5400 - precision: 0.5116 - recall: 0.4112 - auc: 0.5622\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.7896 - accuracy: 0.6166 - precision: 0.5867 - recall: 0.6168 - auc: 0.6652\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.1606 - accuracy: 0.6736 - precision: 0.7110 - recall: 0.5117 - auc: 0.7424\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.6517 - accuracy: 0.7700 - precision: 0.7583 - recall: 0.7477 - auc: 0.8470\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.2123 - accuracy: 0.8061 - precision: 0.7783 - recall: 0.8201 - auc: 0.8976\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.8640 - accuracy: 0.8894 - precision: 0.8741 - recall: 0.8925 - auc: 0.9550\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.6535 - accuracy: 0.9179 - precision: 0.9212 - recall: 0.9019 - auc: 0.9610\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.4427 - accuracy: 0.9244 - precision: 0.9145 - recall: 0.9252 - auc: 0.9733\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2968 - accuracy: 0.9398 - precision: 0.9494 - recall: 0.9206 - auc: 0.9717\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.1359 - accuracy: 0.9551 - precision: 0.9618 - recall: 0.9416 - auc: 0.9876\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0055 - accuracy: 0.9650 - precision: 0.9583 - recall: 0.9673 - auc: 0.9885\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9574 - accuracy: 0.9485 - precision: 0.9461 - recall: 0.9439 - auc: 0.9809\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9257 - accuracy: 0.9299 - precision: 0.9155 - recall: 0.9369 - auc: 0.9767\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7751 - accuracy: 0.9660 - precision: 0.9627 - recall: 0.9650 - auc: 0.9900\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7284 - accuracy: 0.9430 - precision: 0.9352 - recall: 0.9439 - auc: 0.9807\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.6731 - accuracy: 0.9452 - precision: 0.9163 - recall: 0.9720 - auc: 0.9821\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.6112 - accuracy: 0.9573 - precision: 0.9492 - recall: 0.9603 - auc: 0.9840\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5110 - accuracy: 0.9704 - precision: 0.9831 - recall: 0.9533 - auc: 0.9873\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5202 - accuracy: 0.9387 - precision: 0.9326 - recall: 0.9369 - auc: 0.9776\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4205 - accuracy: 0.9639 - precision: 0.9499 - recall: 0.9743 - auc: 0.9948\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3300 - accuracy: 0.9814 - precision: 0.9835 - recall: 0.9766 - auc: 0.9971\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2745 - accuracy: 0.9869 - precision: 0.9906 - recall: 0.9813 - auc: 0.9952\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2545 - accuracy: 0.9737 - precision: 0.9654 - recall: 0.9790 - auc: 0.9947\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2231 - accuracy: 0.9792 - precision: 0.9767 - recall: 0.9790 - auc: 0.9931\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2003 - accuracy: 0.9715 - precision: 0.9718 - recall: 0.9673 - auc: 0.9942\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1744 - accuracy: 0.9704 - precision: 0.9674 - recall: 0.9696 - auc: 0.9952\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1176 - accuracy: 0.9825 - precision: 0.9725 - recall: 0.9907 - auc: 0.9990\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1040 - accuracy: 0.9814 - precision: 0.9835 - recall: 0.9766 - auc: 0.9941\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0504 - accuracy: 0.9923 - precision: 0.9976 - recall: 0.9860 - auc: 0.9973\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0095 - accuracy: 0.9945 - precision: 0.9953 - recall: 0.9930 - auc: 0.9993\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0014 - accuracy: 0.9836 - precision: 0.9814 - recall: 0.9836 - auc: 0.9986\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9562 - accuracy: 0.9934 - precision: 0.9930 - recall: 0.9930 - auc: 0.9999\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9425 - accuracy: 0.9912 - precision: 0.9884 - recall: 0.9930 - auc: 0.9994\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9865 - accuracy: 0.9650 - precision: 0.9500 - recall: 0.9766 - auc: 0.9936\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9317 - accuracy: 0.9890 - precision: 0.9929 - recall: 0.9836 - auc: 0.9996\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9012 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9953 - auc: 0.9996\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8726 - accuracy: 0.9956 - precision: 0.9930 - recall: 0.9977 - auc: 0.9999\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8445 - accuracy: 0.9989 - precision: 0.9977 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8239 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9953 - auc: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8067 - accuracy: 0.9978 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7851 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8170 - accuracy: 0.9858 - precision: 0.9859 - recall: 0.9836 - auc: 0.9959\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8105 - accuracy: 0.9890 - precision: 0.9838 - recall: 0.9930 - auc: 0.9990\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7909 - accuracy: 0.9978 - precision: 0.9953 - recall: 1.0000 - auc: 0.9998\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7563 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7324 - accuracy: 0.9967 - precision: 0.9953 - recall: 0.9977 - auc: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7099 - accuracy: 0.9989 - precision: 0.9977 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7595 - accuracy: 0.9726 - precision: 0.9719 - recall: 0.9696 - auc: 0.9962\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7343 - accuracy: 0.9923 - precision: 0.9884 - recall: 0.9953 - auc: 0.9996\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 10.6981 - accuracy: 0.5290 - precision_1: 0.4975 - recall_1: 0.4743 - auc_1: 0.5341\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.2700 - accuracy: 0.5728 - precision_1: 0.5528 - recall_1: 0.4650 - auc_1: 0.5945\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.7497 - accuracy: 0.5827 - precision_1: 0.5741 - recall_1: 0.4252 - auc_1: 0.6260\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.1209 - accuracy: 0.6681 - precision_1: 0.6640 - recall_1: 0.5911 - auc_1: 0.7463\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 52ms/step - loss: 3.6117 - accuracy: 0.7547 - precision_1: 0.7040 - recall_1: 0.8224 - auc_1: 0.8238\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.1438 - accuracy: 0.8302 - precision_1: 0.8212 - recall_1: 0.8154 - auc_1: 0.9210\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.8253 - accuracy: 0.8992 - precision_1: 0.8733 - recall_1: 0.9182 - auc_1: 0.9512\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.6235 - accuracy: 0.8981 - precision_1: 0.8649 - recall_1: 0.9276 - auc_1: 0.9567\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4247 - accuracy: 0.9266 - precision_1: 0.9188 - recall_1: 0.9252 - auc_1: 0.9754\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2714 - accuracy: 0.9419 - precision_1: 0.9310 - recall_1: 0.9463 - auc_1: 0.9745\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0884 - accuracy: 0.9562 - precision_1: 0.9597 - recall_1: 0.9463 - auc_1: 0.9863\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.0201 - accuracy: 0.9387 - precision_1: 0.9429 - recall_1: 0.9252 - auc_1: 0.9765\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.9012 - accuracy: 0.9507 - precision_1: 0.9570 - recall_1: 0.9369 - auc_1: 0.9847\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.8109 - accuracy: 0.9507 - precision_1: 0.9464 - recall_1: 0.9486 - auc_1: 0.9834\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7250 - accuracy: 0.9474 - precision_1: 0.9460 - recall_1: 0.9416 - auc_1: 0.9876\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.6657 - accuracy: 0.9540 - precision_1: 0.9488 - recall_1: 0.9533 - auc_1: 0.9824\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5444 - accuracy: 0.9737 - precision_1: 0.9676 - recall_1: 0.9766 - auc_1: 0.9935\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4771 - accuracy: 0.9759 - precision_1: 0.9721 - recall_1: 0.9766 - auc_1: 0.9927\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4195 - accuracy: 0.9759 - precision_1: 0.9833 - recall_1: 0.9650 - auc_1: 0.9928\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3827 - accuracy: 0.9704 - precision_1: 0.9718 - recall_1: 0.9650 - auc_1: 0.9915\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4165 - accuracy: 0.9452 - precision_1: 0.9458 - recall_1: 0.9369 - auc_1: 0.9813\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3305 - accuracy: 0.9803 - precision_1: 0.9767 - recall_1: 0.9813 - auc_1: 0.9940\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2466 - accuracy: 0.9880 - precision_1: 0.9883 - recall_1: 0.9860 - auc_1: 0.9967\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1872 - accuracy: 0.9901 - precision_1: 0.9953 - recall_1: 0.9836 - auc_1: 0.9969\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2017 - accuracy: 0.9682 - precision_1: 0.9672 - recall_1: 0.9650 - auc_1: 0.9925\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2110 - accuracy: 0.9617 - precision_1: 0.9602 - recall_1: 0.9579 - auc_1: 0.9903\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1294 - accuracy: 0.9836 - precision_1: 0.9859 - recall_1: 0.9790 - auc_1: 0.9973\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0741 - accuracy: 0.9956 - precision_1: 0.9977 - recall_1: 0.9930 - auc_1: 0.9982\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0826 - accuracy: 0.9726 - precision_1: 0.9786 - recall_1: 0.9626 - auc_1: 0.9951\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.0438 - accuracy: 0.9825 - precision_1: 0.9836 - recall_1: 0.9790 - auc_1: 0.9965\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0097 - accuracy: 0.9880 - precision_1: 0.9883 - recall_1: 0.9860 - auc_1: 0.9983\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9732 - accuracy: 0.9923 - precision_1: 0.9907 - recall_1: 0.9930 - auc_1: 0.9977\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9489 - accuracy: 0.9923 - precision_1: 0.9907 - recall_1: 0.9930 - auc_1: 0.9988\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9167 - accuracy: 0.9945 - precision_1: 0.9930 - recall_1: 0.9953 - auc_1: 0.9995\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8907 - accuracy: 0.9978 - precision_1: 1.0000 - recall_1: 0.9953 - auc_1: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8803 - accuracy: 0.9901 - precision_1: 0.9861 - recall_1: 0.9930 - auc_1: 0.9997\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9037 - accuracy: 0.9781 - precision_1: 0.9857 - recall_1: 0.9673 - auc_1: 0.9970\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0937 - accuracy: 0.9179 - precision_1: 0.9095 - recall_1: 0.9159 - auc_1: 0.9598\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0283 - accuracy: 0.9628 - precision_1: 0.9417 - recall_1: 0.9813 - auc_1: 0.9853\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9395 - accuracy: 0.9770 - precision_1: 0.9722 - recall_1: 0.9790 - auc_1: 0.9937\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9072 - accuracy: 0.9814 - precision_1: 0.9976 - recall_1: 0.9626 - auc_1: 0.9916\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8580 - accuracy: 0.9858 - precision_1: 0.9905 - recall_1: 0.9790 - auc_1: 0.9963\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8376 - accuracy: 0.9814 - precision_1: 0.9746 - recall_1: 0.9860 - auc_1: 0.9958\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8027 - accuracy: 0.9890 - precision_1: 0.9794 - recall_1: 0.9977 - auc_1: 0.9987\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7919 - accuracy: 0.9825 - precision_1: 0.9858 - recall_1: 0.9766 - auc_1: 0.9989\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7567 - accuracy: 0.9945 - precision_1: 1.0000 - recall_1: 0.9883 - auc_1: 0.9989\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7407 - accuracy: 0.9934 - precision_1: 0.9930 - recall_1: 0.9930 - auc_1: 0.9998\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7172 - accuracy: 0.9967 - precision_1: 0.9953 - recall_1: 0.9977 - auc_1: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7012 - accuracy: 0.9967 - precision_1: 0.9977 - recall_1: 0.9953 - auc_1: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.6819 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 10.7913 - accuracy: 0.5290 - precision_2: 0.4969 - recall_2: 0.3762 - auc_2: 0.5349\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.3783 - accuracy: 0.5575 - precision_2: 0.5335 - recall_2: 0.4463 - auc_2: 0.5693\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.8365 - accuracy: 0.5531 - precision_2: 0.5205 - recall_2: 0.5935 - auc_2: 0.5911\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.2369 - accuracy: 0.6112 - precision_2: 0.5731 - recall_2: 0.6682 - auc_2: 0.6704\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.7451 - accuracy: 0.7185 - precision_2: 0.6913 - recall_2: 0.7220 - auc_2: 0.7816\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.3388 - accuracy: 0.7820 - precision_2: 0.7608 - recall_2: 0.7804 - auc_2: 0.8551\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.9847 - accuracy: 0.8675 - precision_2: 0.8481 - recall_2: 0.8738 - auc_2: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.7111 - accuracy: 0.8916 - precision_2: 0.8538 - recall_2: 0.9276 - auc_2: 0.9579\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.5133 - accuracy: 0.9168 - precision_2: 0.9112 - recall_2: 0.9112 - auc_2: 0.9685\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4168 - accuracy: 0.8938 - precision_2: 0.8559 - recall_2: 0.9299 - auc_2: 0.9570\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2472 - accuracy: 0.9387 - precision_2: 0.9326 - recall_2: 0.9369 - auc_2: 0.9748\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0820 - accuracy: 0.9639 - precision_2: 0.9625 - recall_2: 0.9603 - auc_2: 0.9845\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.9488 - accuracy: 0.9628 - precision_2: 0.9624 - recall_2: 0.9579 - auc_2: 0.9864\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.8737 - accuracy: 0.9529 - precision_2: 0.9425 - recall_2: 0.9579 - auc_2: 0.9852\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7760 - accuracy: 0.9639 - precision_2: 0.9669 - recall_2: 0.9556 - auc_2: 0.9873\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8298 - accuracy: 0.9299 - precision_2: 0.9194 - recall_2: 0.9322 - auc_2: 0.9687\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.7402 - accuracy: 0.9507 - precision_2: 0.9527 - recall_2: 0.9416 - auc_2: 0.9834\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6650 - accuracy: 0.9562 - precision_2: 0.9755 - recall_2: 0.9299 - auc_2: 0.9828\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5869 - accuracy: 0.9606 - precision_2: 0.9516 - recall_2: 0.9650 - auc_2: 0.9857\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4735 - accuracy: 0.9770 - precision_2: 0.9766 - recall_2: 0.9743 - auc_2: 0.9925\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3944 - accuracy: 0.9814 - precision_2: 0.9813 - recall_2: 0.9790 - auc_2: 0.9932\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3473 - accuracy: 0.9770 - precision_2: 0.9766 - recall_2: 0.9743 - auc_2: 0.9931\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3025 - accuracy: 0.9781 - precision_2: 0.9744 - recall_2: 0.9790 - auc_2: 0.9945\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2539 - accuracy: 0.9814 - precision_2: 0.9790 - recall_2: 0.9813 - auc_2: 0.9959\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2270 - accuracy: 0.9792 - precision_2: 0.9701 - recall_2: 0.9860 - auc_2: 0.9954\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2028 - accuracy: 0.9726 - precision_2: 0.9764 - recall_2: 0.9650 - auc_2: 0.9960\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1849 - accuracy: 0.9748 - precision_2: 0.9765 - recall_2: 0.9696 - auc_2: 0.9914\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1316 - accuracy: 0.9890 - precision_2: 0.9883 - recall_2: 0.9883 - auc_2: 0.9963\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1690 - accuracy: 0.9650 - precision_2: 0.9714 - recall_2: 0.9533 - auc_2: 0.9879\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1149 - accuracy: 0.9737 - precision_2: 0.9833 - recall_2: 0.9603 - auc_2: 0.9925\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0472 - accuracy: 0.9869 - precision_2: 0.9929 - recall_2: 0.9790 - auc_2: 0.9969\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0439 - accuracy: 0.9781 - precision_2: 0.9811 - recall_2: 0.9720 - auc_2: 0.9951\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0085 - accuracy: 0.9847 - precision_2: 0.9905 - recall_2: 0.9766 - auc_2: 0.9978\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9771 - accuracy: 0.9880 - precision_2: 0.9906 - recall_2: 0.9836 - auc_2: 0.9980\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9601 - accuracy: 0.9880 - precision_2: 0.9883 - recall_2: 0.9860 - auc_2: 0.9977\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9131 - accuracy: 0.9934 - precision_2: 0.9930 - recall_2: 0.9930 - auc_2: 0.9999\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8872 - accuracy: 0.9967 - precision_2: 0.9977 - recall_2: 0.9953 - auc_2: 0.9996\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8640 - accuracy: 0.9978 - precision_2: 0.9977 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8562 - accuracy: 0.9945 - precision_2: 0.9930 - recall_2: 0.9953 - auc_2: 0.9998\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8459 - accuracy: 0.9934 - precision_2: 0.9930 - recall_2: 0.9930 - auc_2: 0.9980\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8097 - accuracy: 0.9967 - precision_2: 0.9953 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9805 - accuracy: 0.9321 - precision_2: 0.9256 - recall_2: 0.9299 - auc_2: 0.9739\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9351 - accuracy: 0.9704 - precision_2: 0.9926 - recall_2: 0.9439 - auc_2: 0.9935\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8619 - accuracy: 0.9825 - precision_2: 0.9836 - recall_2: 0.9790 - auc_2: 0.9971\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8205 - accuracy: 0.9890 - precision_2: 0.9883 - recall_2: 0.9883 - auc_2: 0.9966\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7717 - accuracy: 0.9945 - precision_2: 0.9930 - recall_2: 0.9953 - auc_2: 0.9990\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7499 - accuracy: 0.9923 - precision_2: 0.9930 - recall_2: 0.9907 - auc_2: 0.9994\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7175 - accuracy: 0.9989 - precision_2: 1.0000 - recall_2: 0.9977 - auc_2: 0.9993\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7022 - accuracy: 0.9956 - precision_2: 0.9930 - recall_2: 0.9977 - auc_2: 0.9999\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6862 - accuracy: 0.9956 - precision_2: 0.9930 - recall_2: 0.9977 - auc_2: 1.0000\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 10.7224 - accuracy: 0.4852 - precision_3: 0.4420 - recall_3: 0.3738 - auc_3: 0.4656\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.2414 - accuracy: 0.5498 - precision_3: 0.5212 - recall_3: 0.4883 - auc_3: 0.5662\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.7308 - accuracy: 0.5685 - precision_3: 0.5450 - recall_3: 0.4813 - auc_3: 0.5987\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.1311 - accuracy: 0.6210 - precision_3: 0.6414 - recall_3: 0.4346 - auc_3: 0.6916\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.6500 - accuracy: 0.7076 - precision_3: 0.6761 - recall_3: 0.7220 - auc_3: 0.7718\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.2331 - accuracy: 0.7777 - precision_3: 0.7778 - recall_3: 0.7360 - auc_3: 0.8634\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.9089 - accuracy: 0.8740 - precision_3: 0.8735 - recall_3: 0.8551 - auc_3: 0.9353\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.6642 - accuracy: 0.8883 - precision_3: 0.8606 - recall_3: 0.9089 - auc_3: 0.9460\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4130 - accuracy: 0.9354 - precision_3: 0.9281 - recall_3: 0.9346 - auc_3: 0.9717\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 52ms/step - loss: 2.2574 - accuracy: 0.9376 - precision_3: 0.9365 - recall_3: 0.9299 - auc_3: 0.9766\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.1571 - accuracy: 0.9441 - precision_3: 0.9456 - recall_3: 0.9346 - auc_3: 0.9730\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0067 - accuracy: 0.9573 - precision_3: 0.9576 - recall_3: 0.9509 - auc_3: 0.9878\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.9383 - accuracy: 0.9430 - precision_3: 0.9372 - recall_3: 0.9416 - auc_3: 0.9808\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8820 - accuracy: 0.9430 - precision_3: 0.9541 - recall_3: 0.9229 - auc_3: 0.9800\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.7432 - accuracy: 0.9704 - precision_3: 0.9652 - recall_3: 0.9720 - auc_3: 0.9889\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6390 - accuracy: 0.9628 - precision_3: 0.9624 - recall_3: 0.9579 - auc_3: 0.9920\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5596 - accuracy: 0.9715 - precision_3: 0.9696 - recall_3: 0.9696 - auc_3: 0.9910\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4842 - accuracy: 0.9781 - precision_3: 0.9789 - recall_3: 0.9743 - auc_3: 0.9937\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5224 - accuracy: 0.9409 - precision_3: 0.9561 - recall_3: 0.9159 - auc_3: 0.9785\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4662 - accuracy: 0.9496 - precision_3: 0.9505 - recall_3: 0.9416 - auc_3: 0.9831\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4487 - accuracy: 0.9376 - precision_3: 0.9385 - recall_3: 0.9276 - auc_3: 0.9814\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3726 - accuracy: 0.9584 - precision_3: 0.9452 - recall_3: 0.9673 - auc_3: 0.9834\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2966 - accuracy: 0.9726 - precision_3: 0.9569 - recall_3: 0.9860 - auc_3: 0.9936\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2465 - accuracy: 0.9770 - precision_3: 0.9722 - recall_3: 0.9790 - auc_3: 0.9937\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1895 - accuracy: 0.9825 - precision_3: 0.9882 - recall_3: 0.9743 - auc_3: 0.9937\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1416 - accuracy: 0.9781 - precision_3: 0.9789 - recall_3: 0.9743 - auc_3: 0.9977\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1268 - accuracy: 0.9825 - precision_3: 0.9747 - recall_3: 0.9883 - auc_3: 0.9962\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0905 - accuracy: 0.9890 - precision_3: 0.9906 - recall_3: 0.9860 - auc_3: 0.9945\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0483 - accuracy: 0.9923 - precision_3: 0.9930 - recall_3: 0.9907 - auc_3: 0.9959\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0920 - accuracy: 0.9617 - precision_3: 0.9602 - recall_3: 0.9579 - auc_3: 0.9886\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0461 - accuracy: 0.9759 - precision_3: 0.9810 - recall_3: 0.9673 - auc_3: 0.9932\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0055 - accuracy: 0.9869 - precision_3: 0.9860 - recall_3: 0.9860 - auc_3: 0.9949\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9703 - accuracy: 0.9869 - precision_3: 0.9883 - recall_3: 0.9836 - auc_3: 0.9959\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9358 - accuracy: 0.9901 - precision_3: 0.9883 - recall_3: 0.9907 - auc_3: 0.9979\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8979 - accuracy: 0.9934 - precision_3: 0.9930 - recall_3: 0.9930 - auc_3: 0.9995\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9017 - accuracy: 0.9836 - precision_3: 0.9859 - recall_3: 0.9790 - auc_3: 0.9962\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8922 - accuracy: 0.9825 - precision_3: 0.9769 - recall_3: 0.9860 - auc_3: 0.9965\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8623 - accuracy: 0.9923 - precision_3: 0.9930 - recall_3: 0.9907 - auc_3: 0.9978\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8343 - accuracy: 0.9945 - precision_3: 0.9953 - recall_3: 0.9930 - auc_3: 0.9994\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8272 - accuracy: 0.9880 - precision_3: 0.9883 - recall_3: 0.9860 - auc_3: 0.9980\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8287 - accuracy: 0.9825 - precision_3: 0.9836 - recall_3: 0.9790 - auc_3: 0.9970\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8124 - accuracy: 0.9923 - precision_3: 0.9930 - recall_3: 0.9907 - auc_3: 0.9983\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7868 - accuracy: 0.9956 - precision_3: 0.9953 - recall_3: 0.9953 - auc_3: 0.9999\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7648 - accuracy: 0.9967 - precision_3: 0.9953 - recall_3: 0.9977 - auc_3: 0.9997\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7384 - accuracy: 0.9967 - precision_3: 0.9977 - recall_3: 0.9953 - auc_3: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7230 - accuracy: 0.9956 - precision_3: 0.9953 - recall_3: 0.9953 - auc_3: 0.9997\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7783 - accuracy: 0.9814 - precision_3: 0.9813 - recall_3: 0.9790 - auc_3: 0.9980\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9125 - accuracy: 0.9332 - precision_3: 0.9051 - recall_3: 0.9579 - auc_3: 0.9811\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9240 - accuracy: 0.9277 - precision_3: 0.9415 - recall_3: 0.9019 - auc_3: 0.9800\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8195 - accuracy: 0.9770 - precision_3: 0.9880 - recall_3: 0.9626 - auc_3: 0.9949\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 10.9112 - accuracy: 0.5104 - precision_4: 0.4767 - recall_4: 0.4533 - auc_4: 0.5083\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.4600 - accuracy: 0.5312 - precision_4: 0.5000 - recall_4: 0.4556 - auc_4: 0.5265\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.7898 - accuracy: 0.5816 - precision_4: 0.5593 - recall_4: 0.5070 - auc_4: 0.6008\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.1446 - accuracy: 0.6123 - precision_4: 0.5774 - recall_4: 0.6449 - auc_4: 0.6632\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.6281 - accuracy: 0.7076 - precision_4: 0.7028 - recall_4: 0.6519 - auc_4: 0.7814\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.2252 - accuracy: 0.7470 - precision_4: 0.7599 - recall_4: 0.6729 - auc_4: 0.8209\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.9029 - accuracy: 0.8007 - precision_4: 0.8045 - recall_4: 0.7593 - auc_4: 0.8889\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.6528 - accuracy: 0.8817 - precision_4: 0.8463 - recall_4: 0.9136 - auc_4: 0.9381\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.4656 - accuracy: 0.9047 - precision_4: 0.9012 - recall_4: 0.8949 - auc_4: 0.9553\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.2840 - accuracy: 0.9266 - precision_4: 0.9112 - recall_4: 0.9346 - auc_4: 0.9714\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.1109 - accuracy: 0.9485 - precision_4: 0.9568 - recall_4: 0.9322 - auc_4: 0.9799\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.1879 - accuracy: 0.8795 - precision_4: 0.8581 - recall_4: 0.8902 - auc_4: 0.9387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.0677 - accuracy: 0.9266 - precision_4: 0.9457 - recall_4: 0.8949 - auc_4: 0.9723\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.9213 - accuracy: 0.9485 - precision_4: 0.9504 - recall_4: 0.9393 - auc_4: 0.9823\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.7871 - accuracy: 0.9573 - precision_4: 0.9534 - recall_4: 0.9556 - auc_4: 0.9844\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.7007 - accuracy: 0.9595 - precision_4: 0.9536 - recall_4: 0.9603 - auc_4: 0.9840\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.6304 - accuracy: 0.9595 - precision_4: 0.9494 - recall_4: 0.9650 - auc_4: 0.9883\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5936 - accuracy: 0.9551 - precision_4: 0.9448 - recall_4: 0.9603 - auc_4: 0.9817\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5099 - accuracy: 0.9671 - precision_4: 0.9761 - recall_4: 0.9533 - auc_4: 0.9894\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4119 - accuracy: 0.9748 - precision_4: 0.9833 - recall_4: 0.9626 - auc_4: 0.9942\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4534 - accuracy: 0.9332 - precision_4: 0.9199 - recall_4: 0.9393 - auc_4: 0.9773\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3680 - accuracy: 0.9628 - precision_4: 0.9646 - recall_4: 0.9556 - auc_4: 0.9873\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3101 - accuracy: 0.9737 - precision_4: 0.9879 - recall_4: 0.9556 - auc_4: 0.9906\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2517 - accuracy: 0.9726 - precision_4: 0.9786 - recall_4: 0.9626 - auc_4: 0.9925\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2426 - accuracy: 0.9726 - precision_4: 0.9832 - recall_4: 0.9579 - auc_4: 0.9872\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2564 - accuracy: 0.9573 - precision_4: 0.9664 - recall_4: 0.9416 - auc_4: 0.9861\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1788 - accuracy: 0.9792 - precision_4: 0.9904 - recall_4: 0.9650 - auc_4: 0.9941\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1358 - accuracy: 0.9847 - precision_4: 0.9905 - recall_4: 0.9766 - auc_4: 0.9967\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1359 - accuracy: 0.9781 - precision_4: 0.9766 - recall_4: 0.9766 - auc_4: 0.9927\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0923 - accuracy: 0.9858 - precision_4: 0.9882 - recall_4: 0.9813 - auc_4: 0.9937\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0815 - accuracy: 0.9770 - precision_4: 0.9766 - recall_4: 0.9743 - auc_4: 0.9950\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0376 - accuracy: 0.9880 - precision_4: 0.9838 - recall_4: 0.9907 - auc_4: 0.9969\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1692 - accuracy: 0.9409 - precision_4: 0.9289 - recall_4: 0.9463 - auc_4: 0.9688\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1164 - accuracy: 0.9650 - precision_4: 0.9737 - recall_4: 0.9509 - auc_4: 0.9923\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0490 - accuracy: 0.9803 - precision_4: 0.9881 - recall_4: 0.9696 - auc_4: 0.9966\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9938 - accuracy: 0.9836 - precision_4: 0.9836 - recall_4: 0.9813 - auc_4: 0.9977\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9422 - accuracy: 0.9880 - precision_4: 0.9793 - recall_4: 0.9953 - auc_4: 0.9988\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9263 - accuracy: 0.9759 - precision_4: 0.9743 - recall_4: 0.9743 - auc_4: 0.9965\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8852 - accuracy: 0.9912 - precision_4: 0.9953 - recall_4: 0.9860 - auc_4: 0.9965\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8537 - accuracy: 0.9912 - precision_4: 1.0000 - recall_4: 0.9813 - auc_4: 0.9986\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8446 - accuracy: 0.9890 - precision_4: 0.9906 - recall_4: 0.9860 - auc_4: 0.9974\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8018 - accuracy: 0.9978 - precision_4: 0.9953 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7976 - accuracy: 0.9912 - precision_4: 0.9884 - recall_4: 0.9930 - auc_4: 0.9997\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7760 - accuracy: 0.9956 - precision_4: 0.9953 - recall_4: 0.9953 - auc_4: 0.9992\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7536 - accuracy: 0.9978 - precision_4: 0.9977 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7355 - accuracy: 0.9989 - precision_4: 1.0000 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7181 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6982 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6850 - accuracy: 0.9978 - precision_4: 0.9977 - recall_4: 0.9977 - auc_4: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7078 - accuracy: 0.9956 - precision_4: 0.9953 - recall_4: 0.9953 - auc_4: 0.9999\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff820eaa7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " Accuracy: 98.865% (+/-1.254) \n",
      " Precision: 98.333% (+/-3.333) \n",
      " Recall: 98.864% (+/-1.245) \n",
      " AUC: 99.732% (+/-0.350) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 11.0949 - accuracy: 0.5356 - precision_5: 0.5053 - recall_5: 0.4463 - auc_5: 0.5638\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 6.8574 - accuracy: 0.6134 - precision_5: 0.5931 - recall_5: 0.5584 - auc_5: 0.6723\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.0135 - accuracy: 0.7174 - precision_5: 0.6714 - recall_5: 0.7780 - auc_5: 0.8078\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.4151 - accuracy: 0.6386 - precision_5: 0.6244 - recall_5: 0.5748 - auc_5: 0.7138\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.8288 - accuracy: 0.8105 - precision_5: 0.8102 - recall_5: 0.7780 - auc_5: 0.8983\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.3753 - accuracy: 0.8905 - precision_5: 0.8694 - recall_5: 0.9019 - auc_5: 0.9540\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.0247 - accuracy: 0.9299 - precision_5: 0.9062 - recall_5: 0.9486 - auc_5: 0.9794\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.7944 - accuracy: 0.9485 - precision_5: 0.9504 - recall_5: 0.9393 - auc_5: 0.9881\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.6405 - accuracy: 0.9463 - precision_5: 0.9356 - recall_5: 0.9509 - auc_5: 0.9884\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.6535 - accuracy: 0.9036 - precision_5: 0.8696 - recall_5: 0.9346 - auc_5: 0.9627\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5426 - accuracy: 0.9463 - precision_5: 0.9459 - recall_5: 0.9393 - auc_5: 0.9849\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4373 - accuracy: 0.9419 - precision_5: 0.9412 - recall_5: 0.9346 - auc_5: 0.9832\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.2771 - accuracy: 0.9529 - precision_5: 0.9551 - recall_5: 0.9439 - auc_5: 0.9907\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.1105 - accuracy: 0.9704 - precision_5: 0.9696 - recall_5: 0.9673 - auc_5: 0.9951\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.9539 - accuracy: 0.9836 - precision_5: 0.9859 - recall_5: 0.9790 - auc_5: 0.9982\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.8514 - accuracy: 0.9792 - precision_5: 0.9812 - recall_5: 0.9743 - auc_5: 0.9983\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7687 - accuracy: 0.9869 - precision_5: 0.9883 - recall_5: 0.9836 - auc_5: 0.9987\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6720 - accuracy: 0.9934 - precision_5: 0.9930 - recall_5: 0.9930 - auc_5: 0.9998\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5945 - accuracy: 0.9912 - precision_5: 0.9930 - recall_5: 0.9883 - auc_5: 0.9987\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5351 - accuracy: 0.9890 - precision_5: 0.9883 - recall_5: 0.9883 - auc_5: 0.9995\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4861 - accuracy: 0.9934 - precision_5: 0.9976 - recall_5: 0.9883 - auc_5: 0.9996\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4458 - accuracy: 0.9934 - precision_5: 0.9953 - recall_5: 0.9907 - auc_5: 0.9994\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4040 - accuracy: 0.9923 - precision_5: 0.9907 - recall_5: 0.9930 - auc_5: 0.9998\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4851 - accuracy: 0.9540 - precision_5: 0.9595 - recall_5: 0.9416 - auc_5: 0.9889\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4057 - accuracy: 0.9858 - precision_5: 0.9792 - recall_5: 0.9907 - auc_5: 0.9991\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3327 - accuracy: 0.9880 - precision_5: 0.9883 - recall_5: 0.9860 - auc_5: 0.9991\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2498 - accuracy: 0.9967 - precision_5: 1.0000 - recall_5: 0.9930 - auc_5: 0.9999\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1849 - accuracy: 0.9989 - precision_5: 1.0000 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1327 - accuracy: 0.9989 - precision_5: 0.9977 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2020 - accuracy: 0.9737 - precision_5: 0.9879 - recall_5: 0.9556 - auc_5: 0.9923\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2324 - accuracy: 0.9858 - precision_5: 0.9837 - recall_5: 0.9860 - auc_5: 0.9984\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1970 - accuracy: 0.9923 - precision_5: 0.9930 - recall_5: 0.9907 - auc_5: 0.9996\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1094 - accuracy: 0.9967 - precision_5: 0.9930 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0503 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0337 - accuracy: 0.9901 - precision_5: 0.9883 - recall_5: 0.9907 - auc_5: 0.9992\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0210 - accuracy: 0.9912 - precision_5: 0.9907 - recall_5: 0.9907 - auc_5: 0.9990\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9800 - accuracy: 0.9934 - precision_5: 0.9930 - recall_5: 0.9930 - auc_5: 0.9999\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9342 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8966 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8629 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8413 - accuracy: 0.9978 - precision_5: 0.9977 - recall_5: 0.9977 - auc_5: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8392 - accuracy: 0.9956 - precision_5: 0.9953 - recall_5: 0.9953 - auc_5: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8321 - accuracy: 0.9967 - precision_5: 0.9953 - recall_5: 0.9977 - auc_5: 0.9999\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0812 - accuracy: 0.8959 - precision_5: 0.9325 - recall_5: 0.8388 - auc_5: 0.9616\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0860 - accuracy: 0.9452 - precision_5: 0.9163 - recall_5: 0.9720 - auc_5: 0.9859\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0427 - accuracy: 0.9485 - precision_5: 0.9281 - recall_5: 0.9650 - auc_5: 0.9848\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9002 - accuracy: 0.9890 - precision_5: 0.9860 - recall_5: 0.9907 - auc_5: 0.9982\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8525 - accuracy: 0.9880 - precision_5: 0.9976 - recall_5: 0.9766 - auc_5: 0.9973\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8484 - accuracy: 0.9704 - precision_5: 0.9630 - recall_5: 0.9743 - auc_5: 0.9946\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7880 - accuracy: 0.9934 - precision_5: 0.9862 - recall_5: 1.0000 - auc_5: 0.9993\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff82064f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 10.8975 - accuracy: 0.5465 - precision_6: 0.5217 - recall_6: 0.3925 - auc_6: 0.5905\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.5903 - accuracy: 0.6101 - precision_6: 0.5679 - recall_6: 0.7033 - auc_6: 0.6565\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.9083 - accuracy: 0.7087 - precision_6: 0.6695 - recall_6: 0.7477 - auc_6: 0.7907\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.2021 - accuracy: 0.8050 - precision_6: 0.7717 - recall_6: 0.8294 - auc_6: 0.8852\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.7940 - accuracy: 0.8116 - precision_6: 0.7581 - recall_6: 0.8785 - auc_6: 0.9032\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.3463 - accuracy: 0.9113 - precision_6: 0.8881 - recall_6: 0.9276 - auc_6: 0.9752\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.0486 - accuracy: 0.9398 - precision_6: 0.9347 - recall_6: 0.9369 - auc_6: 0.9781\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.8509 - accuracy: 0.9321 - precision_6: 0.9276 - recall_6: 0.9276 - auc_6: 0.9825\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.6564 - accuracy: 0.9584 - precision_6: 0.9432 - recall_6: 0.9696 - auc_6: 0.9911\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4700 - accuracy: 0.9628 - precision_6: 0.9603 - recall_6: 0.9603 - auc_6: 0.9946\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3475 - accuracy: 0.9562 - precision_6: 0.9491 - recall_6: 0.9579 - auc_6: 0.9916\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2035 - accuracy: 0.9759 - precision_6: 0.9765 - recall_6: 0.9720 - auc_6: 0.9948\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.0641 - accuracy: 0.9836 - precision_6: 0.9747 - recall_6: 0.9907 - auc_6: 0.9974\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1182 - accuracy: 0.9222 - precision_6: 0.9161 - recall_6: 0.9182 - auc_6: 0.9759\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.0069 - accuracy: 0.9573 - precision_6: 0.9471 - recall_6: 0.9626 - auc_6: 0.9925\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8990 - accuracy: 0.9628 - precision_6: 0.9624 - recall_6: 0.9579 - auc_6: 0.9929\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8129 - accuracy: 0.9496 - precision_6: 0.9442 - recall_6: 0.9486 - auc_6: 0.9930\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6877 - accuracy: 0.9890 - precision_6: 0.9953 - recall_6: 0.9813 - auc_6: 0.9975\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6183 - accuracy: 0.9858 - precision_6: 0.9905 - recall_6: 0.9790 - auc_6: 0.9988\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5407 - accuracy: 0.9956 - precision_6: 0.9930 - recall_6: 0.9977 - auc_6: 0.9996\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4599 - accuracy: 0.9945 - precision_6: 0.9953 - recall_6: 0.9930 - auc_6: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4157 - accuracy: 0.9934 - precision_6: 0.9930 - recall_6: 0.9930 - auc_6: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3887 - accuracy: 0.9901 - precision_6: 0.9883 - recall_6: 0.9907 - auc_6: 0.9997\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3443 - accuracy: 0.9901 - precision_6: 0.9861 - recall_6: 0.9930 - auc_6: 0.9990\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3155 - accuracy: 0.9945 - precision_6: 0.9930 - recall_6: 0.9953 - auc_6: 0.9990\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2990 - accuracy: 0.9836 - precision_6: 0.9769 - recall_6: 0.9883 - auc_6: 0.9985\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2564 - accuracy: 0.9890 - precision_6: 0.9883 - recall_6: 0.9883 - auc_6: 0.9984\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1924 - accuracy: 0.9989 - precision_6: 1.0000 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1384 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0928 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0600 - accuracy: 0.9989 - precision_6: 1.0000 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0467 - accuracy: 0.9923 - precision_6: 0.9884 - recall_6: 0.9953 - auc_6: 0.9995\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0385 - accuracy: 0.9901 - precision_6: 0.9906 - recall_6: 0.9883 - auc_6: 0.9986\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1330 - accuracy: 0.9660 - precision_6: 0.9522 - recall_6: 0.9766 - auc_6: 0.9936\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1150 - accuracy: 0.9967 - precision_6: 1.0000 - recall_6: 0.9930 - auc_6: 0.9999\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.0502 - accuracy: 0.9989 - precision_6: 0.9977 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9851 - accuracy: 0.9978 - precision_6: 0.9977 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9324 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8958 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8660 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8449 - accuracy: 0.9978 - precision_6: 0.9977 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8557 - accuracy: 0.9923 - precision_6: 0.9953 - recall_6: 0.9883 - auc_6: 0.9988\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8895 - accuracy: 0.9978 - precision_6: 1.0000 - recall_6: 0.9953 - auc_6: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9122 - accuracy: 0.9978 - precision_6: 0.9977 - recall_6: 0.9977 - auc_6: 0.9999\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8780 - accuracy: 0.9967 - precision_6: 0.9977 - recall_6: 0.9953 - auc_6: 0.9997\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8455 - accuracy: 0.9923 - precision_6: 0.9930 - recall_6: 0.9907 - auc_6: 0.9998\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8059 - accuracy: 0.9967 - precision_6: 0.9953 - recall_6: 0.9977 - auc_6: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7823 - accuracy: 0.9967 - precision_6: 0.9953 - recall_6: 0.9977 - auc_6: 0.9999\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0546 - accuracy: 0.8620 - precision_6: 0.8953 - recall_6: 0.7991 - auc_6: 0.9544\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0159 - accuracy: 0.9595 - precision_6: 0.9335 - recall_6: 0.9836 - auc_6: 0.9889\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff73c038e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 11.2880 - accuracy: 0.5181 - precision_7: 0.4860 - recall_7: 0.4860 - auc_7: 0.5211\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 7.1232 - accuracy: 0.5367 - precision_7: 0.5069 - recall_7: 0.4276 - auc_7: 0.5474\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.2986 - accuracy: 0.5246 - precision_7: 0.4935 - recall_7: 0.5327 - auc_7: 0.5539\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.4733 - accuracy: 0.5936 - precision_7: 0.6234 - recall_7: 0.3364 - auc_7: 0.6499\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.9078 - accuracy: 0.6495 - precision_7: 0.6159 - recall_7: 0.6706 - auc_7: 0.7082\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.4337 - accuracy: 0.7514 - precision_7: 0.7072 - recall_7: 0.8014 - auc_7: 0.8307\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.0529 - accuracy: 0.8434 - precision_7: 0.8306 - recall_7: 0.8364 - auc_7: 0.9171\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.7455 - accuracy: 0.9058 - precision_7: 0.9071 - recall_7: 0.8902 - auc_7: 0.9633\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5006 - accuracy: 0.9277 - precision_7: 0.9289 - recall_7: 0.9159 - auc_7: 0.9800\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3778 - accuracy: 0.9277 - precision_7: 0.9229 - recall_7: 0.9229 - auc_7: 0.9734\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3995 - accuracy: 0.8686 - precision_7: 0.8565 - recall_7: 0.8645 - auc_7: 0.9386\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.2039 - accuracy: 0.9332 - precision_7: 0.9258 - recall_7: 0.9322 - auc_7: 0.9790\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.0457 - accuracy: 0.9474 - precision_7: 0.9439 - recall_7: 0.9439 - auc_7: 0.9850\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8779 - accuracy: 0.9628 - precision_7: 0.9624 - recall_7: 0.9579 - auc_7: 0.9916\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7636 - accuracy: 0.9759 - precision_7: 0.9788 - recall_7: 0.9696 - auc_7: 0.9948\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.6923 - accuracy: 0.9726 - precision_7: 0.9809 - recall_7: 0.9603 - auc_7: 0.9926\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6297 - accuracy: 0.9715 - precision_7: 0.9718 - recall_7: 0.9673 - auc_7: 0.9951\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5822 - accuracy: 0.9715 - precision_7: 0.9855 - recall_7: 0.9533 - auc_7: 0.9949\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5093 - accuracy: 0.9847 - precision_7: 0.9814 - recall_7: 0.9860 - auc_7: 0.9985\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4485 - accuracy: 0.9858 - precision_7: 0.9905 - recall_7: 0.9790 - auc_7: 0.9985\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4394 - accuracy: 0.9704 - precision_7: 0.9674 - recall_7: 0.9696 - auc_7: 0.9966\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4881 - accuracy: 0.9529 - precision_7: 0.9425 - recall_7: 0.9579 - auc_7: 0.9900\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4584 - accuracy: 0.9682 - precision_7: 0.9672 - recall_7: 0.9650 - auc_7: 0.9942\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3803 - accuracy: 0.9770 - precision_7: 0.9857 - recall_7: 0.9650 - auc_7: 0.9965\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.2820 - accuracy: 0.9945 - precision_7: 0.9953 - recall_7: 0.9930 - auc_7: 0.9988\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1889 - accuracy: 0.9945 - precision_7: 0.9953 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1266 - accuracy: 0.9967 - precision_7: 1.0000 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0817 - accuracy: 0.9956 - precision_7: 0.9977 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0536 - accuracy: 0.9945 - precision_7: 0.9907 - recall_7: 0.9977 - auc_7: 0.9994\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0445 - accuracy: 0.9923 - precision_7: 0.9953 - recall_7: 0.9883 - auc_7: 0.9998\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2117 - accuracy: 0.9288 - precision_7: 0.9007 - recall_7: 0.9533 - auc_7: 0.9836\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1391 - accuracy: 0.9880 - precision_7: 0.9906 - recall_7: 0.9836 - auc_7: 0.9993\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0644 - accuracy: 0.9890 - precision_7: 0.9906 - recall_7: 0.9860 - auc_7: 0.9990\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9950 - accuracy: 0.9912 - precision_7: 0.9884 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9701 - accuracy: 0.9912 - precision_7: 0.9907 - recall_7: 0.9907 - auc_7: 0.9992\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9904 - accuracy: 0.9847 - precision_7: 0.9792 - recall_7: 0.9883 - auc_7: 0.9984\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9663 - accuracy: 0.9880 - precision_7: 0.9793 - recall_7: 0.9953 - auc_7: 0.9996\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9257 - accuracy: 0.9923 - precision_7: 0.9884 - recall_7: 0.9953 - auc_7: 0.9999\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8934 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8571 - accuracy: 0.9934 - precision_7: 0.9976 - recall_7: 0.9883 - auc_7: 0.9998\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8396 - accuracy: 0.9934 - precision_7: 0.9930 - recall_7: 0.9930 - auc_7: 0.9998\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8947 - accuracy: 0.9825 - precision_7: 0.9791 - recall_7: 0.9836 - auc_7: 0.9987\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9227 - accuracy: 0.9934 - precision_7: 0.9930 - recall_7: 0.9930 - auc_7: 0.9999\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8546 - accuracy: 0.9989 - precision_7: 1.0000 - recall_7: 0.9977 - auc_7: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7935 - accuracy: 0.9978 - precision_7: 0.9977 - recall_7: 0.9977 - auc_7: 0.9999\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7513 - accuracy: 0.9978 - precision_7: 1.0000 - recall_7: 0.9953 - auc_7: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8464 - accuracy: 0.9529 - precision_7: 0.9345 - recall_7: 0.9673 - auc_7: 0.9909\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8756 - accuracy: 0.9606 - precision_7: 0.9804 - recall_7: 0.9346 - auc_7: 0.9862\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8289 - accuracy: 0.9748 - precision_7: 0.9951 - recall_7: 0.9509 - auc_7: 0.9960\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7738 - accuracy: 0.9901 - precision_7: 0.9906 - recall_7: 0.9883 - auc_7: 0.9992\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff8218ff730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 11.2092 - accuracy: 0.4940 - precision_8: 0.4325 - recall_8: 0.2547 - auc_8: 0.5042\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 6.9809 - accuracy: 0.5444 - precision_8: 0.5117 - recall_8: 0.6145 - auc_8: 0.5705\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 5.1615 - accuracy: 0.6002 - precision_8: 0.5636 - recall_8: 0.6519 - auc_8: 0.6459\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.3753 - accuracy: 0.6550 - precision_8: 0.6200 - recall_8: 0.6822 - auc_8: 0.7191\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.7921 - accuracy: 0.7722 - precision_8: 0.7489 - recall_8: 0.7734 - auc_8: 0.8570\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.2989 - accuracy: 0.8784 - precision_8: 0.8453 - recall_8: 0.9065 - auc_8: 0.9409\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.9456 - accuracy: 0.9277 - precision_8: 0.9249 - recall_8: 0.9206 - auc_8: 0.9714\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.7851 - accuracy: 0.9080 - precision_8: 0.9095 - recall_8: 0.8925 - auc_8: 0.9612\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.5669 - accuracy: 0.9441 - precision_8: 0.9294 - recall_8: 0.9533 - auc_8: 0.9878\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3854 - accuracy: 0.9617 - precision_8: 0.9624 - recall_8: 0.9556 - auc_8: 0.9919\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.2145 - accuracy: 0.9770 - precision_8: 0.9788 - recall_8: 0.9720 - auc_8: 0.9959\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0822 - accuracy: 0.9748 - precision_8: 0.9698 - recall_8: 0.9766 - auc_8: 0.9965\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0022 - accuracy: 0.9715 - precision_8: 0.9786 - recall_8: 0.9603 - auc_8: 0.9933\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8884 - accuracy: 0.9858 - precision_8: 0.9905 - recall_8: 0.9790 - auc_8: 0.9977\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7704 - accuracy: 0.9912 - precision_8: 0.9953 - recall_8: 0.9860 - auc_8: 0.9990\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6833 - accuracy: 0.9847 - precision_8: 0.9905 - recall_8: 0.9766 - auc_8: 0.9992\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.6056 - accuracy: 0.9945 - precision_8: 0.9976 - recall_8: 0.9907 - auc_8: 0.9995\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.6889 - accuracy: 0.9650 - precision_8: 0.9670 - recall_8: 0.9579 - auc_8: 0.9948\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.7532 - accuracy: 0.9781 - precision_8: 0.9789 - recall_8: 0.9743 - auc_8: 0.9972\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6663 - accuracy: 0.9748 - precision_8: 0.9765 - recall_8: 0.9696 - auc_8: 0.9957\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6234 - accuracy: 0.9441 - precision_8: 0.9456 - recall_8: 0.9346 - auc_8: 0.9896\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5540 - accuracy: 0.9573 - precision_8: 0.9534 - recall_8: 0.9556 - auc_8: 0.9904\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4091 - accuracy: 0.9847 - precision_8: 0.9792 - recall_8: 0.9883 - auc_8: 0.9976\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3061 - accuracy: 0.9923 - precision_8: 0.9953 - recall_8: 0.9883 - auc_8: 0.9996\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2299 - accuracy: 0.9945 - precision_8: 1.0000 - recall_8: 0.9883 - auc_8: 0.9997\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2056 - accuracy: 0.9912 - precision_8: 0.9953 - recall_8: 0.9860 - auc_8: 0.9993\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1827 - accuracy: 0.9956 - precision_8: 0.9977 - recall_8: 0.9930 - auc_8: 0.9999\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1229 - accuracy: 0.9956 - precision_8: 0.9977 - recall_8: 0.9930 - auc_8: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0754 - accuracy: 0.9967 - precision_8: 0.9977 - recall_8: 0.9953 - auc_8: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0513 - accuracy: 0.9934 - precision_8: 0.9930 - recall_8: 0.9930 - auc_8: 0.9996\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0745 - accuracy: 0.9759 - precision_8: 0.9743 - recall_8: 0.9743 - auc_8: 0.9964\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1506 - accuracy: 0.9540 - precision_8: 0.9509 - recall_8: 0.9509 - auc_8: 0.9896\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1390 - accuracy: 0.9671 - precision_8: 0.9482 - recall_8: 0.9836 - auc_8: 0.9949\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0814 - accuracy: 0.9792 - precision_8: 0.9767 - recall_8: 0.9790 - auc_8: 0.9967\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0208 - accuracy: 0.9869 - precision_8: 1.0000 - recall_8: 0.9720 - auc_8: 0.9981\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9779 - accuracy: 0.9912 - precision_8: 0.9884 - recall_8: 0.9930 - auc_8: 0.9989\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9396 - accuracy: 0.9923 - precision_8: 0.9907 - recall_8: 0.9930 - auc_8: 0.9995\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8980 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8696 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8423 - accuracy: 0.9967 - precision_8: 0.9977 - recall_8: 0.9953 - auc_8: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8189 - accuracy: 0.9967 - precision_8: 1.0000 - recall_8: 0.9930 - auc_8: 0.9999\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7980 - accuracy: 0.9978 - precision_8: 1.0000 - recall_8: 0.9953 - auc_8: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9507 - accuracy: 0.9376 - precision_8: 0.9264 - recall_8: 0.9416 - auc_8: 0.9795\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9166 - accuracy: 0.9737 - precision_8: 0.9676 - recall_8: 0.9766 - auc_8: 0.9944\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8791 - accuracy: 0.9814 - precision_8: 0.9952 - recall_8: 0.9650 - auc_8: 0.9966\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8461 - accuracy: 0.9803 - precision_8: 0.9812 - recall_8: 0.9766 - auc_8: 0.9973\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7827 - accuracy: 0.9945 - precision_8: 0.9885 - recall_8: 1.0000 - auc_8: 0.9996\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7828 - accuracy: 0.9858 - precision_8: 0.9882 - recall_8: 0.9813 - auc_8: 0.9979\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7378 - accuracy: 0.9967 - precision_8: 1.0000 - recall_8: 0.9930 - auc_8: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7163 - accuracy: 0.9967 - precision_8: 0.9953 - recall_8: 0.9977 - auc_8: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff7901b0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 11.0566 - accuracy: 0.5553 - precision_9: 0.5362 - recall_9: 0.3808 - auc_9: 0.5670\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 6.7716 - accuracy: 0.6846 - precision_9: 0.6246 - recall_9: 0.8201 - auc_9: 0.7554\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.9657 - accuracy: 0.7831 - precision_9: 0.7995 - recall_9: 0.7173 - auc_9: 0.8766\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.3003 - accuracy: 0.7558 - precision_9: 0.7412 - recall_9: 0.7360 - auc_9: 0.8417\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.7467 - accuracy: 0.8543 - precision_9: 0.8186 - recall_9: 0.8855 - auc_9: 0.9344\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.3053 - accuracy: 0.9277 - precision_9: 0.9132 - recall_9: 0.9346 - auc_9: 0.9688\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.0218 - accuracy: 0.9332 - precision_9: 0.9379 - recall_9: 0.9182 - auc_9: 0.9757\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.8569 - accuracy: 0.9189 - precision_9: 0.9060 - recall_9: 0.9229 - auc_9: 0.9657\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.6183 - accuracy: 0.9518 - precision_9: 0.9444 - recall_9: 0.9533 - auc_9: 0.9884\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4989 - accuracy: 0.9365 - precision_9: 0.9343 - recall_9: 0.9299 - auc_9: 0.9823\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3655 - accuracy: 0.9617 - precision_9: 0.9624 - recall_9: 0.9556 - auc_9: 0.9876\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.2193 - accuracy: 0.9748 - precision_9: 0.9787 - recall_9: 0.9673 - auc_9: 0.9954\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1108 - accuracy: 0.9748 - precision_9: 0.9787 - recall_9: 0.9673 - auc_9: 0.9961\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0102 - accuracy: 0.9814 - precision_9: 0.9813 - recall_9: 0.9790 - auc_9: 0.9959\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.8869 - accuracy: 0.9858 - precision_9: 0.9814 - recall_9: 0.9883 - auc_9: 0.9988\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.7806 - accuracy: 0.9912 - precision_9: 0.9907 - recall_9: 0.9907 - auc_9: 0.9997\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.6859 - accuracy: 0.9945 - precision_9: 0.9930 - recall_9: 0.9953 - auc_9: 0.9988\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.6719 - accuracy: 0.9803 - precision_9: 0.9881 - recall_9: 0.9696 - auc_9: 0.9976\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6213 - accuracy: 0.9912 - precision_9: 0.9907 - recall_9: 0.9907 - auc_9: 0.9992\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5445 - accuracy: 0.9923 - precision_9: 0.9884 - recall_9: 0.9953 - auc_9: 0.9989\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4703 - accuracy: 0.9912 - precision_9: 0.9907 - recall_9: 0.9907 - auc_9: 0.9993\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4182 - accuracy: 0.9956 - precision_9: 0.9953 - recall_9: 0.9953 - auc_9: 0.9983\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3758 - accuracy: 0.9923 - precision_9: 0.9907 - recall_9: 0.9930 - auc_9: 0.9986\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3121 - accuracy: 0.9989 - precision_9: 0.9977 - recall_9: 1.0000 - auc_9: 0.9998\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2495 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.2015 - accuracy: 0.9967 - precision_9: 0.9977 - recall_9: 0.9953 - auc_9: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1616 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1182 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3678 - accuracy: 0.9091 - precision_9: 0.8791 - recall_9: 0.9346 - auc_9: 0.9536\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4136 - accuracy: 0.9507 - precision_9: 0.9549 - recall_9: 0.9393 - auc_9: 0.9849\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3294 - accuracy: 0.9748 - precision_9: 0.9742 - recall_9: 0.9720 - auc_9: 0.9899\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2065 - accuracy: 0.9869 - precision_9: 0.9837 - recall_9: 0.9883 - auc_9: 0.9961\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1269 - accuracy: 0.9901 - precision_9: 0.9861 - recall_9: 0.9930 - auc_9: 0.9990\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0496 - accuracy: 0.9967 - precision_9: 0.9930 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0012 - accuracy: 0.9978 - precision_9: 0.9977 - recall_9: 0.9977 - auc_9: 0.9999\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9615 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9314 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9034 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8787 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8662 - accuracy: 0.9956 - precision_9: 0.9953 - recall_9: 0.9953 - auc_9: 0.9999\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9846 - accuracy: 0.9496 - precision_9: 0.9591 - recall_9: 0.9322 - auc_9: 0.9845\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9474 - accuracy: 0.9781 - precision_9: 0.9679 - recall_9: 0.9860 - auc_9: 0.9962\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8919 - accuracy: 0.9956 - precision_9: 0.9977 - recall_9: 0.9930 - auc_9: 0.9996\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8497 - accuracy: 0.9956 - precision_9: 0.9930 - recall_9: 0.9977 - auc_9: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8182 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7917 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7673 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.7466 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7313 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7173 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff7901b0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 97.729% (+/-1.392) \n",
      " Precision: 96.355% (+/-3.555) \n",
      " Recall: 97.955% (+/-1.325) \n",
      " AUC: 99.710% (+/-0.159) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),input_shape=(None,n_length,n_features))))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 12.8103 - accuracy: 0.5323 - precision_10: 0.5011 - recall_10: 0.5491 - auc_10: 0.5482\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 10.3054 - accuracy: 0.5838 - precision_10: 0.5609 - recall_10: 0.5164 - auc_10: 0.6165\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 8.1800 - accuracy: 0.6451 - precision_10: 0.6126 - recall_10: 0.6612 - auc_10: 0.6886\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 6.6570 - accuracy: 0.7163 - precision_10: 0.6952 - recall_10: 0.7033 - auc_10: 0.7984\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.6171 - accuracy: 0.8061 - precision_10: 0.7872 - recall_10: 0.8037 - auc_10: 0.8832\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.9009 - accuracy: 0.8729 - precision_10: 0.8750 - recall_10: 0.8505 - auc_10: 0.9430\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.4329 - accuracy: 0.9124 - precision_10: 0.9047 - recall_10: 0.9089 - auc_10: 0.9694\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.0544 - accuracy: 0.9518 - precision_10: 0.9486 - recall_10: 0.9486 - auc_10: 0.9904\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.7307 - accuracy: 0.9792 - precision_10: 0.9767 - recall_10: 0.9790 - auc_10: 0.9977\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.4431 - accuracy: 0.9836 - precision_10: 0.9836 - recall_10: 0.9813 - auc_10: 0.9992\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.1857 - accuracy: 0.9923 - precision_10: 0.9884 - recall_10: 0.9953 - auc_10: 0.9995\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.9972 - accuracy: 0.9869 - precision_10: 0.9906 - recall_10: 0.9813 - auc_10: 0.9991\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.8517 - accuracy: 0.9945 - precision_10: 0.9953 - recall_10: 0.9930 - auc_10: 0.9998\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.6864 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5012 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.3303 - accuracy: 0.9989 - precision_10: 0.9977 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1999 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1045 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0215 - accuracy: 0.9945 - precision_10: 0.9953 - recall_10: 0.9930 - auc_10: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.9475 - accuracy: 0.9956 - precision_10: 0.9953 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.8785 - accuracy: 0.9912 - precision_10: 0.9907 - recall_10: 0.9907 - auc_10: 0.9996\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.1405 - accuracy: 0.9080 - precision_10: 0.8891 - recall_10: 0.9182 - auc_10: 0.9743\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.4269 - accuracy: 0.9726 - precision_10: 0.9809 - recall_10: 0.9603 - auc_10: 0.9932\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5496 - accuracy: 0.9836 - precision_10: 0.9725 - recall_10: 0.9930 - auc_10: 0.9974\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3563 - accuracy: 0.9901 - precision_10: 0.9883 - recall_10: 0.9907 - auc_10: 0.9995\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0812 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8754 - accuracy: 0.9978 - precision_10: 1.0000 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7523 - accuracy: 0.9934 - precision_10: 0.9953 - recall_10: 0.9907 - auc_10: 0.9998\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6649 - accuracy: 0.9912 - precision_10: 0.9861 - recall_10: 0.9953 - auc_10: 0.9994\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6157 - accuracy: 0.9934 - precision_10: 0.9862 - recall_10: 1.0000 - auc_10: 0.9999\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5451 - accuracy: 0.9967 - precision_10: 1.0000 - recall_10: 0.9930 - auc_10: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4461 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3496 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2732 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2097 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1796 - accuracy: 0.9945 - precision_10: 0.9953 - recall_10: 0.9930 - auc_10: 0.9999\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1756 - accuracy: 0.9956 - precision_10: 0.9953 - recall_10: 0.9953 - auc_10: 0.9999\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1576 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1130 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0649 - accuracy: 0.9989 - precision_10: 0.9977 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0285 - accuracy: 0.9956 - precision_10: 0.9977 - recall_10: 0.9930 - auc_10: 0.9999\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9977 - accuracy: 0.9967 - precision_10: 0.9977 - recall_10: 0.9953 - auc_10: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9669 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9359 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9192 - accuracy: 0.9967 - precision_10: 0.9953 - recall_10: 0.9977 - auc_10: 0.9999\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8909 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8608 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8440 - accuracy: 0.9978 - precision_10: 0.9977 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8226 - accuracy: 0.9989 - precision_10: 1.0000 - recall_10: 0.9977 - auc_10: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7949 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff821868950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 12.6373 - accuracy: 0.5597 - precision_11: 0.5312 - recall_11: 0.5164 - auc_11: 0.5681\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 10.0202 - accuracy: 0.5915 - precision_11: 0.5676 - recall_11: 0.5397 - auc_11: 0.6462\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 7.8812 - accuracy: 0.6889 - precision_11: 0.6636 - recall_11: 0.6822 - auc_11: 0.7460\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 6.3917 - accuracy: 0.7963 - precision_11: 0.7881 - recall_11: 0.7734 - auc_11: 0.8803\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.4030 - accuracy: 0.8729 - precision_11: 0.8498 - recall_11: 0.8855 - auc_11: 0.9473\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.7188 - accuracy: 0.9288 - precision_11: 0.9311 - recall_11: 0.9159 - auc_11: 0.9785\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.2551 - accuracy: 0.9452 - precision_11: 0.9500 - recall_11: 0.9322 - auc_11: 0.9845\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.8765 - accuracy: 0.9660 - precision_11: 0.9563 - recall_11: 0.9720 - auc_11: 0.9941\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.5935 - accuracy: 0.9715 - precision_11: 0.9653 - recall_11: 0.9743 - auc_11: 0.9958\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.3272 - accuracy: 0.9781 - precision_11: 0.9834 - recall_11: 0.9696 - auc_11: 0.9983\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.1332 - accuracy: 0.9726 - precision_11: 0.9764 - recall_11: 0.9650 - auc_11: 0.9978\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.0312 - accuracy: 0.9759 - precision_11: 0.9765 - recall_11: 0.9720 - auc_11: 0.9976\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.9338 - accuracy: 0.9890 - precision_11: 0.9929 - recall_11: 0.9836 - auc_11: 0.9993\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.7915 - accuracy: 0.9880 - precision_11: 0.9906 - recall_11: 0.9836 - auc_11: 0.9998\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.6460 - accuracy: 0.9890 - precision_11: 0.9838 - recall_11: 0.9930 - auc_11: 0.9993\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.6301 - accuracy: 0.9430 - precision_11: 0.9455 - recall_11: 0.9322 - auc_11: 0.9892\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5935 - accuracy: 0.9715 - precision_11: 0.9741 - recall_11: 0.9650 - auc_11: 0.9963\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5541 - accuracy: 0.9759 - precision_11: 0.9833 - recall_11: 0.9650 - auc_11: 0.9968\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4631 - accuracy: 0.9912 - precision_11: 0.9930 - recall_11: 0.9883 - auc_11: 0.9996\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3140 - accuracy: 0.9934 - precision_11: 0.9930 - recall_11: 0.9930 - auc_11: 0.9999\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1492 - accuracy: 0.9967 - precision_11: 0.9953 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.0345 - accuracy: 0.9923 - precision_11: 0.9907 - recall_11: 0.9930 - auc_11: 0.9999\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.9171 - accuracy: 0.9978 - precision_11: 0.9953 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7996 - accuracy: 0.9989 - precision_11: 1.0000 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7431 - accuracy: 0.9869 - precision_11: 0.9860 - recall_11: 0.9860 - auc_11: 0.9988\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.7222 - accuracy: 0.9934 - precision_11: 0.9907 - recall_11: 0.9953 - auc_11: 0.9995\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.6607 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5616 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4625 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3783 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3180 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2738 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2385 - accuracy: 0.9956 - precision_11: 0.9930 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1994 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1555 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1330 - accuracy: 0.9945 - precision_11: 0.9953 - recall_11: 0.9930 - auc_11: 0.9998\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1251 - accuracy: 0.9956 - precision_11: 0.9930 - recall_11: 0.9977 - auc_11: 0.9999\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0985 - accuracy: 0.9967 - precision_11: 0.9977 - recall_11: 0.9953 - auc_11: 0.9999\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1014 - accuracy: 0.9869 - precision_11: 0.9906 - recall_11: 0.9813 - auc_11: 0.9985\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1584 - accuracy: 0.9584 - precision_11: 0.9577 - recall_11: 0.9533 - auc_11: 0.9954\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1602 - accuracy: 0.9814 - precision_11: 0.9835 - recall_11: 0.9766 - auc_11: 0.9981\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1967 - accuracy: 0.9836 - precision_11: 0.9905 - recall_11: 0.9743 - auc_11: 0.9987\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1857 - accuracy: 0.9934 - precision_11: 0.9930 - recall_11: 0.9930 - auc_11: 0.9996\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1402 - accuracy: 0.9967 - precision_11: 0.9977 - recall_11: 0.9953 - auc_11: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0562 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.9728 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9050 - accuracy: 0.9989 - precision_11: 0.9977 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8523 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8159 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7915 - accuracy: 0.9978 - precision_11: 0.9977 - recall_11: 0.9977 - auc_11: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff82046da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 12.5369 - accuracy: 0.5531 - precision_12: 0.5246 - recall_12: 0.4977 - auc_12: 0.5773\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 9.9970 - accuracy: 0.6276 - precision_12: 0.5859 - recall_12: 0.7009 - auc_12: 0.6851\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 7.7889 - accuracy: 0.7273 - precision_12: 0.7126 - recall_12: 0.7009 - auc_12: 0.8156\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 6.3258 - accuracy: 0.8204 - precision_12: 0.7986 - recall_12: 0.8248 - auc_12: 0.8961\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.3555 - accuracy: 0.8686 - precision_12: 0.8532 - recall_12: 0.8692 - auc_12: 0.9444\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.6994 - accuracy: 0.9036 - precision_12: 0.8846 - recall_12: 0.9136 - auc_12: 0.9696\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.2044 - accuracy: 0.9452 - precision_12: 0.9416 - recall_12: 0.9416 - auc_12: 0.9877\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.8421 - accuracy: 0.9682 - precision_12: 0.9629 - recall_12: 0.9696 - auc_12: 0.9931\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.5172 - accuracy: 0.9781 - precision_12: 0.9722 - recall_12: 0.9813 - auc_12: 0.9985\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.2684 - accuracy: 0.9847 - precision_12: 0.9836 - recall_12: 0.9836 - auc_12: 0.9995\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.0719 - accuracy: 0.9880 - precision_12: 0.9883 - recall_12: 0.9860 - auc_12: 0.9993\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.9090 - accuracy: 0.9748 - precision_12: 0.9655 - recall_12: 0.9813 - auc_12: 0.9980\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.7159 - accuracy: 0.9901 - precision_12: 0.9906 - recall_12: 0.9883 - auc_12: 0.9998\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5494 - accuracy: 0.9923 - precision_12: 0.9930 - recall_12: 0.9907 - auc_12: 0.9998\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4051 - accuracy: 0.9945 - precision_12: 0.9953 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.2915 - accuracy: 0.9934 - precision_12: 0.9930 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1582 - accuracy: 0.9967 - precision_12: 0.9953 - recall_12: 0.9977 - auc_12: 0.9998\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.0440 - accuracy: 0.9858 - precision_12: 0.9837 - recall_12: 0.9860 - auc_12: 0.9992\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.9881 - accuracy: 0.9770 - precision_12: 0.9834 - recall_12: 0.9673 - auc_12: 0.9983\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0730 - accuracy: 0.9693 - precision_12: 0.9673 - recall_12: 0.9673 - auc_12: 0.9934\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1645 - accuracy: 0.9847 - precision_12: 0.9836 - recall_12: 0.9836 - auc_12: 0.9969\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1253 - accuracy: 0.9880 - precision_12: 0.9860 - recall_12: 0.9883 - auc_12: 0.9989\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.9495 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7730 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.6239 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5332 - accuracy: 0.9967 - precision_12: 0.9930 - recall_12: 1.0000 - auc_12: 0.9999\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4852 - accuracy: 0.9934 - precision_12: 0.9953 - recall_12: 0.9907 - auc_12: 0.9999\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4385 - accuracy: 0.9912 - precision_12: 0.9884 - recall_12: 0.9930 - auc_12: 0.9995\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3827 - accuracy: 0.9956 - precision_12: 0.9953 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3625 - accuracy: 0.9945 - precision_12: 0.9953 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3526 - accuracy: 0.9934 - precision_12: 0.9930 - recall_12: 0.9930 - auc_12: 0.9998\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3161 - accuracy: 0.9945 - precision_12: 0.9953 - recall_12: 0.9930 - auc_12: 0.9999\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.2805 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2072 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1384 - accuracy: 0.9967 - precision_12: 0.9953 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0904 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0546 - accuracy: 0.9989 - precision_12: 1.0000 - recall_12: 0.9977 - auc_12: 0.9999\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0193 - accuracy: 0.9967 - precision_12: 0.9977 - recall_12: 0.9953 - auc_12: 0.9999\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9855 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9619 - accuracy: 0.9956 - precision_12: 0.9953 - recall_12: 0.9953 - auc_12: 0.9998\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9305 - accuracy: 0.9978 - precision_12: 0.9977 - recall_12: 0.9977 - auc_12: 0.9999\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9156 - accuracy: 0.9945 - precision_12: 0.9976 - recall_12: 0.9907 - auc_12: 0.9999\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8991 - accuracy: 0.9978 - precision_12: 0.9953 - recall_12: 1.0000 - auc_12: 0.9999\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8886 - accuracy: 0.9967 - precision_12: 0.9930 - recall_12: 1.0000 - auc_12: 0.9996\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8977 - accuracy: 0.9858 - precision_12: 0.9882 - recall_12: 0.9813 - auc_12: 0.9988\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8842 - accuracy: 0.9923 - precision_12: 0.9907 - recall_12: 0.9930 - auc_12: 0.9992\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8842 - accuracy: 0.9923 - precision_12: 0.9861 - recall_12: 0.9977 - auc_12: 0.9996\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8796 - accuracy: 0.9890 - precision_12: 0.9860 - recall_12: 0.9907 - auc_12: 0.9997\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8684 - accuracy: 0.9912 - precision_12: 0.9884 - recall_12: 0.9930 - auc_12: 0.9994\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9934 - accuracy: 0.9398 - precision_12: 0.9430 - recall_12: 0.9276 - auc_12: 0.9823\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff8203c76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 12.7269 - accuracy: 0.5455 - precision_13: 0.5200 - recall_13: 0.3949 - auc_13: 0.5620\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 10.2970 - accuracy: 0.5071 - precision_13: 0.4732 - recall_13: 0.4533 - auc_13: 0.5056\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 8.1268 - accuracy: 0.5531 - precision_13: 0.5239 - recall_13: 0.5117 - auc_13: 0.5687\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 6.5873 - accuracy: 0.6254 - precision_13: 0.6120 - recall_13: 0.5491 - auc_13: 0.6555\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.5477 - accuracy: 0.6867 - precision_13: 0.6636 - recall_13: 0.6729 - auc_13: 0.7450\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 4.8456 - accuracy: 0.7371 - precision_13: 0.7089 - recall_13: 0.7453 - auc_13: 0.8247\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 4.3119 - accuracy: 0.8467 - precision_13: 0.8144 - recall_13: 0.8715 - auc_13: 0.9285\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.9098 - accuracy: 0.9146 - precision_13: 0.9070 - recall_13: 0.9112 - auc_13: 0.9690\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.6865 - accuracy: 0.9135 - precision_13: 0.9030 - recall_13: 0.9136 - auc_13: 0.9673\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.4392 - accuracy: 0.9562 - precision_13: 0.9554 - recall_13: 0.9509 - auc_13: 0.9908\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.2767 - accuracy: 0.9573 - precision_13: 0.9664 - recall_13: 0.9416 - auc_13: 0.9923\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.0625 - accuracy: 0.9792 - precision_13: 0.9745 - recall_13: 0.9813 - auc_13: 0.9986\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.8694 - accuracy: 0.9890 - precision_13: 0.9906 - recall_13: 0.9860 - auc_13: 0.9992\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.6692 - accuracy: 0.9901 - precision_13: 0.9953 - recall_13: 0.9836 - auc_13: 0.9997\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5064 - accuracy: 0.9901 - precision_13: 0.9883 - recall_13: 0.9907 - auc_13: 0.9995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3848 - accuracy: 0.9847 - precision_13: 0.9836 - recall_13: 0.9836 - auc_13: 0.9990\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.3147 - accuracy: 0.9748 - precision_13: 0.9677 - recall_13: 0.9790 - auc_13: 0.9973\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.2565 - accuracy: 0.9814 - precision_13: 0.9724 - recall_13: 0.9883 - auc_13: 0.9990\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.2596 - accuracy: 0.9606 - precision_13: 0.9558 - recall_13: 0.9603 - auc_13: 0.9952\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1964 - accuracy: 0.9825 - precision_13: 0.9858 - recall_13: 0.9766 - auc_13: 0.9989\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1634 - accuracy: 0.9869 - precision_13: 0.9929 - recall_13: 0.9790 - auc_13: 0.9994\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.1038 - accuracy: 0.9934 - precision_13: 0.9976 - recall_13: 0.9883 - auc_13: 0.9998\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.9788 - accuracy: 0.9923 - precision_13: 0.9884 - recall_13: 0.9953 - auc_13: 0.9999\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8430 - accuracy: 0.9934 - precision_13: 0.9930 - recall_13: 0.9930 - auc_13: 0.9998\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.7355 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6363 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5295 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4430 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3771 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3181 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2976 - accuracy: 0.9901 - precision_13: 0.9883 - recall_13: 0.9907 - auc_13: 0.9995\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3434 - accuracy: 0.9880 - precision_13: 0.9883 - recall_13: 0.9860 - auc_13: 0.9983\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3748 - accuracy: 0.9923 - precision_13: 0.9861 - recall_13: 0.9977 - auc_13: 0.9994\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3466 - accuracy: 0.9890 - precision_13: 0.9906 - recall_13: 0.9860 - auc_13: 0.9995\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2847 - accuracy: 0.9923 - precision_13: 0.9907 - recall_13: 0.9930 - auc_13: 0.9998\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2117 - accuracy: 0.9978 - precision_13: 0.9953 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1568 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1285 - accuracy: 0.9912 - precision_13: 0.9884 - recall_13: 0.9930 - auc_13: 0.9998\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0970 - accuracy: 0.9923 - precision_13: 0.9930 - recall_13: 0.9907 - auc_13: 0.9996\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0635 - accuracy: 0.9956 - precision_13: 0.9930 - recall_13: 0.9977 - auc_13: 0.9999\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0458 - accuracy: 0.9956 - precision_13: 0.9953 - recall_13: 0.9953 - auc_13: 0.9998\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0163 - accuracy: 0.9934 - precision_13: 0.9953 - recall_13: 0.9907 - auc_13: 0.9998\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9732 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9316 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8869 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8488 - accuracy: 0.9989 - precision_13: 0.9977 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8178 - accuracy: 0.9989 - precision_13: 1.0000 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.7906 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7662 - accuracy: 0.9978 - precision_13: 0.9977 - recall_13: 0.9977 - auc_13: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.7496 - accuracy: 0.9978 - precision_13: 0.9977 - recall_13: 0.9977 - auc_13: 0.9998\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff821007598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 12.7734 - accuracy: 0.5203 - precision_14: 0.4896 - recall_14: 0.5491 - auc_14: 0.5206\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 10.2384 - accuracy: 0.5750 - precision_14: 0.5505 - recall_14: 0.5093 - auc_14: 0.5941\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 8.0909 - accuracy: 0.6166 - precision_14: 0.5899 - recall_14: 0.5981 - auc_14: 0.6599\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.5791 - accuracy: 0.7174 - precision_14: 0.6977 - recall_14: 0.7009 - auc_14: 0.7751\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 5.5065 - accuracy: 0.8182 - precision_14: 0.7898 - recall_14: 0.8341 - auc_14: 0.8968\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.7970 - accuracy: 0.8828 - precision_14: 0.8812 - recall_14: 0.8668 - auc_14: 0.9510\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 4.2891 - accuracy: 0.9299 - precision_14: 0.9252 - recall_14: 0.9252 - auc_14: 0.9741\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.9929 - accuracy: 0.9365 - precision_14: 0.9322 - recall_14: 0.9322 - auc_14: 0.9750\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.7015 - accuracy: 0.9671 - precision_14: 0.9693 - recall_14: 0.9603 - auc_14: 0.9964\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 3.4871 - accuracy: 0.9858 - precision_14: 0.9859 - recall_14: 0.9836 - auc_14: 0.9980\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.2393 - accuracy: 0.9934 - precision_14: 0.9884 - recall_14: 0.9977 - auc_14: 0.9984\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.0257 - accuracy: 0.9923 - precision_14: 0.9930 - recall_14: 0.9907 - auc_14: 0.9996\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.8637 - accuracy: 0.9901 - precision_14: 0.9883 - recall_14: 0.9907 - auc_14: 0.9993\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.7558 - accuracy: 0.9847 - precision_14: 0.9905 - recall_14: 0.9766 - auc_14: 0.9976\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.6567 - accuracy: 0.9890 - precision_14: 0.9929 - recall_14: 0.9836 - auc_14: 0.9994\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.5163 - accuracy: 0.9956 - precision_14: 0.9977 - recall_14: 0.9930 - auc_14: 0.9998\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4775 - accuracy: 0.9770 - precision_14: 0.9788 - recall_14: 0.9720 - auc_14: 0.9978\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4798 - accuracy: 0.9901 - precision_14: 0.9953 - recall_14: 0.9836 - auc_14: 0.9994\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.3820 - accuracy: 0.9923 - precision_14: 0.9953 - recall_14: 0.9883 - auc_14: 0.9999\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.2277 - accuracy: 0.9967 - precision_14: 0.9953 - recall_14: 0.9977 - auc_14: 0.9999\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0980 - accuracy: 0.9967 - precision_14: 0.9953 - recall_14: 0.9977 - auc_14: 0.9999\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.0421 - accuracy: 0.9945 - precision_14: 0.9930 - recall_14: 0.9953 - auc_14: 0.9996\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.9933 - accuracy: 0.9912 - precision_14: 0.9930 - recall_14: 0.9883 - auc_14: 0.9998\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.9418 - accuracy: 0.9945 - precision_14: 0.9976 - recall_14: 0.9907 - auc_14: 0.9999\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.9377 - accuracy: 0.9901 - precision_14: 0.9861 - recall_14: 0.9930 - auc_14: 0.9994\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.8941 - accuracy: 0.9901 - precision_14: 0.9929 - recall_14: 0.9860 - auc_14: 0.9998\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.7958 - accuracy: 0.9978 - precision_14: 1.0000 - recall_14: 0.9953 - auc_14: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.6894 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.5887 - accuracy: 0.9989 - precision_14: 1.0000 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.4909 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4155 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3570 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3182 - accuracy: 0.9945 - precision_14: 0.9976 - recall_14: 0.9907 - auc_14: 0.9998\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3132 - accuracy: 0.9858 - precision_14: 0.9905 - recall_14: 0.9790 - auc_14: 0.9995\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2845 - accuracy: 0.9934 - precision_14: 0.9907 - recall_14: 0.9953 - auc_14: 0.9999\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2767 - accuracy: 0.9978 - precision_14: 0.9977 - recall_14: 0.9977 - auc_14: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2381 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1771 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1217 - accuracy: 0.9989 - precision_14: 0.9977 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0891 - accuracy: 0.9945 - precision_14: 0.9930 - recall_14: 0.9953 - auc_14: 0.9984\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.1222 - accuracy: 0.9869 - precision_14: 0.9837 - recall_14: 0.9883 - auc_14: 0.9985\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1621 - accuracy: 0.9901 - precision_14: 0.9906 - recall_14: 0.9883 - auc_14: 0.9997\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1439 - accuracy: 0.9956 - precision_14: 0.9953 - recall_14: 0.9953 - auc_14: 0.9999\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.1250 - accuracy: 0.9890 - precision_14: 0.9883 - recall_14: 0.9883 - auc_14: 0.9995\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0806 - accuracy: 0.9923 - precision_14: 0.9953 - recall_14: 0.9883 - auc_14: 0.9998\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0283 - accuracy: 0.9923 - precision_14: 0.9884 - recall_14: 0.9953 - auc_14: 0.9998\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0143 - accuracy: 0.9858 - precision_14: 0.9814 - recall_14: 0.9883 - auc_14: 0.9988\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0417 - accuracy: 0.9869 - precision_14: 0.9883 - recall_14: 0.9836 - auc_14: 0.9987\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2181 - accuracy: 0.9409 - precision_14: 0.9309 - recall_14: 0.9439 - auc_14: 0.9864\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3440 - accuracy: 0.9233 - precision_14: 0.9262 - recall_14: 0.9089 - auc_14: 0.9746\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff820f2af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 57.642% (+/-1.680) \n",
      " Precision: 47.588% (+/-1.000) \n",
      " Recall: 100.000% (+/-0.000) \n",
      " AUC: 87.086% (+/-3.846) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_3(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'selu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' ,metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy,precision,recall,auc = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy,precision,recall,auc\n",
    "\n",
    "def run_experiment_3(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    accuracies = list()\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    aucs = list()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy,precision,recall,auc = evaluate_model_3(trainX, trainy, testX, testy)\n",
    "        accuracy = accuracy * 100.0\n",
    "        precision = precision * 100.0\n",
    "        recall = recall * 100.0\n",
    "        auc = auc * 100.0\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc)\n",
    "    # summarize results\n",
    "    summarize_results(accuracies,precisions,recalls,aucs)\n",
    "    \n",
    "run_experiment_3(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
