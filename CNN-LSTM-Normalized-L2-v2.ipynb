{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25 = np.load('s25.npy')\n",
    "h25 = np.load('h25.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s25_labels = np.array([0 for _ in range(0,len(s25))])\n",
    "h25_labels = np.array([1 for _ in range(0,len(h25))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(s25,h25,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(s25_labels,h25_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 6250, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print( ' Accuracy: %.3f%% (+/-%.3f) ' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print( ' >#%d: %.3f ' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 10.9801 - accuracy: 0.4863\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 6.6651 - accuracy: 0.5246\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 4.9996 - accuracy: 0.5608\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.3070 - accuracy: 0.5805\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.7850 - accuracy: 0.6331\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.3611 - accuracy: 0.7054\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.9779 - accuracy: 0.8357\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.6614 - accuracy: 0.8949\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.4321 - accuracy: 0.9277\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.3050 - accuracy: 0.9277\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.3150 - accuracy: 0.8740\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.1507 - accuracy: 0.9266\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.9743 - accuracy: 0.9606\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8301 - accuracy: 0.9693\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.7270 - accuracy: 0.9628\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.6409 - accuracy: 0.9737\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.5797 - accuracy: 0.9715\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.8819 - accuracy: 0.8258\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.6671 - accuracy: 0.9551\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5524 - accuracy: 0.9617\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4140 - accuracy: 0.9737\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3325 - accuracy: 0.9792\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2686 - accuracy: 0.9814\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2158 - accuracy: 0.9880\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1802 - accuracy: 0.9901\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1483 - accuracy: 0.9858\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1190 - accuracy: 0.9847\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1922 - accuracy: 0.9463\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1410 - accuracy: 0.9803\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1036 - accuracy: 0.9836\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.0659 - accuracy: 0.9792\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0208 - accuracy: 0.9825\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9928 - accuracy: 0.9847\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9485 - accuracy: 0.9945\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9242 - accuracy: 0.9912\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9157 - accuracy: 0.9847\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9074 - accuracy: 0.9825\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8778 - accuracy: 0.9912\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8473 - accuracy: 0.9967\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8325 - accuracy: 0.9923\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.7997 - accuracy: 0.9989\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7794 - accuracy: 0.9967\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8100 - accuracy: 0.9803\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8784 - accuracy: 0.9573\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8486 - accuracy: 0.9682\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8032 - accuracy: 0.9869\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7919 - accuracy: 0.9825\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7387 - accuracy: 0.9956\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7119 - accuracy: 0.9956\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6893 - accuracy: 0.9967\n",
      " >#1: 99.127 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 10.7945 - accuracy: 0.5203\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 6.4042 - accuracy: 0.5663\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.8300 - accuracy: 0.6648\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.1545 - accuracy: 0.7744\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.6288 - accuracy: 0.8554\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.3291 - accuracy: 0.8499\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.9832 - accuracy: 0.9255\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.7984 - accuracy: 0.9091\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.5757 - accuracy: 0.9507\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.4074 - accuracy: 0.9584\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.2691 - accuracy: 0.9507\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.1664 - accuracy: 0.9617\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.0656 - accuracy: 0.9660\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.0373 - accuracy: 0.9496\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 1.9333 - accuracy: 0.9693\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.8418 - accuracy: 0.9737\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.7290 - accuracy: 0.9825\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.6422 - accuracy: 0.9858\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.5752 - accuracy: 0.9836\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.5273 - accuracy: 0.9890\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 1.5226 - accuracy: 0.9792\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.4907 - accuracy: 0.9715\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 1.4341 - accuracy: 0.9803\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4783 - accuracy: 0.9430\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4826 - accuracy: 0.9496\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 1.3918 - accuracy: 0.9803\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3291 - accuracy: 0.9748\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2714 - accuracy: 0.9814\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2971 - accuracy: 0.9595\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2227 - accuracy: 0.9825\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1682 - accuracy: 0.9858\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1231 - accuracy: 0.9912\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0860 - accuracy: 0.9934\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0484 - accuracy: 0.9967\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0364 - accuracy: 0.9901\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 1.0067 - accuracy: 0.9967\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9801 - accuracy: 0.9967\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9504 - accuracy: 0.9978\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9205 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8996 - accuracy: 0.9967\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8892 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8715 - accuracy: 0.9967\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8455 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8244 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8077 - accuracy: 0.9978\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7916 - accuracy: 0.9989\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7745 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7597 - accuracy: 0.9978\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.7429 - accuracy: 0.9978\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7414 - accuracy: 0.9967\n",
      " >#2: 98.690 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 10.8557 - accuracy: 0.5235\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 6.5404 - accuracy: 0.5367\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.9315 - accuracy: 0.5947\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.2425 - accuracy: 0.6648\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 3.7092 - accuracy: 0.7448\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.2325 - accuracy: 0.8653\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.9443 - accuracy: 0.8872\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.6891 - accuracy: 0.9299\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.5671 - accuracy: 0.9025\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.3917 - accuracy: 0.9266\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.2547 - accuracy: 0.9321\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.0948 - accuracy: 0.9507\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9537 - accuracy: 0.9650\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8239 - accuracy: 0.9737\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8150 - accuracy: 0.9474\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.7703 - accuracy: 0.9529\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.6401 - accuracy: 0.9836\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5667 - accuracy: 0.9759\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5047 - accuracy: 0.9792\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4453 - accuracy: 0.9803\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3931 - accuracy: 0.9825\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3340 - accuracy: 0.9923\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2886 - accuracy: 0.9890\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2518 - accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2064 - accuracy: 0.9923\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1737 - accuracy: 0.9901\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1285 - accuracy: 0.9934\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1033 - accuracy: 0.9934\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2981 - accuracy: 0.9168\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3748 - accuracy: 0.9168\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.2844 - accuracy: 0.9463\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 1.1581 - accuracy: 0.9737\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0927 - accuracy: 0.9781\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0352 - accuracy: 0.9858\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9823 - accuracy: 0.9901\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9492 - accuracy: 0.9923\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9283 - accuracy: 0.9923\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8883 - accuracy: 0.9956\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8622 - accuracy: 0.9967\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8415 - accuracy: 0.9978\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8203 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8205 - accuracy: 0.9901\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0519 - accuracy: 0.9135\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9623 - accuracy: 0.9693\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8900 - accuracy: 0.9880\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8384 - accuracy: 0.9858\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7798 - accuracy: 0.9956\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7542 - accuracy: 0.9967\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.7294 - accuracy: 0.9967\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.7144 - accuracy: 0.9956\n",
      " >#3: 98.253 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 10.7159 - accuracy: 0.5378\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 6.2855 - accuracy: 0.5564\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.7844 - accuracy: 0.5465\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.1999 - accuracy: 0.5706\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.7076 - accuracy: 0.6539\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 3.3394 - accuracy: 0.6966\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.0207 - accuracy: 0.7963\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.7180 - accuracy: 0.8729\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.4870 - accuracy: 0.9014\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.2801 - accuracy: 0.9310\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.1608 - accuracy: 0.9299\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.1094 - accuracy: 0.9168\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.9884 - accuracy: 0.9430\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8772 - accuracy: 0.9496\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8358 - accuracy: 0.9343\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.7545 - accuracy: 0.9452\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 49ms/step - loss: 1.6377 - accuracy: 0.9595\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5425 - accuracy: 0.9715\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4433 - accuracy: 0.9781\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.3813 - accuracy: 0.9748\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3468 - accuracy: 0.9759\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3374 - accuracy: 0.9759\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3026 - accuracy: 0.9704\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.2499 - accuracy: 0.9825\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1914 - accuracy: 0.9847\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1672 - accuracy: 0.9792\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1303 - accuracy: 0.9836\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1107 - accuracy: 0.9770\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0621 - accuracy: 0.9836\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0396 - accuracy: 0.9858\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.0074 - accuracy: 0.9901\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0386 - accuracy: 0.9715\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9663 - accuracy: 0.9880\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9238 - accuracy: 0.9934\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8955 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9016 - accuracy: 0.9836\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9485 - accuracy: 0.9584\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9154 - accuracy: 0.9682\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8956 - accuracy: 0.9781\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9061 - accuracy: 0.9660\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8470 - accuracy: 0.9847\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8788 - accuracy: 0.9660\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9641 - accuracy: 0.9222\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8547 - accuracy: 0.9803\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8243 - accuracy: 0.9792\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7663 - accuracy: 0.9934\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7523 - accuracy: 0.9901\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7201 - accuracy: 0.9956\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6997 - accuracy: 0.9956\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6886 - accuracy: 0.9967\n",
      " >#4: 99.563 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 10.5801 - accuracy: 0.5476\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 6.0798 - accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.6529 - accuracy: 0.5860\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.0818 - accuracy: 0.6769\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.5964 - accuracy: 0.7426\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.1874 - accuracy: 0.8094\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.9252 - accuracy: 0.8160\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.7089 - accuracy: 0.8642\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.4779 - accuracy: 0.9113\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.3299 - accuracy: 0.9211\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 2.2399 - accuracy: 0.9189\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.1332 - accuracy: 0.9310\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.0298 - accuracy: 0.9343\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.9000 - accuracy: 0.9573\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8063 - accuracy: 0.9551\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.7486 - accuracy: 0.9463\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.6794 - accuracy: 0.9529\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5872 - accuracy: 0.9693\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4902 - accuracy: 0.9814\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5276 - accuracy: 0.9233\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5506 - accuracy: 0.8992\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5236 - accuracy: 0.9157\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3637 - accuracy: 0.9617\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2768 - accuracy: 0.9737\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2847 - accuracy: 0.9529\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2140 - accuracy: 0.9858\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1702 - accuracy: 0.9890\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.1167 - accuracy: 0.9869\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0781 - accuracy: 0.9858\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0342 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0296 - accuracy: 0.9858\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.0770 - accuracy: 0.9617\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9934 - accuracy: 0.9858\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9954 - accuracy: 0.9836\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.0313 - accuracy: 0.9693\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0657 - accuracy: 0.9650\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9746 - accuracy: 0.9858\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9348 - accuracy: 0.9869\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8844 - accuracy: 0.9923\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8542 - accuracy: 0.9956\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8416 - accuracy: 0.9858\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8290 - accuracy: 0.9880\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7949 - accuracy: 0.9978\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7753 - accuracy: 0.9923\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8106 - accuracy: 0.9923\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8463 - accuracy: 0.9890\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8233 - accuracy: 0.9923\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7818 - accuracy: 0.9956\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7390 - accuracy: 0.9978\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7204 - accuracy: 0.9934\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f34ed92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#5: 96.943 \n",
      "[99.12663698196411, 98.68995547294617, 98.25327396392822, 99.56331849098206, 96.94322943687439]\n",
      " Accuracy: 98.515% (+/-0.899) \n"
     ]
    }
   ],
   "source": [
    "run_experiment(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 11.0673 - accuracy: 0.5126\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 6.7860 - accuracy: 0.6079\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.9999 - accuracy: 0.6725\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.2194 - accuracy: 0.8478\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.6594 - accuracy: 0.8850\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.2314 - accuracy: 0.9430\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.9512 - accuracy: 0.9507\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.7397 - accuracy: 0.9639\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.6805 - accuracy: 0.9398\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.5079 - accuracy: 0.9518\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.3726 - accuracy: 0.9584\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.2014 - accuracy: 0.9814\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0705 - accuracy: 0.9880\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9377 - accuracy: 0.9956\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8506 - accuracy: 0.9945\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7632 - accuracy: 0.9890\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6911 - accuracy: 0.9912\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6025 - accuracy: 0.9967\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5212 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4541 - accuracy: 0.9967\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4156 - accuracy: 0.9989\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3938 - accuracy: 0.9890\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3554 - accuracy: 0.9901\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3316 - accuracy: 0.9858\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2594 - accuracy: 0.9956\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2388 - accuracy: 0.9890\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3280 - accuracy: 0.9518\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3144 - accuracy: 0.9715\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2462 - accuracy: 0.9803\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1689 - accuracy: 0.9912\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1018 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0495 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0104 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0509 - accuracy: 0.9792\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0661 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0346 - accuracy: 0.9901\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9799 - accuracy: 0.9923\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9361 - accuracy: 0.9989\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9151 - accuracy: 0.9945\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9317 - accuracy: 0.9945\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8941 - accuracy: 0.9978\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8528 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8217 - accuracy: 0.9989\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8007 - accuracy: 0.9978\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7768 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7540 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7352 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7190 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7039 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.6975 - accuracy: 0.9967\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7e305c0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#1: 89.520 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 11.0689 - accuracy: 0.5301\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.7817 - accuracy: 0.6123\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 5.0244 - accuracy: 0.6824\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.2401 - accuracy: 0.8258\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.6757 - accuracy: 0.8992\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 3.2517 - accuracy: 0.9157\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.9767 - accuracy: 0.9310\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.8146 - accuracy: 0.9266\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.6338 - accuracy: 0.9452\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4543 - accuracy: 0.9551\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.2787 - accuracy: 0.9639\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.1960 - accuracy: 0.9660\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.1662 - accuracy: 0.9507\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0301 - accuracy: 0.9682\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9140 - accuracy: 0.9715\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8068 - accuracy: 0.9847\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.7196 - accuracy: 0.9890\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.6330 - accuracy: 0.9901\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5525 - accuracy: 0.9967\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4932 - accuracy: 0.9945\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4334 - accuracy: 0.9945\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3975 - accuracy: 0.9923\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4180 - accuracy: 0.9770\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3770 - accuracy: 0.9934\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3070 - accuracy: 0.9978\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3771 - accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3697 - accuracy: 0.9704\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2863 - accuracy: 0.9858\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2106 - accuracy: 0.9901\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1341 - accuracy: 0.9956\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0815 - accuracy: 0.9945\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0395 - accuracy: 0.9956\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0041 - accuracy: 0.9989\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9691 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9394 - accuracy: 0.9989\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9173 - accuracy: 0.9956\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9063 - accuracy: 0.9967\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8867 - accuracy: 0.9967\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8853 - accuracy: 0.9934\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8639 - accuracy: 0.9967\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8483 - accuracy: 0.9978\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9795 - accuracy: 0.9518\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9820 - accuracy: 0.9682\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9446 - accuracy: 0.9858\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9157 - accuracy: 0.9869\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8734 - accuracy: 0.9890\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8378 - accuracy: 0.9978\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8167 - accuracy: 0.9912\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7782 - accuracy: 0.9967\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7520 - accuracy: 0.9967\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f35bbc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#2: 98.253 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 11.1898 - accuracy: 0.5148\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.8661 - accuracy: 0.5827\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 5.0596 - accuracy: 0.6364\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.2970 - accuracy: 0.6988\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.6980 - accuracy: 0.8598\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.2487 - accuracy: 0.9003\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.9959 - accuracy: 0.9135\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.8008 - accuracy: 0.9288\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.5671 - accuracy: 0.9507\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.3864 - accuracy: 0.9660\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.2414 - accuracy: 0.9650\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.1138 - accuracy: 0.9682\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0220 - accuracy: 0.9584\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9260 - accuracy: 0.9704\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8607 - accuracy: 0.9693\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7367 - accuracy: 0.9770\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6316 - accuracy: 0.9869\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5963 - accuracy: 0.9781\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5586 - accuracy: 0.9803\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5225 - accuracy: 0.9748\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4559 - accuracy: 0.9825\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3968 - accuracy: 0.9836\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3352 - accuracy: 0.9934\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2668 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2314 - accuracy: 0.9890\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1881 - accuracy: 0.9923\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1420 - accuracy: 0.9978\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1017 - accuracy: 0.9978\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0878 - accuracy: 0.9978\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0839 - accuracy: 0.9945\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1160 - accuracy: 0.9704\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0514 - accuracy: 0.9967\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0195 - accuracy: 0.9923\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9647 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.9280 - accuracy: 0.9989\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8966 - accuracy: 0.9989\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8723 - accuracy: 0.9978\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8471 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8260 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8019 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7894 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4163 - accuracy: 0.8018\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2745 - accuracy: 0.9409\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.0975 - accuracy: 0.9770\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9452 - accuracy: 0.9803\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9223 - accuracy: 0.9650\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8504 - accuracy: 0.9825\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7959 - accuracy: 0.9923\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7539 - accuracy: 0.9967\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.7252 - accuracy: 0.9956\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f34e7c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >#3: 96.943 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 11.0401 - accuracy: 0.5071\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.7199 - accuracy: 0.5367\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 5.0071 - accuracy: 0.6090\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.2877 - accuracy: 0.6780\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.8096 - accuracy: 0.7010\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.3330 - accuracy: 0.8576\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.0452 - accuracy: 0.8729\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.7466 - accuracy: 0.9354\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.5502 - accuracy: 0.9354\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4386 - accuracy: 0.9211\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.2626 - accuracy: 0.9540\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.1767 - accuracy: 0.9452\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0357 - accuracy: 0.9639\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0166 - accuracy: 0.9299\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8629 - accuracy: 0.9682\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7226 - accuracy: 0.9858\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6765 - accuracy: 0.9660\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5920 - accuracy: 0.9912\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5260 - accuracy: 0.9858\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4528 - accuracy: 0.9912\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.3784 - accuracy: 0.9934\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3255 - accuracy: 0.9923\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3081 - accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2662 - accuracy: 0.9923\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2409 - accuracy: 0.9890\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1989 - accuracy: 0.9869\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1736 - accuracy: 0.9858\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1404 - accuracy: 0.9934\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0924 - accuracy: 0.9967\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0465 - accuracy: 0.9989\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0072 - accuracy: 0.9956\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0370 - accuracy: 0.9803\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9987 - accuracy: 0.9945\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9774 - accuracy: 0.9923\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9508 - accuracy: 0.9967\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9220 - accuracy: 0.9989\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9227 - accuracy: 0.9901\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0137 - accuracy: 0.9814\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0813 - accuracy: 0.9847\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0132 - accuracy: 0.9912\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9789 - accuracy: 0.9792\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9025 - accuracy: 0.9923\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8689 - accuracy: 0.9912\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8338 - accuracy: 0.9956\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7937 - accuracy: 0.9956\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7589 - accuracy: 0.9989\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7355 - accuracy: 0.9989\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7143 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6937 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6746 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7e302f3ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#4: 99.127 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 11.0828 - accuracy: 0.5093\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.7535 - accuracy: 0.5619\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 5.0164 - accuracy: 0.6276\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.2826 - accuracy: 0.6878\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.6974 - accuracy: 0.8204\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.2103 - accuracy: 0.8981\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.8826 - accuracy: 0.9321\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.6455 - accuracy: 0.9452\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4967 - accuracy: 0.9507\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.3868 - accuracy: 0.9398\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2019 - accuracy: 0.9660\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.0748 - accuracy: 0.9639\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.9365 - accuracy: 0.9825\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8532 - accuracy: 0.9803\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7721 - accuracy: 0.9814\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6640 - accuracy: 0.9901\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5783 - accuracy: 0.9912\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5222 - accuracy: 0.9869\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4481 - accuracy: 0.9880\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3913 - accuracy: 0.9858\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3451 - accuracy: 0.9847\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3020 - accuracy: 0.9890\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2601 - accuracy: 0.9890\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2107 - accuracy: 0.9923\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1599 - accuracy: 0.9967\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1203 - accuracy: 0.9978\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1730 - accuracy: 0.9639\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1362 - accuracy: 0.9836\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1290 - accuracy: 0.9814\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0689 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0264 - accuracy: 0.9945\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9943 - accuracy: 0.9989\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9795 - accuracy: 0.9912\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9438 - accuracy: 0.9978\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9181 - accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9605 - accuracy: 0.9825\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9875 - accuracy: 0.9825\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9255 - accuracy: 0.9945\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9614 - accuracy: 0.9704\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9168 - accuracy: 0.9869\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8633 - accuracy: 0.9945\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8261 - accuracy: 0.9967\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7916 - accuracy: 0.9967\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8318 - accuracy: 0.9825\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8222 - accuracy: 0.9880\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7868 - accuracy: 0.9967\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7628 - accuracy: 0.9989\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7320 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7067 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6827 - accuracy: 0.9989\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f309a32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#5: 98.690 \n",
      "[89.51964974403381, 98.25327396392822, 96.94322943687439, 99.12663698196411, 98.68995547294617]\n",
      " Accuracy: 96.507% (+/-3.569) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_2(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),input_shape=(None,n_length,n_features))))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def run_experiment_2(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model_2(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print( ' >#%d: %.3f ' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "    \n",
    "run_experiment_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 12.8753 - accuracy: 0.5312\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 10.4236 - accuracy: 0.5827\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 8.2475 - accuracy: 0.6145\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.6349 - accuracy: 0.7196\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 5.5214 - accuracy: 0.7831\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.7141 - accuracy: 0.8598\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.2111 - accuracy: 0.8970\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.8510 - accuracy: 0.9277\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.5898 - accuracy: 0.9332\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.3694 - accuracy: 0.9671\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.2035 - accuracy: 0.9825\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.9903 - accuracy: 0.9869\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.7954 - accuracy: 0.9847\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.6497 - accuracy: 0.9814\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.5369 - accuracy: 0.9880\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4607 - accuracy: 0.9912\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.4765 - accuracy: 0.9474\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.4890 - accuracy: 0.9770\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.5259 - accuracy: 0.9770\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.3701 - accuracy: 0.9945\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.1851 - accuracy: 0.9923\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0057 - accuracy: 0.9967\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8594 - accuracy: 0.9956\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7383 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6384 - accuracy: 0.9934\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5505 - accuracy: 0.9989\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4782 - accuracy: 0.9989\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4170 - accuracy: 0.9989\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.3596 - accuracy: 0.9978\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3136 - accuracy: 0.9978\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2634 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2078 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1598 - accuracy: 0.9989\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1378 - accuracy: 0.9923\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1435 - accuracy: 0.9912\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1631 - accuracy: 0.9869\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1748 - accuracy: 0.9890\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1799 - accuracy: 0.9890\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1494 - accuracy: 0.9858\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1235 - accuracy: 0.9912\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1955 - accuracy: 0.9847\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2567 - accuracy: 0.9869\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2100 - accuracy: 0.9945\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1094 - accuracy: 0.9989\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0128 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9315 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8677 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8216 - accuracy: 0.9989\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7818 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7536 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f34e7cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#1: 69.869 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 12.9706 - accuracy: 0.4973\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 10.5912 - accuracy: 0.5334\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 8.3871 - accuracy: 0.5936\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 6.8053 - accuracy: 0.6769\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 5.6926 - accuracy: 0.7525\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.8811 - accuracy: 0.8280\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.3579 - accuracy: 0.8686\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 3.9876 - accuracy: 0.9058\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.6853 - accuracy: 0.9343\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.4402 - accuracy: 0.9485\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.2125 - accuracy: 0.9682\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.0189 - accuracy: 0.9748\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.9336 - accuracy: 0.9671\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.8800 - accuracy: 0.9628\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.7859 - accuracy: 0.9737\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.6562 - accuracy: 0.9890\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.5199 - accuracy: 0.9869\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.3659 - accuracy: 0.9880\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.2240 - accuracy: 0.9945\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.1134 - accuracy: 0.9901\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.0073 - accuracy: 0.9869\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.9156 - accuracy: 0.9934\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8632 - accuracy: 0.9847\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8208 - accuracy: 0.9934\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7464 - accuracy: 0.9978\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6669 - accuracy: 0.9912\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.5826 - accuracy: 0.9989\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5082 - accuracy: 0.9978\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.4473 - accuracy: 0.9923\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4824 - accuracy: 0.9858\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6034 - accuracy: 0.9781\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5952 - accuracy: 0.9945\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5228 - accuracy: 0.9912\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4058 - accuracy: 0.9956\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.2925 - accuracy: 0.9978\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1959 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1203 - accuracy: 0.9989\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0651 - accuracy: 0.9978\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0313 - accuracy: 0.9956\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0058 - accuracy: 0.9945\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9726 - accuracy: 0.9989\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9574 - accuracy: 0.9956\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9403 - accuracy: 0.9978\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1110 - accuracy: 0.9463\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6229 - accuracy: 0.8620\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6721 - accuracy: 0.9452\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6072 - accuracy: 0.9770\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.4490 - accuracy: 0.9880\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2884 - accuracy: 0.9901\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1411 - accuracy: 0.9934\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7e302a81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#2: 65.066 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 12.5844 - accuracy: 0.5137\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 9.9628 - accuracy: 0.5652\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 7.7585 - accuracy: 0.6659\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 6.2873 - accuracy: 0.7634\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 5.2879 - accuracy: 0.8456\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.6401 - accuracy: 0.9102\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.1620 - accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.8363 - accuracy: 0.9792\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.5261 - accuracy: 0.9934\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.2714 - accuracy: 0.9912\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.0155 - accuracy: 0.9967\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.8052 - accuracy: 0.9890\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.6316 - accuracy: 0.9945\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.4756 - accuracy: 0.9945\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.3180 - accuracy: 0.9945\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.1869 - accuracy: 0.9956\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.0669 - accuracy: 0.9978\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.9727 - accuracy: 0.9956\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.9025 - accuracy: 0.9934\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.8625 - accuracy: 0.9814\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.8547 - accuracy: 0.9901\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.8034 - accuracy: 0.9967\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7161 - accuracy: 0.9956\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6176 - accuracy: 0.9989\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5212 - accuracy: 0.9989\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4336 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3635 - accuracy: 0.9956\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6597 - accuracy: 0.8795\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.7108 - accuracy: 0.9671\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7425 - accuracy: 0.9869\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6373 - accuracy: 0.9945\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.5345 - accuracy: 0.9967\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4073 - accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.2977 - accuracy: 0.9989\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2175 - accuracy: 0.9989\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.1609 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0956 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0355 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.9912 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9585 - accuracy: 0.9978\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9243 - accuracy: 0.9989\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8939 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8813 - accuracy: 0.9945\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8840 - accuracy: 0.9934\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8919 - accuracy: 0.9825\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8747 - accuracy: 0.9967\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8521 - accuracy: 0.9989\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8219 - accuracy: 0.9989\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.7876 - accuracy: 0.9989\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.7677 - accuracy: 0.9989\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f35c83510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >#3: 55.895 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 12.4051 - accuracy: 0.5290\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 9.4839 - accuracy: 0.6199\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 7.2790 - accuracy: 0.7393\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 5.9155 - accuracy: 0.8149\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 5.0546 - accuracy: 0.8686\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.4737 - accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.0358 - accuracy: 0.9595\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.7273 - accuracy: 0.9660\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.4093 - accuracy: 0.9814\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.1513 - accuracy: 0.9869\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.9400 - accuracy: 0.9880\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.7538 - accuracy: 0.9901\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.6119 - accuracy: 0.9858\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.4831 - accuracy: 0.9923\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.3664 - accuracy: 0.9956\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2424 - accuracy: 0.9967\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2194 - accuracy: 0.9682\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.1813 - accuracy: 0.9836\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.1295 - accuracy: 0.9814\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.0305 - accuracy: 0.9836\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.9195 - accuracy: 0.9923\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.8148 - accuracy: 0.9945\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.6941 - accuracy: 0.9989\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.6047 - accuracy: 0.9967\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5338 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4579 - accuracy: 0.9967\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.3909 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3378 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2831 - accuracy: 0.9967\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.2468 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2217 - accuracy: 0.9945\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1881 - accuracy: 0.9967\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1420 - accuracy: 0.9989\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1001 - accuracy: 0.9989\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0634 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0351 - accuracy: 0.9934\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0180 - accuracy: 0.9912\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9917 - accuracy: 0.9989\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.9710 - accuracy: 0.9989\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2627 - accuracy: 0.9036\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3162 - accuracy: 0.9255\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2734 - accuracy: 0.9792\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1624 - accuracy: 0.9912\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0577 - accuracy: 0.9945\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9616 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8946 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.8417 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8011 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7701 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7436 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7f3027ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#4: 60.699 \n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 12.4562 - accuracy: 0.5685\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 9.7760 - accuracy: 0.6353\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 7.5300 - accuracy: 0.7645\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 6.1088 - accuracy: 0.8302\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 5.2288 - accuracy: 0.8653\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 4.6095 - accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 4.1049 - accuracy: 0.9650\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.7457 - accuracy: 0.9748\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.4476 - accuracy: 0.9869\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 3.1700 - accuracy: 0.9890\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 2.9543 - accuracy: 0.9890\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.7652 - accuracy: 0.9847\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 2.6036 - accuracy: 0.9901\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.4885 - accuracy: 0.9869\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.4797 - accuracy: 0.9759\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 2.4229 - accuracy: 0.9934\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.2881 - accuracy: 0.9967\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 2.1018 - accuracy: 0.9978\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.9399 - accuracy: 0.9967\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.8285 - accuracy: 0.9945\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.7994 - accuracy: 0.9737\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.7669 - accuracy: 0.9901\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7938 - accuracy: 0.9628\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.7173 - accuracy: 0.9858\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.6454 - accuracy: 0.9923\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 51ms/step - loss: 1.5462 - accuracy: 0.9989\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4587 - accuracy: 0.9956\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.4603 - accuracy: 0.9803\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.5024 - accuracy: 0.9912\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.4732 - accuracy: 0.9945\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3672 - accuracy: 0.9967\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2680 - accuracy: 0.9989\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1878 - accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.1195 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.0654 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0200 - accuracy: 0.9989\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9836 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.9473 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9127 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.8819 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8538 - accuracy: 0.9989\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2822 - accuracy: 0.8675\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2152 - accuracy: 0.9682\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2209 - accuracy: 0.9836\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.1214 - accuracy: 0.9880\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.0221 - accuracy: 0.9945\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.9622 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8905 - accuracy: 0.9989\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.8282 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.7784 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7e3066c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " >#5: 57.642 \n",
      "[69.86899375915527, 65.06550312042236, 55.89519739151001, 60.69868803024292, 57.64192342758179]\n",
      " Accuracy: 61.834% (+/-5.082) \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_3(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 50, 128\n",
    "    n_features = trainX.shape[2]\n",
    "    n_steps, n_length = 10, 625\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='selu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'selu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def run_experiment_3(X,y,repeats=5):\n",
    "    # load data\n",
    "    trainX, testX,trainy, testy = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    mean = trainX.mean(axis=0)\n",
    "    trainX -= mean\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX /= std\n",
    "    testX -= mean\n",
    "    testX /= std\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model_3(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print( ' >#%d: %.3f ' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "    \n",
    "run_experiment_3(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
